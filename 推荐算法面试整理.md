[TOC]

# 机器学习算法

## 逻辑斯蒂回归（Logistic Regression，LR）



## 协同过滤

### 1 目标场景

存在共现矩阵的情况下，进行点击率预估、评分预测等等

### 2 基本思想

物以类聚，人以群分。

### 3 相似度计算方式

- 杰卡德（Jaccard）相似度

  这个是**衡量两个集合的相似度的一种指标**。两个集合A和B的交集元素在A，B的并集中所占的比例，称为两个集合的杰卡德相似系数
  $$
  J(A,B)=\frac{|A\cap{B}|}{|A\cup{B}|}
  $$

- 余弦相似度

  衡量了用户向量之间向量夹角的大小，夹角越小，说明相似度越大，两个用户越相似
  $$
  sim(i,j)=cos(i,j)=\frac{i·j}{||i||·||j||}
  $$
  **局限性：**对于评分数据不规范的时候，存在有的用户喜欢打高分，有的用户喜欢打低分情况的时候，有的用户喜欢乱打分的情况，这时候余弦相似度算出来的结果可能就不是那么准确了。

- 皮尔逊相关系数

  皮尔逊相关系数通过使用用户平均分对个体独立评分进行修正，减少了用户评分偏置的影响
  $$
  sim(i,j)=\frac{\sum_{p\in{P}}(R_{i,p}-\overline{R_i})(R_{jp}-\overline{R_j})}{\sqrt{\sum_{p\in{P}}(R_{i,p}-\overline{R_i})^2}\sqrt{\sum_{p\in{P}}(R_{jp}-\overline{R_j})^2}}
  $$

- 其他

- 余弦相似度VS欧式距离

### 4 基于User的协同过滤 UserCF

- 步骤：

  - 计算用户A与其他用户的相似度

  - 根据相似度用户计算用户A对物品的最终评分
    $$
    R_{u,p}=\frac{\sum_{s\in{S}}(w_{u,s}R_{s,p})}{\sum_{s\in{S}}w_{u,s}}
    $$

  - 根据用户评分对用户进行推荐：定一个阈值，预测评分超过阈值即可推荐给用户

- 缺点：

  - 数据稀疏性：

    一个大型的电子商务推荐系统一般有非常多的物品，用户可能买的其中不到1%的物品，不同用户之间买的物品重叠性较低，导致算法无法找到一个用户的邻居，即偏好相似的用户，即使找到准确性也不会太高。这导致UserCF不适用于那些正反馈获取较困难的应用场景

  - 用户相似度矩阵维护难度大：

    绝大多数产品的用户数都要远大于物品数，因此维护用户相似度矩阵的难度要大得多；用户相似度矩阵的存储空间随着用户数量的增加而增加，不适合用户数据量大的情况的使用。

- 适用场景：常适用于用户少，物品多，时效性较强的场合

### 5 基于Item的协同过滤 ItemCF

- 步骤：
  - 首先计算待选物品和其他物品的相似度
  - 找出与待选物品最相似的n个物品
  - 根据用户对这n个物品的打分去计算对待选物品的打分情况
- 优点：
  - ItemCF算法的预测结果比UserCF算法质量要高一些
  - 由于ItemCF算法可以预先计算好物品的相似度，所以在线的预测性能要比UserCF算法高
- 缺点：
  - 数据稀疏性
  - 物品相似度矩阵维护难度大
- 适用场景：

### 6 UserCF和ItemCF的优缺点对比

- 区别 

  ![image-20220405163844329](F:\面试\推荐算法\图片\UserCF和ItemCF区别.png)

- 共同的缺点

  - 不能彻底解决数据稀疏性问题
  - 泛化能力弱
    - 热门物品具有很强的头部效应，容易跟大量物品产生相似，而尾部物品由于特征向量稀疏，导致很少被推荐
    - 为解决这一问题，矩阵分解技术被提出
  - 无法利用更多的信息：**一般是仅仅基于用户的行为数据**，而不依赖于任何附加信息或者用户的任何附加信息，比如不依赖物品自身特征、用户性别、年龄等

### 7 协同过滤算法的优缺点

- 优点：
  - 算法原理朴素简单，即"物以类聚，人以群分"，已得到工业界验证过的一类重要算法，在大型互联网公司都有很好的落地和应用
  - 易使用Spark分布平台来实现，因此可以通过增加计算节点很容易处理大规模数据集。
  - 可以很好的为用户推荐多样性、新颖性的item，特别是当群体规模越大、用户行为越多，推荐的效果越好
  - 只依赖用户的操作行为，不依赖具体user相关和item相关的信息就可以实现
- 缺点：
  - 冷启动问题：如果用户行为少，这时就很难发挥协同过滤算法的优势和价值，甚至无法为用户做推荐
  - 稀疏性问题：互联网产品用户基数大，item数量多，一般用户只对很少量的item产生操作行为，这时用户操作行为矩阵是非常稀疏的，太稀疏的行为矩阵计算出的item相似度往往不够精准，最终影响推荐结果的精确度。

## 矩阵分解（Matrix Factorization，MF）

矩阵分解也叫做隐语义模型
$$
p(u,i)=p^T_uq_i=\sum_{f=1}^{F}{p_{uf}q_{if}}
$$

- LFM的损失函数：未正则化和正则化

$$
loss=\sum(p(u,i)-p^{LFM}(u,i))^2
$$

$$
loss=\sum(p(u,i)-p^{LFM}(u,i))^2+\alpha|p_u|^2+\alpha|q_i|^2
$$

- LFM算法迭代，对其求偏导
  $$
  \frac{\partial{loss}}{\partial{p_{uf}}} = -2(p(u,i)-p^{LFM}(u,i))q_{if}+2\partial{p_{uf}}
  $$

  $$
  \frac{\partial{loss}}{\partial{q_{if}}} = -2(p(u,i)-p^{LFM}(u,i))p_{uf}+2\partial{q_{if}}
  $$

- 梯度下降
  $$
  p_{uf}=p_{uf} - \beta\frac{\partial{loss}}{\partial{p_{uf}}}
  $$

  $$
  q_{if}=q_{if} - \beta\frac{\partial{loss}}{\partial{q_{if}}}
  $$

- 影响训练效果的因素

  - 负样本的选取
  - 隐特征F，正则化参数，learning rate

- LFM vs CF

  - LFM是属于监督学习的分支，通过训练样本的label设定损失函数，利用最优化方法来使得损失函数最小化，从而得到最优模型；CF是通过公式建模求解相似度矩阵
  - LFM空间复杂度为O(max(M×F，N×F))，CF的空间复杂度为O(M^2)或O(N^2)，离线计算LFM较快
  - CF可较好地实时计算，LFM响应不及时，实时计算CF较快

## 因子分解机（Factorization Machine，FM）

- 针对问题

  - 在面对稀疏特征向量时，Poly2特征交叉项无法收敛
  - Poly2计算复杂度过高

- 改进思路：当k足够大的时候，对于**任意对称正定的实矩阵W**，均存在实矩阵V，使得W=V·VT

- 数学模型
  $$
  y=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n-1}\sum_{j=i+1}^n<v_i,v_j>x_ix_j,<v_i,v_j>=\sum_{f=1}^kv_{i,f}v_{j,f}
  $$

- 损失函数
  $$
  J(w_0,w_1,w_2,...,w_n,w_{12},w_{13},...,w_{n-1,n})=-\frac{1}{m}\sum_{i=1}^my^{(i)}logy^{(i)}_{pre}+(1-y^{(i)})log(1-y^{(i)}_{pre})
  $$

- 梯度下降
  $$
  y=w_0+\sum_{i=1}^nw_ix_i+\frac{1}{2}\sum_{f=1}^k[(\sum_{i=1}^nv_{i,f}x_i)^2-\sum_{i=1}^n(v_{i,f}x_i)^2]
  $$

- 优点

  - 极大降低了训练开销 O(n^2)->O(kn)
  - **隐向量的引入**，使得FM能更好解决数据稀疏性的问题：
    - 这里可以观察到，**交叉项的权重是两个矩阵的点乘而不直接是一个权重矩阵**，这是因为类型变量经过One-Hot或其他类似形式的编码后，会产生高维稀疏矩阵，导致有的交叉项在训练样本中从未出现过，如直接是一个权重矩阵则权重为0，训练不出相关信息。因而相当于是通过矩阵分解的形式，将原本的权重矩阵表示为两个矩阵相乘。这样，即使交叉项为0还是可以得到相关权重，以此解决高维稀疏矩阵的问题。
  - **FM模型是利用两个特征的Embedding做内积得到二阶特征交叉的权重**，那么我们可以将训练好的FM特征取出离线存好，之后用来做其他扩展





## FM引入特征域（Field-ware Factorization Machines，FFM）

相比于FM，FFM模型引入了特征域的概念，其数学形式的二阶部分如下
$$
FM(w,x)=\sum_{j_1=1}^n\sum_{j_2=j_1+1}^n(w_{j_1f_2}w_{j_2f_1})x_{j_1}x_{j_2}
$$
其与FM的区别在于隐向量由原来的wj1变成了wj1f2，这意味着每个特征对应的不是唯一一个隐向量，而是一组隐向量。当 x<sub>j1</sub> 特征与 x<sub>j2 </sub>特征进行交叉时， x<sub>j1</sub> 会从 x<sub>j1</sub> 的这一组隐向量中挑出与x<sub>j2 </sub>的域对应的隐向量wj1f2进行交叉。



# 深度学习



# 样本

## 负样本采样

### 推荐系统中有哪些场景是无法获得真负样本的？如何解决？

个性化推荐。App内部的推荐，我们可以根据埋点，比较容易获知用户滑过、忽略了某些推荐内容，所以比较有信心拿哪些item作为负样本。但是在推送场景下，我们很难知道用户未点击的item是用户真的不喜欢还是压根没看见。所以不能放心地将所有未点击的item都当负样本。

在这种无法获得真负样本的场景下，一般我们通过随机采样来获得负样本。但是，随机采样毕竟引入了噪声，这时，再用CTR预估这种要求"绝对准确性"的算法，就不合适了。所以，在召回或个性化推送场景下，我们一般采用pairwise LearningToRank建模排序的相对准确性。

### 为什么不能只拿曝光未点击做召回模型的负样本？

我们希望召回训练数据的正样本是user和item匹配度最高的那些样本，也即用户点击样本，负样本是user和item最不匹配的那些样本，但不能拿“曝光未点击”作为召回模型的负样本，因为我们从线上日志获得的训练样本，已经是上一版本的召回、粗排、精排替用户筛选过的，即已经是对用户“匹配度较高”的样本了，即推荐系统以为用户会喜欢他们，但用户的行为又表明的对他的嫌弃。拿这样的样本训练出来的模型做召回，并不能与线上环境的数据分布保持一致。也就是说曝光未点击既不能成为合格的正样本，也不能成为合格的负样本。

所以一般的做法是拿点击样本做正样本，拿随机采样做负样本，因为线上召回时，候选库里大多数的物料是与用户没有关系的，随机抽样能够很好地模拟这一分布。

## 正样本采样

### 热门打压

- 生成正样本 item+ 时，打压高热item

  目的是为了降低item成为 **item+** 的可能性。因此，item越热门，其成为 **item+** 的概率就应该越低。

  一个item成为 **item+** 的概率
  $$
  P_{pos}(w_i)=(\sqrt{\frac{z(w_i)}{a}} + 1)\frac{a}{z(w_i)}
  $$

  $$
  z(w_i)=\frac{点击过w_i的用户数}{同时段所有发生过点击行为的用户总数}
  $$

  a 为一个超参数，一般在 1e-3~1e-5 之间

  可以看出 z(w<sub>i</sub>) 越高，item成为 item+ 的概率就越低，从而实现了对热门item的打压。

  而对于一些罕见item，按照公式计算出的概率大于1，说明罕见的item只要被点击过，就一定会被当成正样本。

# 其他

## AB实验

- **定义**

  **A/B 测试**为一种随机测试，将两个不同的东西（即A和B）进行假设比较。该测试运用统计学上的**假设检定**和**双母体假设检定**。A/B 测试可以用来测试某一个变量两个不同版本的差异，一般是让A和B只有该变量不同，再测试其他人对于A和B的反映差异，再判断A和B的方式何者较佳。

  在同一时间对于目标受众做科学抽样、分组测试以评估效果。因为**时间**也是属于**变量**的一部分，比如说平时和双十一期间，gmv一定是双十一期间来的高。

- **为什么要做A/B测试**

  **A/B测试** 可以帮助业务进行最终决策，并且有充分的数据来支撑你的论点。

  - **风险控制**：小流量实验可以避免直接上线效果不好以造成损失。其次，实验迭代的过程中，决策都是有科学依据的，可以避免系统性的偏差
  - **因果推断**：我们推断 A/B实验 中的优化和改变最终能影响到线上数据以及用户行为。A/B测试 可以帮助证明或者推翻我们的推断
  - **复利效应**：A/B测试 是可以持续不断进行的实验，即使一次实验提升的效果不大，但是长期下来复利效应的积累会产生很大的变化和回报

- **A/B test 流程**

  - 分析现状，建立假设：分析业务，确定最高优先级的改进点，作出假设，提出优化建议。
  - 设定指标：设置主要指标来衡量版本的优劣；设置辅助指标来评估其他影响。
  - 设计与开发：设计优化版本的原型并完成开发。
  - 确定测试时长：确定测试进行的时长。
  - 确定分流方案：确定每个测试版本的分流比例及其他分流细节。
  - 采集并分析数据：收集实验数据，进行有效性和效果判断。
  - 给出结论：①确定发布新版本；②调整分流比例继续测试；③优化迭代方案重新开发，回到步骤1。

- **分流&分层的策略**

  如果流量人群不进行分流和分层，则会导致某一个实验占的流量很多，变相导致另一个实验的流量锐减，从而得到的实验结果会有统计学上的误差。

  - **分流策略**

    - Random-随机分流：
    - Partition By User-按用户切分：
    - Partition By Category-按分类切分：

  - **分流分层规则**

    - 正交与互斥：

      - 正交：每个独立实验为一层，层与层之间是正交的，流量穿越每层实验时，都会被随机打乱，且随机结果离散
      - 互斥：实验在同一层拆分流量，且同一层内不同组的流量是不互相重叠的

    - 分流模型

      域1和域2拆分流量，此时域1和域2是互斥的

      流量经过域2中的B1层、B2层、B3层，B1层、B2层、B3层的流量都是与域2的流量相等。此时B1层、B2层、B3层的流量是正交的。

      流量流过域2中的B1层时，又把B1层分为了B1-1，B1-2，B1-3，此时B1-1，B1-2，B1-3之间又是互斥的

    - 规则使用场景

      比如B1层、B2层、B3层可能分别为：UI层、搜索结果层、广告结果层，这些层基本上是没有任何业务关联的，即使使用相同的流量（流量正交）也不会对实际业务结果造成影响。但是不同层之间所进行的实验相互关联，就会影响下游实验。因此建议同一类型的实验在同一层内进行，并且要考虑不同实验之间相互的依赖

- **其他技术**

  - **p-value**：概率，主要在 A/B测试 中说明实验提升的显著性，并且往往与假设检验相挂钩。

    - p < 0.05：有统计学差异
    - p < 0.01：有显著统计学差异
    - p < 0.001：有极其显著的统计学差异

    在实践中可以先设置空跑期，进行AA test，来检查流量分布是否均匀

  - **假设检验**：是推论统计中用于检验现有数据是否足以支持特定假设的方法。一旦能估计未知参数，就会希望根据结果对未知的真正参数值做出适当的推论。假设检验的步骤如下：

    - 最初研究假设为真相不明
    - 提出相关的零假设和备择假设
    - 考虑检验中对样本做出的统计假设
    - 选择一个显著性水平 α
    - 选择适合的检验统计量 T
    - 在设定零假设为真下推导检验统计量的分布
    - 根据在零假设成立时的检验统计量T分布，找到概率为显著性水平 (α) 的区域，此区域称为“拒绝域”(记作RR或CR)，即在零假设成立的前提下，落在拒绝域的概率只有α。
    - 针对检验统计量T，根据样本计算其估计值t<sub>obs</sub>
    - 若估计值t<sub>obs</sub>未落在拒绝域，则“不拒绝”零假设（do no reject 𝐻<sub>0</sub>）。若估计值t<sub>obs</sub>落在拒绝域，则拒绝零假设，接受备择假设。

## AB实验中常见的问题

### 用户抽样不科学

先来看一组数据

| 学院 | 女生申请数 | 女生录取数 | 女生录取率 | 男生申请数 | 男生录取数 | 男生录取率 | 申请总数 | 录取总数 | 总录取率 |
| ---- | ---------- | ---------- | ---------- | ---------- | ---------- | ---------- | -------- | -------- | -------- |
| 1    | 100        | 49         | 49%        | 20         | 15         | 75%        | 120      | 64       | 53.3%    |
| 2    | 20         | 1          | 5%         | 100        | 10         | 10%        | 120      | 11       | 9.2%     |
| 总计 | 120        | 50         | 42%        | 120        | 25         | 21%        | 240      | 75       | 31.3%    |

单看男生，无论是1号学院还是2号学院，男生录取率都高于女生，因此总体的录取率是不是也是男生高于女生呢？

统计出来并不是，男生的总体录取率要远低于女生，这种现象就被称为辛普森悖论

- **辛普森悖论**：几组不同的数据中均存在一种趋势，但当这些数据组合在一起后，这种趋势消失或反转。其产生的原因主要是数据中存在多个变量。这些变量通常难以识别，被称为“潜伏变量”。潜伏变量可能是由于采样错误造成的。

在 A/B 测试 中，如果实验组和对照组的样本流量分布不一致，就有可能产生辛普森悖论

### 互斥层选择错误

- 互斥层选择原则：
  - 假设实验之间有相关性，那么实验必须置于同一互斥层；
  - 假设实验之间没有相关性，那么实验可以至于不同互斥层

### 不考虑是否显著

只简单地观测实验数据的涨跌，不去考虑实验结果是否显著
