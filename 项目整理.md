# 总览

- 现有召回路（按照订单转化率倒序排序）：
  - TagRecallAnuual：tag年周期召回
  - Repurchase：复购召回
  - TagRecallRepurchase：tag近期复购召回
  - historySearchRecall：历史搜索召回
  - Similar：相似召回**（其点击率较高）**
  - tag：tag实时搜索召回
  - CB：长短期兴趣召回
  - userModelCategory：用户二级品类模型召回
  - hot：热门召回
  - deepWalkRecall：deepwalk召回
  - BoutiqueReplace
  - AdProduct：
  - ItemCF：协同过滤召回
  - ColdStartRecall：冷启动召回
  - StoreOpWindow：
  - Market：

# 一、召回

## 1.1 历史搜索召回

- 项目背景：在推荐的主要场景，新增一路长期搜索召回，以精准命中用户搜索需求，提升推荐GMV和转化率

- 召回思路：

  - 收集近180天用户产生搜索行为后真实曝光数据

  - 根据关键词与商品相关性、用户点击与加购行为、搜索结果页sort计算分数总和排序

    - 计算搜索日期距今天数

    - 并且根据搜索后的行为进行加权。曝光、点击和加购行为赋予不同权重。
      $$
      score=\frac{exp(1) * (1 + log_{10}(1 + pos))}{log_2(diff) + 1 },点击、加购行为
      $$

      $$
      score=\frac{1}{log_2(diff) + 1 }\frac{1}{1 + log_{10}(1 + pos)},曝光行为
      $$

    - 根据item_pos赋予不同权重。如果是点击和加购行为，那么item_pos越靠后，权重越大；如果是曝光行为，那么item_pos越靠后，权重越小

  - 针对每个用户，仅保留同一个tag下分数最高的goodssku，避免同质化

- 线上实验效果

  - **推荐所有**：GMV提升**0.13%**，人均点击卡片数提升**0.64%**，人均加购次数提升**0.27%**，人均点击不同二级品类数提升**0.774%**

  - **首页**：GMV提升**0.53%**，uv购买转化率提升**0.04%**，人均点击卡片数提升**0.65%**，人均加购次数提升**0.37%**，人均点击不同二级品类数提升**0.86%**

  - **分类页推荐**：GMV提升**1.163%**，uv购买转化率降低**0.31%**，人均点击卡片数提升**0.95%**，人均加购次数降低**0.28%**，人均点击不同二级品类数提升**0.88%**

  - **猜你喜欢**：GMV提升**0.77%**，uv购买转化率提升**0.61%**，人均点击卡片数提升**0.91%**，人均加购次数提升**0.72%**，人均点击不同二级品类数提升**1.04%**

## 1.2 tag召回

- 项目背景：用户的搜索行为明确地表达了其购物意图，通过增加对搜索行为数据的召回，可以提升推荐整体的转化效果。
- 召回思路:

  - 对用户在主搜场景下的搜索加购行为进行分析，建立搜索关键词和商品Tag的匹配关系
  - 实时记录用户搜索的关键词，利用匹配关系获取其对应的商品Tag
  - 在线上召回服务中，利用记录的搜索商品Tag，召回在售商品

- 线上实验效果

  - 首页：gmv提升**2.61%**、qty提升**0.85%**、下单人数提升**1.00%**、pv点击率提升**1.13%**、uv点击率提升**1.13%**、pv加购率提升**0.75%**、uv加购率提升**0.96%**、uv购买转化率提升**1.02%**。
  - 分类页tab：gmv提升**2.57%**、qty提升**0.33%**、pv点击率提升**0.80%**、uv点击率提升**1.08%**、pv加购率提升**0.10%**、uv加购率提升**0.50%**、uv购买转化率提升**0.39%**。

  - 猜你喜欢：gmv提升**2.94%**、qty提升**0.40%**、下单人数提升**0.84%**、pv点击率提升**1.47%**、uv点击率提升**1.22%**、pv加购率提升**1.10%**、uv加购率提升**0.95%**、uv购买转化率提升**0.85%**。

  - 全平台：gmv提升**0.61%**、qty提升**0.45%**。

## 1.3 用户二级品类召回

- 项目背景
- 召回思路
- 线上实验效果

## 1.4 tag年周期召回

- 项目背景：在推荐首页瀑布流新增一路tag粒度召回，用于召回当前活跃用户在一年前同起购买记录的同tag商品。

- 召回思路：一年前用户购买过的tag召回

  - 用户与tag关联数据：目标日期天数+3（超参数A），作为基准点，计算基准点一年前的日期，前后15（超参数B）天的用户购买记录，获取用户的购买tag列表

  - 用户过滤：全量用户数据量太大，只取当前日期前推30天（超参数C）活跃的用户过滤，可以覆盖召回目标日期中，一年前有购买记录的用户且在当天活跃的用户比例为94%

  - 运营区域过滤：由于各个区域同一个tag售卖的商品不一样，需要对用户指定售卖区域，过去30天（超参数C）内，用户活跃区域只有一个的占比为93%，取过去用户30天内活跃天数最多的区域作为用户的目标区域

  - tag间排序：根据tag购买记录距离目标日期的时间间隔、购买量、gmv总和排序，得到tag间的排序。
    $$
    score=DiffWeight*DateDiff + GMVWeight*GMV
    $$

  - tag内商品排序：根据tag所属商品的价格，与用户一年前购买的tag内商品的价格差，与商品的cvr、gmv均值联合排序。价格差由商品价格和该tag下商品的平均价格进行计算。

  - 多样性优化：单个二级品类内限制tag数量（超参数D），根据tag间排序截断。限制二级品类最大数量（超参数E），由二级品类内的tag均分

  - 召回上限截断：召回上限为150（超参数F），每一路召回最大100，放宽到150作为商品过滤的buffer，tag间使用z字排序取商品

- 线上实验效果

  - 首页瀑布流：GMV提升**4.081%**，qty提升**2.235%**，uv购买转化率提升**1.982%**，人均加购次数提升**1.457%**
  - 分类页推荐：GMV提升**3.8294%**，qty提升**2.3255%**，uv购买转化率提升**0.8864%**，人均加购次数提升**0.92%**
  - 猜你喜欢：GMV提升**3.318%**，qty提升**1.766%**，uv购买转化率提升**1.035%**，人均加购数提升**0.7666%**
  - 推荐所有：GMV提升**2.6176%**，qty提升**1.3643%**，人均加购次数提升**1.3354%**
  - 平台：GMV提升**0.0078%**，qty提升**0.09%**，uv购买转化率提升**0.136%**
  - 多样性：全平台人均点击二级品类数提升 **1.3589%**

## 1.5 tag近期复购召回

- 项目背景
- 召回思路：用户过去90天（超参数A）tag购买记录，与tag复购周期的匹配
  - 计算复购周期：统计过去一年间tag购买记录的时间周期，过滤异常值，对复购时间进行标准化，左偏高斯分布处理，计算每个时间间隔复购的概率值，总和为1
  - 获取用户与tag的购买时间间隔：获取用户过去90天（超参数A）的购买记录，获取tag最近购买记录与目标天的时间间隔
  - 获取用户的tag复购概率：与第一步的复购周期匹配，获取用户在每个tag上的复购概率，作为tag排序
  - 运营区域过滤：获取用户过去90天（超参数A）所属的运营区域，召回商品与运营区域匹配
  - tag间排序：以复购概率排序
  - tag内商品排序：同一个商品排序最高，其他按照商品价格差、cvr、gmv总和排序
  - 多样性优化与召回上限截断：与年周期召回一致
- 线上实验效果
  - 首页瀑布流：GMV提升**6.198%**，qty提升**4.668%**，uv购买转化率提升**3.155%**，人均加购次数提升**1.699%**
  - 分类页推荐：GMV提升**4.371%**，qty提升**1.447%**，uv购买转化率提升**1.469%**，人均加购次数提升**0.981%**
  - 猜你喜欢：GMV提升**4.893%**，qty提升**4.33%**，uv购买转化率提升**2.821%**，人均加购数提升**2.035%**
  - 推荐所有：GMV提升**4.426%**，qty提升**3.299%**，人均加购次数提升**1.557%**
  - 平台：GMV提升**0.361%**，qty提升**0.318%**，uv购买转化率提升**0.027%**
  - 多样性：推荐所有——核心人均曝光不同二级品类数 **0.487%**，核心人均点击不同二级品类数 **1.119%**，核心曝光二级品类基尼系数 **0.854%**

## 1.6 CB向量召回

- 项目背景：优化原有的召回逻辑

  - 获取用户对二级品类的点击、加购和订单行为，并且为不同的行为进行赋值，点击行为加权为1，加购行为加权为40，订单行为加权为100
  - 计算每个二级品类和全部二级品类的行为值，并且计算TF和IDF
  - 计算用户的总行为值
  - 计算用户的复购行为，若用户离最近一次购买行为的间隔小于对应二级品类的中位数的一半，则过滤
  - 并获取复购的5%分位值以及95%分位值，并且进行归一化
  - 在用户行为的基础上，加上复购信息，并加权为1
  - 每个用户取前30个二级品类进行截断

- 召回思路

  - 正样本采样

    - 用户过滤：过滤不活跃的用户和过于活跃的用户
      - 近1个月加购和订单总数小于N次的用户
      - 近3天点击、加购和订单行为超过M次的用户

    - 二级品类过滤：过滤冷门物品
      - 近1个月订单uv小于 T次 的物品

    - 用户长期行为序列（采样周期为1个月）
      - 加购行为：之前产生过订单行为的二级品类
      - 订单行为：直接加入行为序列

    - 用户短期行为序列（采样周期为3天）
      - 点击行为：按照发生时间顺序，加入行为序列
      - 加购行为：按照发生时间顺序，加入行为序列
      - 订单行为：由event_id关联，且间隔发生时间不超过10min。这是因为用户可能加购完之后继续浏览，浏览完毕后再进行购买，中间可能发生过其他行为。之后再进行订单结算可能只是结算购物车，因此有效行为应该是订单所对应的行为
      - 会话要求：
        - 以一个wechat_session_id作为一次会话，若下一次wechat_session_id与上一次wechat_session_id间隔时间不超过10min，也可将其合并为一次会话
        - 长度限制：短期行为序列长度不超过50
        - 使用三天内最近三次会话的行为序列作为短期行为序列

    - 负样本采样：全局负采样
      - 对长期行为和短期行为分别进行负采样
      - 长期行为：针对订单和加购行为，统计各个二级品类的热度，对热度进行一定打压，并根据概率随机选取负样本
      - 短期行为：同上，只不过针对的行为变为点击、加购和订单行为。

  - 模型：使用的类Transformer架构

    - 由于模型分为长期部分和短期部分，这两个部分走两条不一样的路，因此接下来仅介绍长期部分

    - 输入：长期序列

    - Embedding层：维度为二级品类总数×Embedding维度

    - 序列位置编码：由于用户行为序列顺序也一定程度代表了用户最近的兴趣如何，因此使用类似于sigmoid的函数，对不同位置的行为增加不同的权重
      $$
      pe_i=\frac{0.5}{1 + e^{-slope*(position-(maxLen-1)/2)}}
      $$

    - 掩码：由于不是所有用户都有较多的行为，因此固定长度的序列会有部分为0，即无具体行为，在模型中需要将这部分影响去掉，因此使用了掩码机制

    - Transformer模块：

      - LayerNormlization
      - 多头注意力机制
      - 残差连接
      - 前馈神经网络

  - 损失函数：对比损失函数（InfoNCE）

    - 假设已经有一个编码好的query **q**，以及一系列编码好的样本$k0,k1,k2,...$，那么$k0,k1,k2,...$可以看作是字典中的key。假设字典里只有一个key即 $k+$ 是跟 $q$ 是匹配的，那么$q$跟$k+$就互为正样本对，就需要一个对比学习的损失函数来指导模型进行学习

    - MoCo采用的对比学习损失函数就是InfoNCE loss，以此来训练模型
      $$
      L_q=-log\frac{exp(qk_{+}/T)}{\sum_{i=0}^kexp(qk_{i}/T)}
      $$

    - InfoNCE loss和交叉熵损失有什么关系

      - softmax公式如下
        $$
        \hat{y_+}=softmax(z+)=\frac{exp(z+)}{\sum_{i=0}^kexp(z_i)}
        $$

      - 交叉熵损失函数如下
        $$
        L(\hat{y})=-\sum_{i\in{K}}y_ilog(\hat{y_i})
        $$

      - 在有监督学习下，ground truth是一个one-hot向量，sofmax的结果 $\hat{y_i}$ 取$-log$，再与ground truth相乘之后，即得到如下交叉熵损失
        $$
        -log\frac{exp(z+)}{\sum_{i=0}^kexp(z_i)}
        $$
        这里的 $k$ 在监督学习里指的是这个数据集一共有多少个类别

      - 对于对比学习来说，理论上是可以用上述式子去计算loss，但是实际上行不通

        拿CV领域的ImageNet数据集来举例，该数据集一共有128万张图片，我们使用数据增强手段（例如，随机裁剪、随机颜色失真、随机高斯模糊）来产生对比学习正样本对，每张图片就是单独一类，那 $k$ 就是128万类，而不是1000类了。但是 $softmax$ 操作在如此多类别上进行计算是非常耗时的，再加上有指数运算的操作，当向量的维度是几百万时，计算复杂度太高了，所以对比学习用上式去计算loss是行不通的

      - NCE loss：NCE（noise contrastive estimation）核心思想是将多分类问题转换为二分类问题，一个类是数据类别 data sample，另一个噪声类别 noisy sample，通过学习数据样本和噪声样本之间的区别，将数据样本去和噪声样本做对比，也就是噪声对比（noise contrastive），从而发现数据中的一些特性。但是，如果把整个数据集剩下的数据都当作负样本（即噪声样本），虽然解决了类别多的问题，计算复杂度还是没有降下来，解决办法就是做负样本采样来计算loss，这就是 estimation 的含义，也就是说它只是估计和近似。一般来说，负样本选取的越多，就越接近整个数据集，效果自然会更好。

      - Info NCE loss：Info NCE loss是NCE的一个简单变体，它认为如果你只把问题看作是一个二分类，只有数据样本和噪声样本的话，可能对模型学习不友好，因为很多噪声样本可能本就不是一个类，因此还是把它看成一个多分类问题比较合理（但这里的多分类k指代的是负采样之后负样本的数量，下面会解释）。于是就有了InfoNCE loss，公式如下：
        $$
        L_q=-log\frac{exp(qk_{+}/T)}{\sum_{i=0}^kexp(qk_{i}/T)}
        $$
        上式中，$q⋅k$ 是模型出来的 logits，相当于上文 softmax 公式中的$z$，$τ$ 是一个温度超参数，是个标量，假设我们忽略 $τ$，那么infoNCE loss其实就是cross entropy loss。唯一的区别是，在cross entropy loss里，$k$ 指代的是数据集里类别的数量，而在对比学习InfoNCE loss里，这个 $k$ 指代的是负样本的数量。上式分母中的sum是在1个正样本和k个负样本上做的，从0到$k$，所以共 $k+1$ 个样本，也就是字典里所有的key。恺明大佬在MoCo里提到，InfoNCE loss其实就是一个cross entropy loss，做的是一个 $k+1$ 类的分类任务，目的就是想把 $q$ 这个图片分到 $k+$ 这个类。

    - 温度系数的作用：上式Info NCE loss中的q⋅k相当于是logits，温度系数可以用来控制logits的分布形状。对于既定的logits分布的形状，当 $τ$ 值变大，则$1/τ$就变小，$q⋅k/τ$ 则会使得原来 logits 分布里的数值都变小，且经过指数运算之后，就变得更小了，导致原来的logits分布变得更平滑。相反，如果 $τ$ 取得值小，$1/τ$ 就变大，原来的logits分布里的数值就相应的变大，经过指数运算之后，就变得更大，使得这个分布变得更集中，更peak。

      如果温度系数设的越大，logits分布变得越平滑，那么对比损失会对所有的负样本一视同仁，导致模型学习没有轻重。如果温度系数设的过小，则模型会越关注特别困难的负样本，但其实那些负样本很可能是潜在的正样本，这样会导致模型很难收敛或者泛化能力差。

      总之，温度系数的作用就是它控制了模型对负样本的区分度

  - 评价指标：

    - MRR（平均倒数排名）：
      $$
      MRR=\frac{1}{Q}\sum_{i=1}^{|Q|}\frac{1}{rank_i}
      $$
      其中，$|Q|$ 是用户的个数，$rank_i$ 是对于第 $i$ 个用户，推荐列表中第一个在 ground-truth 结果中的 item 所在的排列位置

      这一个指标主要是为了评判预测结果是否名列前茅

    - Similarity：计算 $topk$ 结果与用户行为序列中所有 item 的相似度，使用点积进行计算。

      这一个指标主要是为了评判 topK 的预测结果是否所有都有一定的可行度

- 线上实验效果

  - 首页瀑布流：GMV提升**1.48%**，qty提升**0.6%**，订单人数提升**1.04%**，人均加购次数提升**0.8%**，uv购买转化率提升**1.06%**

  - 分类页推荐：GMV降低**0.26%**，qty提升**0.74%**，订单人数降低**0.01%**，人均加购次数提升**0.74%**，uv购买转化率提升**0.264%**
  - 猜你喜欢：GMV提升**0.8%**，qty提升**0.32%**，订单人数提升**0.46%**，人均加购次数提升**0.48%**，uv购买转化率提升**0.54%**
  - 推荐所有：GMV提升**0.84%**，qty提升**0.84%**，人均加购次数提升**0.8%**
  - 平台：GMV降低**0.03%**，qty提升**0.10%**，uv购买转化率提升**0.15%**


# 二、粗排





# 三、线上服务







# 四、数据

## 4.1 实验相关

- 实验主要场景
  - 新版首页
  - 分类页推荐
  - 猜你喜欢（包括新老购物车页、个人中心、商品详情页、支付成功页）
  - 平台
  - 推荐所有（包括首页、分类页推荐、猜你喜欢）
  - 相似商品
  - 商详页搭配一起买
  - 分享落地页
  - 凑单推荐
- 相关指标
  - GMV：商品销售总额
  - qty：商品份数
  - 订单人数：order_uv
  - 子订单数：sub_order
  - 订单数：order
  - uv购买转化率：
  - 单价gmv
  - 人均点击次数
  - 人均不去重点击次数
  - 人均加购次数
  - 人均不去重加购次数
  - 人均点击加购次数
  - 人均不去重点击加购次数
  - 客单价
  - 核心人均曝光卡片数
  - 核心人均曝光不同skusn数
  - 核心人均曝光不同二级品类数
  - 核心曝光skusn商品基尼系数
  - 核心曝光二级品类基尼系数：
    - 基尼系数：国际上通用的，用以衡量一个国家或地区居民收入差距的常用指标。基尼系数介于0-1之间，基尼系数越大，表示不平等程度越高
    - 计算方式：A / (A+B)
    - 推广：按照类目的**流行度（曝光次数）**从大到小排序后进行统计后进行洛伦茨曲线的绘制。基尼系数越大代表所有类目的分布越不均匀，系数越小代表类目分布越均匀。
  - 核心人均点击卡片数
  - 核心人均点击不同skusn数
  - 核心人均加购数
  - 核心人均点击不同二级品类数
  - 曝光pv
  - 曝光uv
  - 点击pv
  - 点击uv
  - 加购pv
  - 加购uv
  - pv点击率
  - uv点击率
  - pv加购率
  - uv加购率
  - 平均曝光位置
  - 平均点击位置
  - 平均加购位置
