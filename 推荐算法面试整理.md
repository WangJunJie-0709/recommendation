[TOC]

# 机器学习算法

## 逻辑斯蒂回归（Logistic Regression，LR）



## 协同过滤

### 1 目标场景

存在共现矩阵的情况下，进行点击率预估、评分预测等等

### 2 基本思想

物以类聚，人以群分。

### 3 相似度计算方式

- 杰卡德（Jaccard）相似度

  这个是**衡量两个集合的相似度的一种指标**。两个集合A和B的交集元素在A，B的并集中所占的比例，称为两个集合的杰卡德相似系数
  $$
  J(A,B)=\frac{|A\cap{B}|}{|A\cup{B}|}
  $$

- 余弦相似度

  衡量了用户向量之间向量夹角的大小，夹角越小，说明相似度越大，两个用户越相似
  $$
  sim(i,j)=cos(i,j)=\frac{i·j}{||i||·||j||}
  $$
  **局限性：**对于评分数据不规范的时候，存在有的用户喜欢打高分，有的用户喜欢打低分情况的时候，有的用户喜欢乱打分的情况，这时候余弦相似度算出来的结果可能就不是那么准确了。

- 皮尔逊相关系数

  皮尔逊相关系数通过使用用户平均分对个体独立评分进行修正，减少了用户评分偏置的影响
  $$
  sim(i,j)=\frac{\sum_{p\in{P}}(R_{i,p}-\overline{R_i})(R_{jp}-\overline{R_j})}{\sqrt{\sum_{p\in{P}}(R_{i,p}-\overline{R_i})^2}\sqrt{\sum_{p\in{P}}(R_{jp}-\overline{R_j})^2}}
  $$

- 其他

- 余弦相似度VS欧式距离

### 4 基于User的协同过滤 UserCF

- 步骤：

  - 计算用户A与其他用户的相似度

  - 根据相似度用户计算用户A对物品的最终评分
    $$
    R_{u,p}=\frac{\sum_{s\in{S}}(w_{u,s}R_{s,p})}{\sum_{s\in{S}}w_{u,s}}
    $$

  - 根据用户评分对用户进行推荐：定一个阈值，预测评分超过阈值即可推荐给用户

- 缺点：

  - 数据稀疏性：

    一个大型的电子商务推荐系统一般有非常多的物品，用户可能买的其中不到1%的物品，不同用户之间买的物品重叠性较低，导致算法无法找到一个用户的邻居，即偏好相似的用户，即使找到准确性也不会太高。这导致UserCF不适用于那些正反馈获取较困难的应用场景

  - 用户相似度矩阵维护难度大：

    绝大多数产品的用户数都要远大于物品数，因此维护用户相似度矩阵的难度要大得多；用户相似度矩阵的存储空间随着用户数量的增加而增加，不适合用户数据量大的情况的使用。

- 适用场景：常适用于用户少，物品多，时效性较强的场合

### 5 基于Item的协同过滤 ItemCF

- 步骤：
  - 首先计算待选物品和其他物品的相似度
  - 找出与待选物品最相似的n个物品
  - 根据用户对这n个物品的打分去计算对待选物品的打分情况
- 优点：
  - ItemCF算法的预测结果比UserCF算法质量要高一些
  - 由于ItemCF算法可以预先计算好物品的相似度，所以在线的预测性能要比UserCF算法高
- 缺点：
  - 数据稀疏性
  - 物品相似度矩阵维护难度大
- 适用场景：

### 6 UserCF和ItemCF的优缺点对比

- 区别 

  ![image-20220405163844329](F:\面试\推荐算法\图片\UserCF和ItemCF区别.png)

- 共同的缺点

  - 不能彻底解决数据稀疏性问题
  - 泛化能力弱
    - 热门物品具有很强的头部效应，容易跟大量物品产生相似，而尾部物品由于特征向量稀疏，导致很少被推荐
    - 为解决这一问题，矩阵分解技术被提出
  - 无法利用更多的信息：**一般是仅仅基于用户的行为数据**，而不依赖于任何附加信息或者用户的任何附加信息，比如不依赖物品自身特征、用户性别、年龄等

### 7 协同过滤算法的优缺点

- 优点：
  - 算法原理朴素简单，即"物以类聚，人以群分"，已得到工业界验证过的一类重要算法，在大型互联网公司都有很好的落地和应用
  - 易使用Spark分布平台来实现，因此可以通过增加计算节点很容易处理大规模数据集。
  - 可以很好的为用户推荐多样性、新颖性的item，特别是当群体规模越大、用户行为越多，推荐的效果越好
  - 只依赖用户的操作行为，不依赖具体user相关和item相关的信息就可以实现
- 缺点：
  - 冷启动问题：如果用户行为少，这时就很难发挥协同过滤算法的优势和价值，甚至无法为用户做推荐
  - 稀疏性问题：互联网产品用户基数大，item数量多，一般用户只对很少量的item产生操作行为，这时用户操作行为矩阵是非常稀疏的，太稀疏的行为矩阵计算出的item相似度往往不够精准，最终影响推荐结果的精确度。

## 矩阵分解（Matrix Factorization，MF）

矩阵分解也叫做隐语义模型
$$
p(u,i)=p^T_uq_i=\sum_{f=1}^{F}{p_{uf}q_{if}}
$$

- LFM的损失函数：未正则化和正则化

$$
loss=\sum(p(u,i)-p^{LFM}(u,i))^2
$$

$$
loss=\sum(p(u,i)-p^{LFM}(u,i))^2+\alpha|p_u|^2+\alpha|q_i|^2
$$

- LFM算法迭代，对其求偏导
  $$
  \frac{\partial{loss}}{\partial{p_{uf}}} = -2(p(u,i)-p^{LFM}(u,i))q_{if}+2\partial{p_{uf}}
  $$

  $$
  \frac{\partial{loss}}{\partial{q_{if}}} = -2(p(u,i)-p^{LFM}(u,i))p_{uf}+2\partial{q_{if}}
  $$

- 梯度下降
  $$
  p_{uf}=p_{uf} - \beta\frac{\partial{loss}}{\partial{p_{uf}}}
  $$

  $$
  q_{if}=q_{if} - \beta\frac{\partial{loss}}{\partial{q_{if}}}
  $$

- 影响训练效果的因素

  - 负样本的选取
  - 隐特征F，正则化参数，learning rate

- LFM vs CF

  - LFM是属于监督学习的分支，通过训练样本的label设定损失函数，利用最优化方法来使得损失函数最小化，从而得到最优模型；CF是通过公式建模求解相似度矩阵
  - LFM空间复杂度为O(max(M×F，N×F))，CF的空间复杂度为O(M<sup>2</sup>)或O(N<sup>2</sup>)，离线计算LFM较快
  - CF可较好地实时计算，LFM响应不及时，实时计算CF较快

## 因子分解机（Factorization Machine，FM）

- 针对问题

  - 旨在解决稀疏数据下的特征组合问题

  - 在面对稀疏特征向量时，Poly2特征交叉项无法收敛
    $$
    y(x)=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^n\sum_{j=i+1}^nw_{ij}x_ix_j
    $$
    多项式模型是包含特征组合的最直观的模型，当x<sub>i</sub> 和 x<sub>j</sub> 都非零时，组合特征才有意义。组合特征的参数一共有n(n-1)/2个，任意两个参数都是独立的。然而在数据稀疏性普遍存在的实际应用场景中，二次项参数的训练是很困难的。其原因是每个参数的训练都需要大量非零的样本，这部分样本非常少，容易导致参数不准确，严重影响模型性能

  - **Poly2 **计算复杂度过高

- 改进思路：当 k 足够大的时候，对于**任意对称正定的实矩阵W**，均存在实矩阵V，使得 W = V·V<sup>T</sup>

- 数学模型，隐向量长度 k << n
  $$
  y=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n-1}\sum_{j=i+1}^n<v_i,v_j>x_ix_j,<v_i,v_j>=\sum_{f=1}^kv_{i,f}v_{j,f}
  $$

  - 参考$ab + ac +bc = \frac{1}{2}[(a+b+c)^2 - (a^2 + b^2 + c^2)]$    所以得出
    $$
    \begin{align*}
        &\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}<v_i,v_j>x_ix_j \\
        &= \frac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{n}<v_i,v_j>x_ix_j - \frac{1}{2}\sum_{i=1}^{n}<v_i,v_i>x_ix_i & (1)\\
        &= \frac{1}{2} ( \sum_{i=1}^{n}\sum_{j=1}^n\sum_{f=1}^{k}v_{i,f}\,v_{j,f}x_ix_j - \frac{1}{2}\sum_{i=1}^{n}\sum_{f=1}^{k}v_{i,f}\,v_{i,f}x_ix_i )  & (2)\\
        &= \frac{1}{2}\sum_{f=1}^{k}(\sum_{i=1}^{n}v_{i,f}x_i · \sum_{j=1}^{n}v_{j,f}x_j - \ \sum_{i=1}^{n}v_{i,f}^2x_i^2) & (3)\\
        &= \frac{1}{2}\sum_{f=1}^{k}[(\sum_{i=1}^{n}v_{i,f}x_i)^2 -  \sum_{i=1}^{n}v_{i,f}^2x_i^2 ] & (4)
    \end{align*}
    $$

  - 第1个等号：对称矩阵 $w_{ij}$对角线上半部分；

  - 第2个等号：把向量内积 $<v_i,v_i>$ 展开成累加和的形式；

  - 第3个等号：提出公共部分；

  - 第4个等号： $i$ 和 $j$  相当于是一样的，表示成平方过程。

- 损失函数
  $$
  J(w_0,w_1,w_2,...,w_n,w_{12},w_{13},...,w_{n-1,n})=-\frac{1}{m}\sum_{i=1}^my^{(i)}logy^{(i)}_{pre}+(1-y^{(i)})log(1-y^{(i)}_{pre})
  $$

- 梯度下降
  $$
  y=w_0+\sum_{i=1}^nw_ix_i+\frac{1}{2}\sum_{f=1}^k[(\sum_{i=1}^nv_{i,f}x_i)^2-\sum_{i=1}^n(v_{i,f}x_i)^2]
  $$

- 优点

  - 极大降低了训练开销 O(n<sup>2</sup>)->O(kn)
  - **隐向量的引入**，使得FM能更好解决数据稀疏性的问题：
    - 这里可以观察到，**交叉项的权重是两个矩阵的点乘而不直接是一个权重矩阵**，这是因为类型变量经过One-Hot或其他类似形式的编码后，会产生高维稀疏矩阵，导致有的交叉项在训练样本中从未出现过，如直接是一个权重矩阵则权重为0，训练不出相关信息。因而相当于是通过矩阵分解的形式，将原本的权重矩阵表示为两个矩阵相乘。这样，即使交叉项为0还是可以得到相关权重，以此解决高维稀疏矩阵的问题。
  - **FM模型是利用两个特征的Embedding做内积得到二阶特征交叉的权重**，那么我们可以将训练好的FM特征取出离线存好，之后用来做其他扩展

- 与其他模型的对比

  - 相比于SVM的二阶多项式核而言，FM在样本稀疏的情况下是有优势的；而且，FM的训练/预测复杂度是线性的，而二阶多项式核SVM需要计算核矩阵，核矩阵复杂度是 N<sup>2</sup> 

  - 相比于MF而言，我们把MF中每一项的rating分改写为 
    $$
    r_{ui}=\beta_u+\gamma_i+x_u^Ty_i
    $$
    从上述公式可以看出，这相当于只有两类特征 u 和 i 的FM模型。对于 FM 而言，我们可以加任意多的特征，比如 user 的历史购买平均值，item 的历史购买平均值等。但是MF只能局限在两类特征。在特征的扩展性上不如 FM

- FM模型做统一的召回模型
  - 统一召回
    - 优点：无论候选 Item 来自于哪里，它们在召回阶段的得分是完全可比的
    - 缺点：将多个白箱变成了一个黑箱子，使得召回路变得不可解释了。
  - 多路召回
    - 优点：有可解释性，更加灵活。
    - 缺点：每一路召回因为采取的策略或者模型不同，所以各自的召回模型得分不可比较。比如利用协同过滤召回找到的候选Item得分，与基于兴趣标签这一路召回找到的候选Ite得分，完全是不可比较的。

## FM引入特征域（Field-ware Factorization Machines，FFM）

相比于FM，FFM模型引入了特征域的概念，其数学形式的二阶部分如下
$$
FM(w,x)=\sum_{j_1=1}^n\sum_{j_2=j_1+1}^n(w_{j_1f_2}w_{j_2f_1})x_{j_1}x_{j_2}
$$
FFM 将相同性质的特征都归于同一个 field。简单来说，同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个field，包括用户性别、职业、品类偏好等。

其与FM的区别在于隐向量由原来的 w<sub>j1</sub> 变成了 w<sub>j1f2</sub>，这意味着每个特征对应的不是唯一一个隐向量，而是一组隐向量。当 x<sub>j1</sub> 特征与 x<sub>j2 </sub>特征进行交叉时， x<sub>j1</sub> 会从 x<sub>j1</sub> 的这一组隐向量中挑出与 x<sub>j2 </sub>的域对应的隐向量 w<sub>j1f2</sub> 进行交叉。

假设样本的 n 个特征属于 f 个field，那么FFM的二次项有 nf 个隐向量。而在FM模型中，每一维特征的隐向量只有一个。FM可以看作FFM的特例，就是把所有特征都归属到一个field的FFM模型。

如果隐向量的长度为k，那么FFM的二次参数有 nfk 个，远多于FM模型的 nk 个。此外，由于隐向量与field相关，FFM二次项并不能化简，预测复杂度为 O(kn<sup>2</sup>)

- FFM的SGD优化过程。算法输入 tr、va、pa分别是训练样本集、验证样本集和训练参数设置

  - 根据样本特征数量（tr.n）、field的个数（tr.m）和训练参数（pa），生成初始化模型，即随机生成模型的参数；

  - 如果归一化参数pa.norm为真，计算训练和验证样本的归一化系数，样本 i 的归一化系数为
    $$
    R[i]=\frac{1}{||X[i]||}
    $$

  - 对每一轮迭代，随机打乱训练样本的顺序

  - 对每一个训练样本，执行如下操作

    - 计算每一个样本的FFM项
    - 计算每一个样本的训练误差
    - 利用单个样本的损失函数计算梯度，再根据梯度更新模型参数

  - 对每一个验证样本，计算样本的FFM输出，计算验证误差

  - 重复步骤3~5，直到迭代结束或验证误差达到最小



# 深度学习

## DeepFM



## Wide&Deep

### wide&deep动机

- LR（**Memorization**）：线性模型，具有较强的记忆性
  - 前深度学习 主要是使用 LR模型，通过大量的精细特征工程，利用其较强记性挖掘信息，保证预测结果的准确性。但是会导致用户兴趣收敛，无新鲜感，不利于长久的用户留存
  - 缺点：
    - 此种方式非常依赖人工经验挖掘数据中的特征交互模式。
    - 线性模型特征与特征之间在模型中是独立的，对于训练中未出现过的数据或模式，模型无法学习对应的参数，从而使模型对这些数据的预估能力弱。

- DNN（**generalization**）：借助embedding化实现参数空间的共享，即使对于未见过的数据，也具有一定的预估能力。
  - DNN引入embedding，模型通过MLP结构对特征进行复杂、间接和高阶的隐式交叉学习，挖掘隐藏在数据间潜在关联模式，使模型有能力处理未见过的数据或模式。相比传统机器学习模型，具有更好的泛化性。有利于推荐效果中的新颖性这个维度，即对于数据中未出现的模式，模型也能做出相应的合理反应。
  - 缺点：
    - 隐式学习特征交叉相比于人工显式特征交叉，挖掘数据中的已有模式的难度增加，导致模型的记忆性减弱，不利于推荐的准确性。
    - 对于某些特定的场景(数据分布长尾， 共现矩阵稀疏高秩）很难有效学习低纬度的表示， 造成推荐的过渡泛化。
    - DNN结构的效果相比于传统的机器学习模型，没有明显的优势，这与推荐场景中特征的高维稀疏性有关。
- wide&deep
  - wide&deep模型的整体框架设计思路清晰简洁，就是在DNN结构的基础上融合了LR结构，加强了模型处理高维稀疏特征的能力, 使模型兼具泛化性和记忆性，效果得到提升，也使得深度模型在推荐领域开始普及。

### widedeep模型架构

- input：
  - x_wide：
    - 包含**原始特征**和转换的**共现组合特征**（corss-product特征）
    - Linear Model采用的是 FTRL 模型，让Wide部分变得更加的稀疏，即Wide部分的大部分参数都为0，压缩了模型权重及特征向量的维度。Wide部分模型训练完之后留下来的特征都是非常重要的，那么模型的“记忆能力”就可以理解为发现"直接的"，“暴力的”，“显然的”关联规则的能力
  - x_deep：通过embedding的方式将categorical/id特征映射成稠密向量，让DNN学习到这些特征之间的**深层交叉**，以增强扩展能力
- hidden：全连接网络，一般为3层
  - wide侧使用FTRL
    - 为什么使用ftrl
      - Wide部分采用了两个id类特征(当前曝光app和用户安装app)的乘积，两个id类特征向量进行组合，在维度爆炸的同时，会让原本已经非常稀疏的multihot特征向量，变得更加稀疏。wide部分的权重数量其实是海量的。为了不把数量如此之巨的权重都搬到线上进行model serving，采用FTRL过滤掉哪些稀疏特征无疑是非常好的工程经验。
      - FTRL是一个**稀疏性很好**，**精度又不错**的**随机梯度下降方法**。由于是随机梯度下降，当然可以做到来一个样本就训练一次，进而实现模型的在线更新。
      - L1正则化，**FTRL with L1非常注重模型的稀疏性。这也就是问题的答案，W&D采用L1 FTRL是想让Wide部分变得更加稀疏。**压缩模型权重，也压缩了特征向量的维度。
  - deep侧为DNN，
    - DNN模型，输入的特征主要分为两大类，一类是数值特征(可直接输入DNN)，一类是类别特征(需要经过Embedding之后才能输入到DNN中)，Deep部分的数学形式如下： $$ a^{(l+1)} = f(W^{l}a^{(l)} + b^{l}) $$ 
    - 激活函数为Relu
- output：W&D模型是将两部分输出的结果结合起来联合训练，将deep和wide部分的输出重新使用一个逻辑回归模型做最终的预测，输出概率值。联合训练的数学形式如下：需要注意的是，因为Wide侧的数据是高维稀疏的，所以作者使用了 FTRL算法优化，而Deep侧使用的是 Adagrad。 $$ P(Y=1|x)=\delta(w_{wide}^T[x,\phi(x)] + w_{deep}^T a^{(lf)} + b) $$，对wide侧以及deep侧进行相加
  - 论文中wide侧和deep侧的输出维度都为1

![](Img/widedeep模型框架.png)

### 问题

- 为什么DNN加上lr能够起到好的效果

  - 模型的Wide部分增强了模型的记忆能力，弥补了DNN结构泛化性强而记忆性弱的不足。
  - Wide侧输入手动交叉的特征项，模型可以直接从人工经验中获取显式的关联模式，降低了学习难度。也可以理解为模型腾出了原本挖掘这部分模式的精力，去挖掘其它间接的复杂的模式，也可以理解为模型在学习这些输入的已知模式时，有了更多的信息，可以避开一些坑，减小模型掉入坑里的概率，增大模型接近最优解的可能。

- W&D模型中Wide侧和Deep侧的优化器有区别吗，为什么要区别对待，为什么会选择 AdaGrad 和 FTRL优化器。

  - 有区别：选择不同的优化器是因为Wide侧和Deep侧在模型中的作用不同，需要不同的优化策略来达到最佳的训练效果。AdaGrad和FTRL优化器的使用，使得W&D模型能够充分利用各自的优点，实现在训练过程中的稳定性和高效性。
  - Wide侧主要负责记忆，采用的是线性模型，由于线性模型之间特征是相互独立的，其可以通过学习历史数据中的高频模式来筛选出有价值的特征和特征组合。来增强其记忆性，保证搜索结果的准确性。
    - Wide侧的输入包含原始输入和原始输入的特征组合，这些组合特征是高维且稀疏的，为了处理稀疏特征，Wide侧使用的是FTRL优化器。可以让Wide部分变得更加的稀疏，也就是Wide部分的大部分参数都为0，大大压缩了模型权重及特征向量的维度，让模型更高效的去学习有价值的、显而易见的特征及特征组合，进一步增强模型的记忆能力。而且FTRL模型本身特别适合在线学习和大规模稀疏特征，能够实现较为准确的参数更新，同时考虑了正则化项，有助于防止模型过拟合，提高泛化能力。

  - Deep侧则主要用于扩展，引入embedding，模型通过MLP结构对特征进行间接和高阶的隐式交叉学习实现参数共享，并挖掘隐藏在数据间潜在关联模式，使模型有能力处理未见过的数据或模式。相比传统机器学习模型，具有更好的泛化性。有利于推荐效果中的新颖性这个维度，即对于数据中未出现的模式，模型也能做出相应的合理反应。
    - 对于深度学习模型，不同层或神经元可能需要不同的学习速率，因此Deep侧使用AdaGrad优化器。AdaGrad能够自适应地调整学习率，使得训练过程更加稳定，同时加快模型收敛速度。

- wide侧适合输入哪些特征：

  - Wide侧没有发现新的模式，只是学习到这些模式之间的权重，做一些模式的筛选。因此我们需要**根据人工经验、业务背景，将我们认为有价值的、显而易见的特征及特征组合，喂入Wide侧**

- 如何理解Wide部分有利于增强模型的“记忆能力”，Deep部分有利于增强模型的“泛化能力”？

  - Wide部分是一个广义的线性模型，输入的特征主要有两部分组成，一部分是原始的部分特征，另一部分是原始特征的交叉特征(cross-product transformation)，对于交互特征可以定义为： $$ \phi_{k}(x)=\prod_{i=1}^d x_i^{c_{ki}}, c_{ki}\in {0,1} $$ 是一个布尔变量，当第i个特征属于第k个特征组合时，$c_{ki}$的值为1，否则为0，$x_i$是第i个特征的值，大体意思就是两个特征都同时为1这个新的特征才能为1，否则就是0，说白了就是一个特征组合。用原论文的例子举例：

    > AND(user_installed_app=QQ, impression_app=WeChat)，当特征user_installed_app=QQ,和特征impression_app=WeChat取值都为1的时候，组合特征AND(user_installed_app=QQ, impression_app=WeChat)的取值才为1，否则为0。

    对于 Wide部分训练时候使用的优化器是带 $L_1$正则的FTRL算法(Follow-the-regularized-leader)，而L1 FTRL是非常注重模型稀疏性质的，也就是说W&D模型采用L1 FTRL是想让 Wide部分变得更加的稀疏，即 Wide部分的大部分参数都为0，这就大大压缩了模型权重及特征向量的维度。**Wide部分模型训练完之后留下来的特征都是非常重要的，那么模型的“记忆能力”就可以理解为发现"直接的"，“暴力的”，“显然的”关联规则的能力。**例如Google W&D期望 Wide部分发现这样的规则：**用户安装了应用A，此时曝光应用B，用户安装应用B的概率大。**

  - **Deep部分泛化能力**：它把能想到的所有特征扔进这个黑盒去做函数的拟合，显然这样的过程会“模糊”一些直接的因果关系，泛化成一些间接的，可能的相关性。**我们知道DNN模型随着层数的增加，中间的特征就越抽象，也就提高了模型的泛化能力。**对于 Deep部分的DNN模型作者使用了深度学习常用的优化器AdaGrad，这也是为了使得模型可以得到更精确的解。

- **为什么Deep部分不特别考虑稀疏性的问题？**

  Deep部分-**Age、App Installs等数值类特征、Embedding向量等特征**。Deep部分**不存在严重的特征稀疏问题**，自然可以使用精度更好，更适用于深度学习训练的AdaGrad去训练。

### 重点

- **记忆能力、为什么使用 FTRL**
  - Wide侧的输入包含原始输入和原始输入的特征组合，这些组合特征是高维且稀疏的，为了处理稀疏特征，Wide侧使用的是FTRL优化器。可以让Wide部分变得更加的稀疏，也就是 Wide部分的大部分参数都为0，大大压缩了模型权重及特征向量的维度，让模型更高效的去学习有价值的、显而易见的特征及特征组合，进一步增强模型的记忆能力。而且FTRL模型本身特别适合在线学习和大规模稀疏特征，能够实现较为准确的参数更新，同时考虑了正则化项，有助于防止模型过拟合，提高泛化能力。
  - 也可以理解为 Wide侧输入手动交叉的特征项，模型可以直接从人工经验中获取显式的关联模式，降低了学习难度。模型腾出了原本挖掘这部分模式的精力，去挖掘其它间接的复杂的模式，也可以理解为模型在学习这些输入的已知模式时，有了更多的信息，可以避开一些坑，减小模型掉入坑里的概率，增大模型接近最优解的可能。

- **Deep部分泛化能力**、为什么使用AdaGrad、有什么缺点
  - Deep侧主要用于扩展，引入embedding，模型通过MLP结构对特征进行间接和高阶的隐式交叉学习实现参数共享，并挖掘隐藏在数据间潜在关联模式，使模型有能力处理未见过的数据或模式。相比传统机器学习模型，具有更好的泛化性。有利于推荐效果中的新颖性这个维度，即对于数据中未出现的模式，模型也能做出相应的合理反应。
  - Deep部分**不存在严重的特征稀疏问题**，且对于深度学习模型，不同层或神经元可能需要不同的学习速率，因此 Deep侧使用AdaGrad优化器。AdaGrad能够自适应地调整学习率，使得训练过程更加稳定，同时加快模型收敛速度，使得模型可以得到更精确的解。
  - 缺点
    - 隐式学习特征交叉相比于人工显式特征交叉，挖掘数据中的已有模式的难度增加，导致模型的记忆性减弱，不利于推荐的准确性。
    - 对于某些特定的场景(数据分布长尾， 共现矩阵稀疏高秩）很难有效学习低纬度的表示， 造成推荐的过度泛化。

## DIN(Deep Interest Network)

### 简介

- **内容**：DIN（[Deep Interest Network for Click-Through Rate Prediction](https://arxiv.org/abs/1706.06978#)）是2018年阿里提出来的模型，是阿里妈妈精准定向检索及基础算法团队在2017年6月提出的。其针对电子商务领域（e-commerce industry）的CTR预估，重点在于充分利用/挖掘用户历史行为数据中的信息。通过引入attention机制，针对不同的广告构造不同的用户抽象表示（考虑不同的候选（**广告**）和用户历史行为的相关性），从而实现了在数据维度一定的情况下，更精准地捕捉用户当前的兴趣。

- **核心思想**：

  - 用户的兴趣是多元化的（**diversity**）
  - 并且对于特定的广告，用户不同的兴趣会产生不同的影响（**local activation**）

- **背景**：

  - Embedding&MLP 模型表示**用户的兴趣多样性有限制**，将用户行为序列编码成一个固定长的向量来表示用户兴趣，就是大量稀疏特征先经过 embedding层， 转成低维稠密的，然后进行 concat保留所有信息、或使用常用 pooling的方式压缩 embedding表示，但是会造成一定的信息丢失。而且这两种方式embedding向量的权重都是相同的。

  - Embedding&MLP 模型没有考虑用户与广告之间的关系，也就**无法表达用户广泛的兴趣**， 比如对于同一个用户, 如果候选广告 （Candidate Ad） 发生了变化, 用户的兴趣却依然是同一个向量来表达，根本没有考虑之前用户历史行为商品具体是什么, 究竟用户历史行为中的哪个会对当前的点击预测带来积极的作用。 这限制了模型的表达能力, 毕竟用户的兴趣是多样的。

  - 不必将某个用户所有的兴趣（用户的历史购买记录）全部压缩到向量中，因为只有用户部分的兴趣会影响当前行为（对候选广告点击或不点击），王喆老师举了个例子

    ```text
    假设广告中的商品是键盘，如果用户历史点击的商品中有化妆品，包包，衣服，洗面奶等商品，那么大概率上该用户可能是对键盘不感兴趣的，而如果用户历史行为中的商品有鼠标，电脑，iPad，手机等， 那么大概率该用户对键盘是感兴趣的， 而如果用户历史商品中有鼠标，化妆品，T-shirt和洗面奶， 鼠标这个商品embedding对预测“键盘”广告的点击率的重要程度应该大于后面的那三个。
    ```

- **动机**：

  - 在业务的角度，我们应该怎样自适应的去捕捉用户的兴趣变化，较为准确的实施广告推荐；而放到模型的角度， 我们应该**考虑到用户的历史行为商品与当前商品广告的一个关联性**，如果用户历史商品中很多与当前商品关联，那么说明该商品可能符合用户的品味，就把该广告推荐给他。而一谈到关联性的话， 我们就容易想到“注意力”的思想了， 所以为了更好的从用户的历史行为中学习到与当前商品广告的关联性，学习到用户的兴趣变化， 作者把注意力引入到了模型，设计了一个"local activation unit"结构，利用候选商品和历史问题商品之间的相关性计算出权重，这个就代表了对于当前商品广告的预测，用户历史行为的各个商品的重要程度大小， 而加入了注意力权重的深度学习网络

- **创新**：

  - **前提**：这个模型的使用场景是**非常注重用户的历史行为特征（历史购买过的商品或者类别信息）**

  - **针对Diversity：** 针对用户广泛的兴趣，DIN用 **an interest distribution** 去表示，即用 Pooling（weighted sum）对Diversity建模（对用户多种多样的兴趣建模）。
  - 针对**Local Activation**
    - 所以 DIN 稍加改进，利用 attention机制实现 Local Activation，从用户历史行为中动态学习用户兴趣的embedding向量，针对不同的广告构造不同的用户抽象表示，从而实现了在数据维度一定的情况下，更精准地捕捉用户当前的兴趣。
    - 对用户历史行为进行了不同的加权处理，针对不同的广告，不同的 behavior id 赋予不同的权重，这个权重是由当前behavior id和候选广告共同决定的，这就是Attention机制。即针对当前候选Ad，去局部的激活（*Local Activate*）相关的历史兴趣信息。
    - 与当前候选广告相关性越高的历史行为，会获得越高的 **attention score**，从而会主导这一次预测。
  - CTR中**特征稀疏而且维度高**，通常利用 L1、L2、Dropout 等手段防止过拟合。由于传统L2正则计算的是全部参数，CTR预估场景的模型参数往往数以亿计。DIN 提出了一种正则化方法，在每次小批量迭代中，给与不同频次的特征不同的正则权重；
  - 由于传统的**激活函数**，如Relu在输入小于0时输出为0，将导致许多网络节点的迭代速度变慢。PRelu虽然加快了迭代速度，但是其分割点默认为0，实际上分割点应该由数据决定。因此，DIN提出了一种数据动态自适应激活函数Dice。
  - **针对大规模稀疏数据的模型训练：**当DNN深度比较深（参数非常多），输入又非常稀疏的时候，很容易过拟合。DIN提出**Adaptive regularizaion**来防止过拟合，效果显著。

### 模型结构及原理

- 特征表示

  - 工业上的CTR预测数据集一般都是`multi-group categorial form`的形式，就是类别型特征最为常见，这种数据集一般长这样：

    <div align=center>
    <img src="https://img-blog.csdnimg.cn/20210118190044920.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" style="zoom: 67%;" />
    </div>

  - 框出来的那个特征，这个包含着丰富的用户兴趣信息对于特征编码，作者这里举了个例子：`[weekday=Friday, gender=Female, visited_cate_ids={Bag,Book}, ad_cate_id=Book]`， 这种情况我们知道一般是通过one-hot的形式对其编码， 转成系数的二值特征的形式。但是这里我们会发现一个`visted_cate_ids`， 也就是用户的历史商品列表， 对于某个用户来讲，这个值是个多值型的特征， 而且还要知道这个特征的长度不一样长，也就是用户购买的历史商品个数不一样多，这个显然。这个特征的话，我们一般是用到multi-hot编码，也就是可能不止1个1了，有哪个商品，对应位置就是1， 所以经过编码后的数据长下面这个样子： 

<div align=center>
<img src="https://img-blog.csdnimg.cn/20210118185933510.png" style="zoom:67%;" />
</div>


- 基线模型

  - 这里的 base模型，就是上面提到过的 Embedding&MLP 的形式， 分为三大模块：Embedding layer，Pooling & Concat layer和MLP， 结构如下

    <div align=center>
    <img src="https://img-blog.csdnimg.cn/20210118191224464.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" style="zoom:80%;" />
    </div>

  - 前面的大部分深度模型结构也是遵循着这个范式套路， 简介一下各个模块。

    - Embedding layer：这个层的作用是把高维稀疏的输入转成低维稠密向量， 每个离散特征下面都会对应着一个embedding词典， 维度是$D\times K$， 这里的$D$表示的是隐向量的维度， 而$K$表示的是当前离散特征的唯一取值个数,  这里为了好理解，

      - 这里举个例子说明，就比如上面的 weekday 特征：假设某个用户的weekday特征就是周五，化成one-hot编码的时候，就是[0,0,0,0,1,0,0]表示，这里如果再假设隐向量维度是D， 那么这个特征对应的embedding词典是一个$D\times7$的一个矩阵(每一列代表一个embedding，7列正好7个embedding向量，对应周一到周日)，那么该用户这个one-hot向量经过embedding层之后会得到一个$D\times1$的向量，也就是周五对应的那个embedding，怎么算的，其实就是$embedding矩阵* [0,0,0,0,1,0,0]^T$ 。其实也就是直接把embedding矩阵中one-hot向量为1的那个位置的embedding向量拿出来。 这样就得到了稀疏特征的稠密向量了。其他离散特征也是同理，只不过上面那个multi-hot编码的那个，会得到一个embedding向量的列表，因为他开始的那个multi-hot向量不止有一个是1，这样乘以embedding矩阵，就会得到一个列表了。通过这个层，上面的输入特征都可以拿到相应的稠密embedding向量了。

    - **pooling layer and Concat layer**： pooling层的作用是将用户的历史行为embedding这个最终变成一个定长的向量，因为每个用户历史购买的商品数是不一样的， 也就是每个用户multi-hot中1的个数不一致，这样经过embedding层，得到的用户历史行为embedding的个数不一样多，也就是上面的embedding列表$t_i$不一样长， 那么这样的话，每个用户的历史行为特征拼起来就不一样长了。 而后面如果加全连接网络的话，我们知道，他需要定长的特征输入。 所以往往用一个pooling layer先把用户历史行为embedding变成固定长度(统一长度)，所以有了这个公式：
      $$
      e_i=pooling(e_{i1}, e_{i2}, ...e_{ik})
      $$

      - 这里的$e_{ij}$是用户历史行为的那些embedding。$e_i$就变成了定长的向量， 这里的$i$表示第$i$个历史特征组(是历史行为，比如历史的商品id，历史的商品类别id等)， 这里的$k$表示对应历史特种组里面用户购买过的商品数量，也就是历史embedding的数量，看上面图里面的user behaviors系列，就是那个过程了。 Concat layer层的作用就是拼接了，就是把这所有的特征embedding向量，如果再有连续特征的话也算上，从特征维度拼接整合，作为MLP的输入。

    - **MLP**：这个就是普通的全连接，用了学习特征之间的各种交互。

    - **Loss**: 由于这里是点击率预测任务， 二分类的问题，所以这里的损失函数用的负的log对数似然：
      $$
      L=-\frac{1}{N} \sum_{(\boldsymbol{x}, y) \in \mathcal{S}}(y \log p(\boldsymbol{x})+(1-y) \log (1-p(\boldsymbol{x})))
      $$

  - 这就是base 模型的全貌， 这里应该能看出这种模型的问题， 通过上面的图也能看出来， 用户的历史行为特征和当前的候选广告特征在全都拼起来给神经网络之前，是一点交互的过程都没有， 而拼起来之后给神经网络，虽然是有了交互了，但是原来的一些信息，比如，每个历史商品的信息会丢失了一部分，因为这个与当前候选广告商品交互的是池化后的历史特征embedding， 这个embedding是综合了所有的历史商品信息， 这个通过我们前面的分析，对于预测当前广告点击率，并不是所有历史商品都有用，综合所有的商品信息反而会增加一些噪声性的信息，可以联想上面举得那个键盘鼠标的例子，如果加上了各种洗面奶，衣服啥的反而会起到反作用。其次就是这样综合起来，已经没法再看出到底用户历史行为中的哪个商品与当前商品比较相关，也就是丢失了历史行为中各个商品对当前预测的重要性程度。最后一点就是如果所有用户浏览过的历史行为商品，最后都通过embedding和pooling转换成了固定长度的embedding，这样会限制模型学习用户的多样化兴趣。

  - 那么改进这个问题的思路有哪些呢？  第一个就是加大embedding的维度，增加之前各个商品的表达能力，这样即使综合起来，embedding的表达能力也会加强， 能够蕴涵用户的兴趣信息，但是这个在大规模的真实推荐场景计算量超级大，不可取。 另外一个思路就是**在当前候选广告和用户的历史行为之间引入注意力的机制**，这样在预测当前广告是否点击的时候，让模型更关注于与当前广告相关的那些用户历史产品，也就是说**与当前商品更加相关的历史行为更能促进用户的点击行为**。 作者这里又举了之前的一个例子：

    - 想象一下，当一个年轻母亲访问电子商务网站时，她发现展示的新手袋很可爱，就点击它。让我们来分析一下点击行为的驱动力。
    - 展示的广告通过软搜索这位年轻母亲的历史行为，发现她最近曾浏览过类似的商品，如大手提袋和皮包，从而击中了她的相关兴趣

  - 第二个思路就是DIN的改进之处了。DIN通过给定一个候选广告，然后去注意与该广告相关的局部兴趣的表示来模拟此过程。 DIN不会通过使用同一向量来表达所有用户的不同兴趣，而是通过考虑历史行为的相关性来自适应地计算用户兴趣的表示向量（对于给的广告）。 该表示向量随不同广告而变化。下面看一下DIN模型。

### DIN模型架构

上面分析完了base模型的不足和改进思路之后，DIN模型的结构就呼之欲出了。首先，它依然是采用了base模型的结构，只不过是在这个的基础上加了一个注意力机制来学习用户兴趣与当前候选广告间的关联程度， 用论文里面的话是，引入了一个新的`local activation unit`， 这个东西用在了用户历史行为特征上面， **能够根据用户历史行为特征和当前广告的相关性给用户历史行为特征embedding进行加权**。我们先看一下它的结构，然后看一下这个加权公式。

<img src="https://img-blog.csdnimg.cn/20210118220015871.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" style="zoom: 80%;" />


这里改进的地方已经框出来了，这里会发现相比于base model， 这里加了一个local activation unit， 这里面是一个前馈神经网络，输入是用户历史行为商品和当前的候选商品， 输出是它俩之间的相关性， 这个相关性相当于每个历史商品的权重，把这个权重与原来的历史行为embedding相乘求和就得到了用户的兴趣表示$\boldsymbol{v}_{U}(A)$, 这个东西的计算公式如下：
$$
\boldsymbol{v}_{U}(A)=f\left(\boldsymbol{v}_{A}, \boldsymbol{e}_{1}, \boldsymbol{e}_{2}, \ldots, \boldsymbol{e}_{H}\right)=\sum_{j=1}^{H} a\left(\boldsymbol{e}_{j}, \boldsymbol{v}_{A}\right) \boldsymbol{e}_{j}=\sum_{j=1}^{H} \boldsymbol{w}_{j} \boldsymbol{e}_{j}
$$
这里的$\{\boldsymbol{v}_{A}, \boldsymbol{e}_{1}, \boldsymbol{e}_{2}, \ldots, \boldsymbol{e}_{H}\}$是用户$U$的历史行为特征embedding， $v_{A}$表示的是候选广告$A$的embedding向量， $a(e_j, v_A)=w_j$表示的权重或者历史行为商品与当前广告$A$的相关性程度。$a(\cdot)$表示的上面那个前馈神经网络，也就是那个所谓的注意力机制， 当然，看图里的话，输入除了历史行为向量和候选广告向量外，还加了一个它俩的外积操作，作者说这里是有利于模型相关性建模的显性知识。

这里有一点需要特别注意，就是**这里的权重加和不是1**， 准确的说这里不是权重， 而是直接算的相关性的那种分数作为了权重，也就是平时的那种scores(softmax之前的那个值)，这个是为了保留用户的兴趣强度。

#### local activation unit

DIN的关键点在于 AU 的设计，DIN会计算候选广告与用户最近N个历史行为商品的相关性权重weight，将其作为加权系数来对这N个行为商品的embeddings做sum pooling，用户兴趣正是由这个加权求和后的embedding来体现

<img src="C:/Users/PC/Desktop/推荐系统(1)/推荐系统/img/din_local_activation_unit.png" alt="img" style="zoom:40%;" />

- 与传统attention区别：
  - 权重加和不是1
  - 直接算的相关性的那种分数作为了权重
- 实现细节
  - local_activation_unit:  
    - att_input = torch.cat([queries, keys, queries - keys, queries * keys], axis=-1), queries * keys为向量外积
    - att_output = dnn(att_input)  - > B x len， **用Dice方法替代经典的PReLU激活函数**
    - 对分数scale, 和Transformer同样操作，用于控制元素间的数据量级，防止softemax后输出接近1 导致梯度消失
  - AttentionPoolingLayer:
    - 输入：query 为候选target， keys为历史行为序列
    - 先对keys进行mask，记录填充位置， 得到key_masks
    - 把att_output中mask位置分数置为0
    - 做sum pooling
  - mini-batch aware regularization
    - 如果我们使用L2正则化来防止过拟合，那么我们需要对W进行惩罚，即在损失函数中加入一个正则项： $L= L_0 + \lambda \| w\|^2$ 那么我们需要对W的每一个元素进行更新。
      - 一是计算开销过大。因为X是一个高维稀疏的矩阵，所以W也是一个高维稀疏的矩阵。如果我们对W的每一个元素都进行更新，那么我们需要遍历整个W矩阵，这会消耗大量的时间和空间。
      - 二是信息丢失。因为X是一个稀疏的矩阵，所以有很多特征在某些样本中并没有出现。如果我们对这些特征对应的嵌入向量也进行惩罚，那么我们就会降低这些特征的权重，从而丢失了这些特征所包含的信息。
    - **mini-batch aware regularization: 一种Adaptive的正则化方法**是一种用于大规模稀疏场景下的正则化方法，它可以减少计算开销和过拟合的风险。它的主要思想是只对每个mini-batch中参数不为0的部分进行梯度更新，而不是对整个参数矩阵进行更新。这样可以避免对那些没有出现在mini-batch中的特征进行惩罚，从而保留更多的信息。此外，它还在一定程度上解决了数据长尾分布的过拟合问题。对长尾部分样本施加较大的惩罚而对短尾部分施加较小的惩罚来防止模型对于长尾部分的过拟合。

### DIN实现细节

```python
class Dice(nn.Module):
    """
    自定义的dice激活函数，原论文有公式介绍，有点复杂我也没看懂，别的地方用的不多，不介绍了。
    """
    def __init__(self):
        super(Dice, self).__init__()
        self.alpha = nn.Parameter(torch.zeros((1,)))
        self.epsilon = 1e-9
    
    def forward(self, x):

        norm_x = (x - x.mean(dim=0)) / torch.sqrt(x.var(dim=0) + self.epsilon)
        p = torch.sigmoid(norm_x)
        x = self.alpha * x.mul(1-p) + x.mul(p)
    
        return x


class ActivationUnit(nn.Module):
    """
    激活函数单元
    功能是计算用户购买行为与推荐目标之间的注意力系数，比如说用户虽然用户买了这个东西，但是这个东西实际上和推荐目标之间没啥关系，也不重要，所以要乘以一个小权重
    """
    def __init__(self, embedding_dim, dropout=0.2, fc_dims = [32, 16]):
        super(ActivationUnit, self).__init__()
        # 1.初始化fc层
        fc_layers = []
        # 2.输入特征维度
        input_dim = embedding_dim*4     
        # 3.fc层内容：全连接层（4*embedding,32）—>激活函数->dropout->全连接层（32,16）->.....->全连接层（16,1）
        for fc_dim in fc_dims:
            fc_layers.append(nn.Linear(input_dim, fc_dim))
            fc_layers.append(Dice())
            fc_layers.append(nn.Dropout(p = dropout))
            input_dim = fc_dim
        
        fc_layers.append(nn.Linear(input_dim, 1))
        # 4.将上面定义的fc层，整合到sequential中
        self.fc = nn.Sequential(*fc_layers)
    
    def forward(self, query, user_behavior):
        """
            :param query:targe目标的embedding ->（输入维度） batch*1*embed 
            :param user_behavior:行为特征矩阵 ->（输入维度） batch*seq_len*embed
            :return out:预测目标与历史行为之间的注意力系数
        """
        # 1.获取用户历史行为序列长度
        seq_len = user_behavior.shape[1]
        # 2.序列长度*embedding
        queries = torch.cat([query] * seq_len, dim=1)
        # 3.前面的把四个embedding合并成一个（4*embedding）的向量，
        #  第一个向量是目标商品的向量，第二个向量是用户行为的向量，
        #  至于第三个和第四个则是他们的相减和相乘（这里猜测是为了添加一点非线性数据用于全连接层，充分训练）
        attn_input = torch.cat([queries, user_behavior, queries - user_behavior, 
                                queries * user_behavior], dim = -1)
        out = self.fc(attn_input)
        return out

```



### 思考

DIN模型在工业上的应用还是比较广泛的， 大家可以自由去通过查资料看一下具体实践当中这个模型是怎么用的？ 有什么问题？比如行为序列的制作是否合理， 如果时间间隔比较长的话应不应该分一下段？ 再比如注意力机制那里能不能改成别的计算注意力的方式会好点？(我们也知道注意力机制的方式可不仅DNN这一种)， 再比如注意力权重那里该不该加softmax？  这些其实都是可以值的思考探索的一些问题，根据实际的业务场景，大家也可以总结一些更加有意思的工业上应用该模型的技巧和tricks，欢迎一块讨论和分享。

### 总结

**DIN (Deep Interest Network)** 是一种深度学习模型，主要应用于推荐系统中，通过捕捉用户的兴趣并进行个性化推荐。DIN 的核心思想是引入注意力机制，根据用户的历史行为和当前的推荐目标，动态调整每个历史行为的权重，从而实现更精准的推荐。

- **模型结构**

  - **Embedding层**：将用户和物品的离散特征转换为连续的向量表示。

  - **兴趣提取层**（local activation unit）：使用注意力机制对用户的历史行为进行加权，提取与当前推荐目标相关的兴趣。
    - att_input = torch.cat([queries, keys, queries - keys, queries * keys], axis=-1), queries * keys为向量外积
    - att_output = dnn(att_input)  - > B x len， **用Dice方法替代经典的PReLU激活函数**, 准确的说这里不是权重， 而是直接算的相关性的那种分数作为了权重，也就是平时的那种scores(softmax之前的那个值)，这个是为了保留用户的兴趣强度。因为sofmax会导致两极分化
    - 对分数scale, 和Transformer同样操作，用于控制元素间的数据量级，防止softemax后输出接近1 导致梯度消失
    - **mini-batch aware regularization: 一种Adaptive的正则化方法**是一种用于大规模稀疏场景下的正则化方法，它可以减少计算开销和过拟合的风险。它的主要思想是只对每个mini-batch中参数不为0的部分进行梯度更新，而不是对整个参数矩阵进行更新。这样可以避免对那些没有出现在mini-batch中的特征进行惩罚，从而保留更多的信息。此外，它还在一定程度上解决了数据长尾分布的过拟合问题。对长尾部分样本施加较大的惩罚而对短尾部分施加较小的惩罚来防止模型对于长尾部分的过拟合。

  - **全连接层**：对提取的兴趣向量进行进一步的非线性变换，生成最终的用户兴趣表示。

  - **输出层**：计算用户对推荐目标的点击率（CTR）或其他目标。

- **核心思想**：DIN 模型的核心在于引入了注意力机制，用于捕捉用户历史行为与当前推荐目标之间的相关性。具体来说，模型通过计算每个历史行为与当前推荐目标之间的相似度来动态调整每个历史行为的权重，从而使得与当前推荐目标更相关的历史行为在兴趣提取中占据更大的比重。

- **优势**

  - **个性化**：通过注意力机制，DIN 能够动态地调整用户历史行为的权重，实现更个性化的推荐。

  - **解释性强**：注意力机制提供了每个历史行为的权重，可以解释模型的推荐结果。

  - **灵活性高**：可以灵活地处理用户的各种历史行为数据，适用于多种推荐场景。
  - **前提**：这个模型的使用场景是**非常注重用户的历史行为特征（历史购买过的商品或者类别信息）**
  - **针对Diversity：** 针对用户广泛的兴趣，DIN用*an interest distribution*去表示，即用 Pooling（weighted sum）对Diversity建模（对用户多种多样的兴趣建模）。
  - 针对**Local Activation**
    - 所以 DIN 稍加改进，利用attention机制实现 Local Activation，从用户历史行为中动态学习用户兴趣的embedding向量，针对不同的广告构造不同的用户抽象表示，从而实现了在数据维度一定的情况下，更精准地捕捉用户当前的兴趣。
    - 对用户历史行为进行了不同的加权处理，针对不同的广告，不同的 behavior id 赋予不同的权重，这个权重是由当前behavior id和候选广告共同决定的，这就是Attention机制。即针对当前候选Ad，去局部的激活（*Local Activate*）相关的历史兴趣信息。
    - 与当前候选Ad相关性越高的历史行为，会获得越高的*attention score*，从而会主导这一次预测。
  - CTR中**特征稀疏而且维度高**，通常利用L1、L2、Dropout等手段防止过拟合。由于传统L2正则计算的是全部参数，CTR预估场景的模型参数往往数以亿计。DIN提出了一种正则化方法，在每次小批量迭代中，给与不同频次的特征不同的正则权重；
  - 由于传统的**激活函数**，如Relu在输入小于0时输出为0，将导致许多网络节点的迭代速度变慢。PRelu虽然加快了迭代速度，但是其分割点默认为0，实际上分割点应该由数据决定。因此，DIN提出了一种数据动态自适应激活函数Dice。
  - **针对大规模稀疏数据的模型训练：**当DNN深度比较深（参数非常多），输入又非常稀疏的时候，很容易过拟合。DIN提出**Adaptive regularizaion**来防止过拟合，效果显著。

- **实际业务场景应用**：在电商平台上，DIN 模型可以用于商品推荐、内容推荐、广告推荐等多个场景。例如：

  - **商品推荐**：

    - **问题**：用户在浏览商品时，如何根据其历史浏览、点击、购买行为进行精准推荐。

    - **应用**：使用 DIN 模型，根据用户的历史行为和当前正在浏览的商品，动态调整每个历史行为的权重，推荐用户可能感兴趣的商品。

  - **内容推荐**：

    - **问题**：用户在浏览新闻、视频等内容时，如何根据其历史浏览行为进行个性化推荐。

    - **应用**：使用 DIN 模型，根据用户的历史内容浏览行为和当前推荐目标，提取用户兴趣，为用户推荐可能感兴趣的内容。

  - **广告推荐**：

    - **问题**：在广告投放中，如何根据用户的历史点击行为提高广告点击率。
      - **应用**：使用 DIN 模型，根据用户的历史广告点击行为和当前广告目标，动态调整每个历史行为的权重，提高广告点击率预测的准确性。

- **常见问题及解决方案**

  - **行为序列制作是否合理**：

    - **问题**：如何选择和处理用户的行为数据以便最大化模型的效果。

    - **解决方案**：确保选择与目标任务相关的用户行为，并进行数据清洗和预处理，控制行为序列的长度。

  - **如何处理时间间隔较长的行为序列**：

    - **解决方案**：对时间间隔较长的行为序列进行分段(日、周、月、季度)，并引入时间衰减机制。

  - **是否可以尝试其他的注意力机制以提升模型表现**：
    - **解决方案**：可以尝试多头注意力机制、自注意力机制或层次化注意力机制。

  - **注意力权重是否应该加Softmax**：
    - **解决方案**：加Softmax可以使权重归一化，有助于模型稳定性和解释性；在某些场景下，可以考虑其他归一化方法或不进行归一化。原文未加softmax



# 样本

## 负样本采样

### 推荐系统中有哪些场景是无法获得真负样本的？如何解决？

个性化推荐。App内部的推荐，我们可以根据埋点，比较容易获知用户滑过、忽略了某些推荐内容，所以比较有信心拿哪些item作为负样本。但是在推送场景下，我们很难知道用户未点击的item是用户真的不喜欢还是压根没看见。所以不能放心地将所有未点击的item都当负样本。

在这种无法获得真负样本的场景下，一般我们通过随机采样来获得负样本。但是，随机采样毕竟引入了噪声，这时，再用CTR预估这种要求"绝对准确性"的算法，就不合适了。所以，在召回或个性化推送场景下，我们一般采用 **pairwise LearningToRank** 建模排序的相对准确性。

### 为什么不能只拿曝光未点击做召回模型的负样本？

我们希望召回训练数据的正样本是user和item匹配度最高的那些样本，也即用户点击样本，负样本是user和item最不匹配的那些样本，但不能拿“曝光未点击”作为召回模型的负样本，因为我们从线上日志获得的训练样本，已经是上一版本的召回、粗排、精排替用户筛选过的，即已经是对用户“匹配度较高”的样本了，即推荐系统以为用户会喜欢他们，但用户的行为又表明的对他的嫌弃。拿这样的样本训练出来的模型做召回，并不能与线上环境的数据分布保持一致。也就是说曝光未点击既不能成为合格的正样本，也不能成为合格的负样本。

所以一般的做法是拿点击样本做正样本，拿随机采样做负样本，因为线上召回时，候选库里大多数的物料是与用户没有关系的，随机抽样能够很好地模拟这一分布。

### Batch内负采样

Batch内负采样，即仅将正样本（有曝光有点击）作为训练样本输入模型。在训练过程中，对于一个batch的第 i 行样本，其他行的正样本作为第 i 行样本的负样本。一般而言，neg越大越好，neg最大等于batch_size。

缺点：batch内的物品都是热门物品，导致采样后的负样本中页大都为热门物品，造成对热门物品的过度打压。

## 正样本采样

### 热门打压

- 生成正样本 item+ 时，打压高热 item

  目的是为了降低 item 成为 **item+** 的可能性。因此，item越热门，其成为 **item+** 的概率就应该越低。

  一个item成为 **item+** 的概率
  $$
  P_{pos}(w_i)=(\sqrt{\frac{z(w_i)}{a}} + 1)\frac{a}{z(w_i)}
  $$

  $$
  z(w_i)=\frac{点击过w_i的用户数}{同时段所有发生过点击行为的用户总数}
  $$

  a 为一个超参数，一般在 1e<sup>-3</sup>~1e<sup>-5</sup> 之间

  可以看出 z(w<sub>i</sub>) 越高，item成为 item+ 的概率就越低，从而实现了对热门item的打压。

  而对于一些罕见item，按照公式计算出的概率大于1，说明罕见的item只要被点击过，就一定会被当成正样本。

# 其他

## AB实验

- **定义**

  **A/B 测试**为一种随机测试，将两个不同的东西（即A和B）进行假设比较。该测试运用统计学上的**假设检定**和**双母体假设检定**。A/B 测试可以用来测试某一个变量两个不同版本的差异，一般是让A和B只有该变量不同，再测试其他人对于A和B的反映差异，再判断A和B的方式何者较佳。

  在同一时间对于目标受众做科学抽样、分组测试以评估效果。因为**时间**也是属于**变量**的一部分，比如说平时和双十一期间，gmv一定是双十一期间来的高。

- **为什么要做A/B测试**

  **A/B测试** 可以帮助业务进行最终决策，并且有充分的数据来支撑你的论点。

  - **风险控制**：小流量实验可以避免直接上线效果不好以造成损失。其次，实验迭代的过程中，决策都是有科学依据的，可以避免系统性的偏差
  - **因果推断**：我们推断 A/B实验 中的优化和改变最终能影响到线上数据以及用户行为。A/B测试 可以帮助证明或者推翻我们的推断
  - **复利效应**：A/B测试 是可以持续不断进行的实验，即使一次实验提升的效果不大，但是长期下来复利效应的积累会产生很大的变化和回报

- **A/B test 流程**

  - 分析现状，建立假设：分析业务，确定最高优先级的改进点，作出假设，提出优化建议。
  - 设定指标：设置主要指标来衡量版本的优劣；设置辅助指标来评估其他影响。
  - 设计与开发：设计优化版本的原型并完成开发。
  - 确定测试时长：确定测试进行的时长。
  - 确定分流方案：确定每个测试版本的分流比例及其他分流细节。
  - 采集并分析数据：收集实验数据，进行有效性和效果判断。
  - 给出结论：①确定发布新版本；②调整分流比例继续测试；③优化迭代方案重新开发，回到步骤1。

- **分流&分层的策略**

  如果流量人群不进行分流和分层，则会导致某一个实验占的流量很多，变相导致另一个实验的流量锐减，从而得到的实验结果会有统计学上的误差。

  - **分流策略**

    - Random——随机分流：
    - Partition By User——按用户切分：
    - Partition By Category——按分类切分：

  - **分流分层规则**

    - 正交与互斥：

      - 正交：每个独立实验为一层，层与层之间是正交的，流量穿越每层实验时，都会被随机打乱，且随机结果离散
      - 互斥：实验在同一层拆分流量，且同一层内不同组的流量是不互相重叠的

    - 分流模型

      域1和域2拆分流量，此时域1和域2是互斥的

      流量经过域2中的B1层、B2层、B3层，B1层、B2层、B3层的流量都是与域2的流量相等。此时B1层、B2层、B3层的流量是正交的。

      流量流过域2中的B1层时，又把B1层分为了B1-1，B1-2，B1-3，此时B1-1，B1-2，B1-3之间又是互斥的

    - 规则使用场景

      比如B1层、B2层、B3层可能分别为：UI层、搜索结果层、广告结果层，这些层基本上是没有任何业务关联的，即使使用相同的流量（流量正交）也不会对实际业务结果造成影响。但是不同层之间所进行的实验相互关联，就会影响下游实验。因此建议同一类型的实验在同一层内进行，并且要考虑不同实验之间相互的依赖

- **其他技术**

  - **p-value**：概率，主要在 A/B测试 中说明实验提升的显著性，并且往往与假设检验相挂钩。

    - p < 0.05：有统计学差异
    - p < 0.01：有显著统计学差异
    - p < 0.001：有极其显著的统计学差异

    在实践中可以先设置空跑期，进行AA test，来检查流量分布是否均匀

  - **假设检验**：是推论统计中用于检验现有数据是否足以支持特定假设的方法。一旦能估计未知参数，就会希望根据结果对未知的真正参数值做出适当的推论。假设检验的步骤如下：

    - 最初研究假设为真相不明
    - 提出相关的零假设和备择假设
    - 考虑检验中对样本做出的统计假设
    - 选择一个显著性水平 α
    - 选择适合的检验统计量 T
    - 在设定零假设为真下推导检验统计量的分布
    - 根据在零假设成立时的检验统计量T分布，找到概率为显著性水平 (α) 的区域，此区域称为“拒绝域”(记作RR或CR)，即在零假设成立的前提下，落在拒绝域的概率只有α。
    - 针对检验统计量T，根据样本计算其估计值t<sub>obs</sub>
    - 若估计值t<sub>obs</sub>未落在拒绝域，则“不拒绝”零假设（do no reject 𝐻<sub>0</sub>）。若估计值t<sub>obs</sub>落在拒绝域，则拒绝零假设，接受备择假设。

## AB实验中常见的问题

### 用户抽样不科学

先来看一组数据

| 学院 | 女生申请数 | 女生录取数 | 女生录取率 | 男生申请数 | 男生录取数 | 男生录取率 | 申请总数 | 录取总数 | 总录取率 |
| ---- | ---------- | ---------- | ---------- | ---------- | ---------- | ---------- | -------- | -------- | -------- |
| 1    | 100        | 49         | 49%        | 20         | 15         | 75%        | 120      | 64       | 53.3%    |
| 2    | 20         | 1          | 5%         | 100        | 10         | 10%        | 120      | 11       | 9.2%     |
| 总计 | 120        | 50         | 42%        | 120        | 25         | 21%        | 240      | 75       | 31.3%    |

单看男生，无论是1号学院还是2号学院，男生录取率都高于女生，因此总体的录取率是不是也是男生高于女生呢？

统计出来并不是，男生的总体录取率要远低于女生，这种现象就被称为辛普森悖论

- **辛普森悖论**：几组不同的数据中均存在一种趋势，但当这些数据组合在一起后，这种趋势消失或反转。其产生的原因主要是数据中存在多个变量。这些变量通常难以识别，被称为“潜伏变量”。潜伏变量可能是由于采样错误造成的。

在 A/B 测试 中，如果实验组和对照组的样本流量分布不一致，就有可能产生辛普森悖论

### 互斥层选择错误

- 互斥层选择原则：
  - 假设实验之间有相关性，那么实验必须置于同一互斥层；
  - 假设实验之间没有相关性，那么实验可以至于不同互斥层

### 不考虑是否显著

只简单地观测实验数据的涨跌，不去考虑实验结果是否显著

## 评价指标

### Hinge

通常用于 maximum-margin 的分类任务中，如支持向量机
$$
L(y)=max(0, 1-\hat{y}y)
$$
以支持向量机为例，其模型为
$$
\hat{y}=w·x
$$
其求导结果如下
$$
\frac{\partial{L}}{\partial{w_i}}=
\begin{cases}
-yx_i, \hat{y}y > 1\\ 
0,  otherwise
\end{cases}
$$
实际应用中，一方面很多时候我们 y 的值域并不是-1~1，比如我们更希望y更接近于一个概率，其值域最好是0~1。另一方面，很多时候我们希望训练的是两个样本之间的相似关系，而非样本的整体关系，所以很多时候我们会用下面的公式
$$
L(y,y^{'})=max(0, m-y+y^{'})
$$
其中，y是正样本的得分，y<sup>'</sup> 是负样本的得分，m是margin

即我们希望正样本分数越高越好，负样本分数越低越好

### Cross-Entropy

### MSE

### 搜索评价指标——NDCG

NDCG，Normalized Discounted cumulative gain(归一化折损累计增益)。

#### 主要思想：

- 高关联度的结果比一般关联度的结果更影响最终的指标得分
- 有高关联度的结果出现在更靠前的位置的时候，指标会越高

#### 累计增益（CG）

CG，cumulative gain，是DCG的前身，只考虑了相关性的关联程度，没有考虑到位置的因素。它是一个搜索结果相关性分数的总和。指定位置p上的CG为：
$$
CG_p=\sum_{i=1}^prel_i
$$
rel<sub>i</sub> 代表这个位置上的相关度

比如：假设搜索 篮球 结果，最理想的是B1、B2、B3。而出现的结果是 B3、B1、B2的话，CG的值是不会变的

#### 折损累计增益（DCG）

DCG，Discounted的CG，就是在每一个CG的结果上除以一个折损值。

目的：为了让排名越靠前的结果越能影响最后的结果。
$$
DCG_p=\sum_{i=1}^p\frac{rel_i}{log_2(i+1)}=rel_1+\sum_{i=2}^p\frac{rel_i}{log_2(i+1)}
$$
还有一种比较常用的公式，用来增加相关度影响比重的DCG计算方式
$$
DCG_p=\sum_{i=1}^p\frac{2^{rel_i}-1}{log_2(i+1)}
$$
后一种更多用于工业。当相关值为二进制时，二者结果是一致的。

#### 归一化折损累计增益（NDCG）

NDCG，Normalized的DCG，由于搜索结果随着检索词的不同，返回的数量是不同的，而DCG是一个累加的值，没法针对两个不同的搜索结果进行比较，因此需要归一化处理。
$$
nDCG_p=\frac{DCG_p}{IDCG_p}
$$
IDCG为理想情况下最大的DCG值
$$
IDCG_p=\sum_{i=1}^{|REL|}\frac{2^{rel_i}-1}{log_2(i+1)}
$$
其中 |REL| 表示，结果按照相关性从大到小的顺序排序，取前p个结果组成的集合。也就是按照最优的方式对结果进行排序

#### 示例

假设搜索回来的结果，其相关性分数分别是 3、2、3、0、1、2

那么CG = 3+2+3+0+1+2=11

可以看到只是对相关的分数进行了一个关联的打分，并没有召回的所在位置对排序结果评分的影响。而我们看DCG：

| i    | reli | log2(i+1) | reli/log2(i+1) |
| ---- | ---- | --------- | -------------- |
| 1    | 3    | 1         | 3              |
| 2    | 2    | 1.58      | 1.26           |
| 3    | 3    | 2         | 1.5            |
| 4    | 0    | 2.32      | 0              |
| 5    | 1    | 2.58      | 0.38           |
| 6    | 2    | 2.8       | 0.71           |

所以DCG = 3+1.26+1.5+0+0.38+0.71 = 6.86

接下来我们归一化，归一化需要先结算 IDCG，假如我们实际召回了8个物品，除了上面的6个，还有两个结果，假设第7个相关性为3，第8个相关性为0。那么在理想情况下的相关性分数排序应该是：3、3、3、2、2、1、0、0。计算IDCG@6:

| i    | reli | log2(i+1) | reli/log2(i+1) |
| ---- | ---- | --------- | -------------- |
| 1    | 3    | 1         | 3              |
| 2    | 3    | 1.58      | 1.89           |
| 3    | 3    | 2         | 1.5            |
| 4    | 2    | 2.32      | 0.86           |
| 5    | 2    | 2.58      | 0.77           |
| 6    | 1    | 2.8       | 0.35           |

所以IDCG = 3+1.89+1.5+0.86+0.77+0.35 = 8.37

因此最终 NDCG@6 = 6.86/8.37 = 81.96%
