[TOC]

# 机器学习算法

## 逻辑斯蒂回归（Logistic Regression，LR）



## 协同过滤

### 1 目标场景

存在共现矩阵的情况下，进行点击率预估、评分预测等等

### 2 基本思想

物以类聚，人以群分。

### 3 相似度计算方式

- 杰卡德（Jaccard）相似度

  这个是**衡量两个集合的相似度的一种指标**。两个集合A和B的交集元素在A，B的并集中所占的比例，称为两个集合的杰卡德相似系数
  $$
  J(A,B)=\frac{|A\cap{B}|}{|A\cup{B}|}
  $$

- 余弦相似度

  衡量了用户向量之间向量夹角的大小，夹角越小，说明相似度越大，两个用户越相似
  $$
  sim(i,j)=cos(i,j)=\frac{i·j}{||i||·||j||}
  $$
  **局限性：**对于评分数据不规范的时候，存在有的用户喜欢打高分，有的用户喜欢打低分情况的时候，有的用户喜欢乱打分的情况，这时候余弦相似度算出来的结果可能就不是那么准确了。

- 皮尔逊相关系数

  皮尔逊相关系数通过使用用户平均分对个体独立评分进行修正，减少了用户评分偏置的影响
  $$
  sim(i,j)=\frac{\sum_{p\in{P}}(R_{i,p}-\overline{R_i})(R_{jp}-\overline{R_j})}{\sqrt{\sum_{p\in{P}}(R_{i,p}-\overline{R_i})^2}\sqrt{\sum_{p\in{P}}(R_{jp}-\overline{R_j})^2}}
  $$

- 其他

- 余弦相似度VS欧式距离

### 4 基于User的协同过滤 UserCF

- 步骤：

  - 计算用户A与其他用户的相似度

  - 根据相似度用户计算用户A对物品的最终评分
    $$
    R_{u,p}=\frac{\sum_{s\in{S}}(w_{u,s}R_{s,p})}{\sum_{s\in{S}}w_{u,s}}
    $$

  - 根据用户评分对用户进行推荐：定一个阈值，预测评分超过阈值即可推荐给用户

- 缺点：

  - 数据稀疏性：

    一个大型的电子商务推荐系统一般有非常多的物品，用户可能买的其中不到1%的物品，不同用户之间买的物品重叠性较低，导致算法无法找到一个用户的邻居，即偏好相似的用户，即使找到准确性也不会太高。这导致UserCF不适用于那些正反馈获取较困难的应用场景

  - 用户相似度矩阵维护难度大：

    绝大多数产品的用户数都要远大于物品数，因此维护用户相似度矩阵的难度要大得多；用户相似度矩阵的存储空间随着用户数量的增加而增加，不适合用户数据量大的情况的使用。

- 适用场景：常适用于用户少，物品多，时效性较强的场合

### 5 基于Item的协同过滤 ItemCF

- 步骤：
  - 首先计算待选物品和其他物品的相似度
  - 找出与待选物品最相似的n个物品
  - 根据用户对这n个物品的打分去计算对待选物品的打分情况
- 优点：
  - ItemCF算法的预测结果比UserCF算法质量要高一些
  - 由于ItemCF算法可以预先计算好物品的相似度，所以在线的预测性能要比UserCF算法高
- 缺点：
  - 数据稀疏性
  - 物品相似度矩阵维护难度大
- 适用场景：

### 6 UserCF和ItemCF的优缺点对比

- 区别 

  ![image-20220405163844329](F:\面试\推荐算法\图片\UserCF和ItemCF区别.png)

- 共同的缺点

  - 不能彻底解决数据稀疏性问题
  - 泛化能力弱
    - 热门物品具有很强的头部效应，容易跟大量物品产生相似，而尾部物品由于特征向量稀疏，导致很少被推荐
    - 为解决这一问题，矩阵分解技术被提出
  - 无法利用更多的信息：**一般是仅仅基于用户的行为数据**，而不依赖于任何附加信息或者用户的任何附加信息，比如不依赖物品自身特征、用户性别、年龄等

### 7 协同过滤算法的优缺点

- 优点：
  - 算法原理朴素简单，即"物以类聚，人以群分"，已得到工业界验证过的一类重要算法，在大型互联网公司都有很好的落地和应用
  - 易使用Spark分布平台来实现，因此可以通过增加计算节点很容易处理大规模数据集。
  - 可以很好的为用户推荐多样性、新颖性的item，特别是当群体规模越大、用户行为越多，推荐的效果越好
  - 只依赖用户的操作行为，不依赖具体user相关和item相关的信息就可以实现
- 缺点：
  - 冷启动问题：如果用户行为少，这时就很难发挥协同过滤算法的优势和价值，甚至无法为用户做推荐
  - 稀疏性问题：互联网产品用户基数大，item数量多，一般用户只对很少量的item产生操作行为，这时用户操作行为矩阵是非常稀疏的，太稀疏的行为矩阵计算出的item相似度往往不够精准，最终影响推荐结果的精确度。

## 矩阵分解（Matrix Factorization，MF）

矩阵分解也叫做隐语义模型
$$
p(u,i)=p^T_uq_i=\sum_{f=1}^{F}{p_{uf}q_{if}}
$$

- LFM的损失函数：未正则化和正则化

$$
loss=\sum(p(u,i)-p^{LFM}(u,i))^2
$$

$$
loss=\sum(p(u,i)-p^{LFM}(u,i))^2+\alpha|p_u|^2+\alpha|q_i|^2
$$

- LFM算法迭代，对其求偏导
  $$
  \frac{\partial{loss}}{\partial{p_{uf}}} = -2(p(u,i)-p^{LFM}(u,i))q_{if}+2\partial{p_{uf}}
  $$

  $$
  \frac{\partial{loss}}{\partial{q_{if}}} = -2(p(u,i)-p^{LFM}(u,i))p_{uf}+2\partial{q_{if}}
  $$

- 梯度下降
  $$
  p_{uf}=p_{uf} - \beta\frac{\partial{loss}}{\partial{p_{uf}}}
  $$

  $$
  q_{if}=q_{if} - \beta\frac{\partial{loss}}{\partial{q_{if}}}
  $$

- 影响训练效果的因素

  - 负样本的选取
  - 隐特征F，正则化参数，learning rate

- LFM vs CF

  - LFM是属于监督学习的分支，通过训练样本的label设定损失函数，利用最优化方法来使得损失函数最小化，从而得到最优模型；CF是通过公式建模求解相似度矩阵
  - LFM空间复杂度为O(max(M×F，N×F))，CF的空间复杂度为O(M^2)或O(N^2)，离线计算LFM较快
  - CF可较好地实时计算，LFM响应不及时，实时计算CF较快

## 因子分解机（Factorization Machine，FM）

- 针对问题

  - 旨在解决稀疏数据下的特征组合问题

  - 在面对稀疏特征向量时，Poly2特征交叉项无法收敛
    $$
    y(x)=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^n\sum_{j=i+1}^nw_{ij}x_ix_j
    $$
    多项式模型是包含特征组合的最直观的模型，当x<sub>i</sub> 和 x<sub>j</sub> 都非零时，组合特征才有意义。组合特征的参数一共有n(n-1)/2个，任意两个参数都是独立的。然而在数据稀疏性普遍存在的实际应用场景中，二次项参数的训练是很困难的。其原因是每个参数的训练都需要大量非零的样本，这部分样本非常少，容易导致参数不准确，严重影响模型性能

  - **Poly2**计算复杂度过高

- 改进思路：当 k 足够大的时候，对于**任意对称正定的实矩阵W**，均存在实矩阵V，使得W=V·V<sup>T</sup>

- 数学模型，隐向量长度 k << n
  $$
  y=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n-1}\sum_{j=i+1}^n<v_i,v_j>x_ix_j,<v_i,v_j>=\sum_{f=1}^kv_{i,f}v_{j,f}
  $$

  - 参考$ab + ac +bc = \frac{1}{2}[(a+b+c)^2 - (a^2 + b^2 + c^2)]$    所以得出
    $$
    \begin{align*}
        &\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}<v_i,v_j>x_ix_j \\
        &= \frac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{n}<v_i,v_j>x_ix_j - \frac{1}{2}\sum_{i=1}^{n}<v_i,v_i>x_ix_i & (1)\\
        &= \frac{1}{2} ( \sum_{i=1}^{n}\sum_{j=1}^n\sum_{f=1}^{k}v_{i,f}\,v_{j,f}x_ix_j - \frac{1}{2}\sum_{i=1}^{n}\sum_{f=1}^{k}v_{i,f}\,v_{i,f}x_ix_i )  & (2)\\
        &= \frac{1}{2}\sum_{f=1}^{k}(\sum_{i=1}^{n}v_{i,f}x_i · \sum_{j=1}^{n}v_{j,f}x_j - \ \sum_{i=1}^{n}v_{i,f}^2x_i^2) & (3)\\
        &= \frac{1}{2}\sum_{f=1}^{k}[(\sum_{i=1}^{n}v_{i,f}x_i)^2 -  \sum_{i=1}^{n}v_{i,f}^2x_i^2 ] & (4)
    \end{align*}
    $$

  - 第1个等号：对称矩阵 $w_{ij}$对角线上半部分；

  - 第2个等号：把向量内积 $<v_i,v_i>$ 展开成累加和的形式；

  - 第3个等号：提出公共部分；

  - 第4个等号： $i$ 和 $j$  相当于是一样的，表示成平方过程。

- 损失函数
  $$
  J(w_0,w_1,w_2,...,w_n,w_{12},w_{13},...,w_{n-1,n})=-\frac{1}{m}\sum_{i=1}^my^{(i)}logy^{(i)}_{pre}+(1-y^{(i)})log(1-y^{(i)}_{pre})
  $$

- 梯度下降
  $$
  y=w_0+\sum_{i=1}^nw_ix_i+\frac{1}{2}\sum_{f=1}^k[(\sum_{i=1}^nv_{i,f}x_i)^2-\sum_{i=1}^n(v_{i,f}x_i)^2]
  $$

- 优点

  - 极大降低了训练开销 O(n<sup>2</sup>)->O(kn)
  - **隐向量的引入**，使得FM能更好解决数据稀疏性的问题：
    - 这里可以观察到，**交叉项的权重是两个矩阵的点乘而不直接是一个权重矩阵**，这是因为类型变量经过One-Hot或其他类似形式的编码后，会产生高维稀疏矩阵，导致有的交叉项在训练样本中从未出现过，如直接是一个权重矩阵则权重为0，训练不出相关信息。因而相当于是通过矩阵分解的形式，将原本的权重矩阵表示为两个矩阵相乘。这样，即使交叉项为0还是可以得到相关权重，以此解决高维稀疏矩阵的问题。
  - **FM模型是利用两个特征的Embedding做内积得到二阶特征交叉的权重**，那么我们可以将训练好的FM特征取出离线存好，之后用来做其他扩展

- 与其他模型的对比

  - 相比于SVM的二阶多项式核而言，FM在样本稀疏的情况下是有优势的；而且，FM的训练/预测复杂度是线性的，而二阶多项式核SVM需要计算核矩阵，核矩阵复杂度是 N<sup>2</sup> 

  - 相比于MF而言，我们把MF中每一项的rating分改写为 
    $$
    r_{ui}=\beta_u+\gamma_i+x_u^Ty_i
    $$
    从上述公式可以看出，这相当于只有两类特征 u 和 i 的FM模型。对于FM而言，我们可以加任意多的特征，比如user的历史购买平均值，item的历史购买平均值等。但是MF只能局限在两类特征。在特征的扩展性上不如FM

## FM引入特征域（Field-ware Factorization Machines，FFM）

相比于FM，FFM模型引入了特征域的概念，其数学形式的二阶部分如下
$$
FM(w,x)=\sum_{j_1=1}^n\sum_{j_2=j_1+1}^n(w_{j_1f_2}w_{j_2f_1})x_{j_1}x_{j_2}
$$
FFM将相同性质的特征都归于同一个field。简单来说，同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个field，包括用户性别、职业、品类偏好等。

其与FM的区别在于隐向量由原来的 w<sub>j1</sub> 变成了 w<sub>j1f2</sub>，这意味着每个特征对应的不是唯一一个隐向量，而是一组隐向量。当 x<sub>j1</sub> 特征与 x<sub>j2 </sub>特征进行交叉时， x<sub>j1</sub> 会从 x<sub>j1</sub> 的这一组隐向量中挑出与 x<sub>j2 </sub>的域对应的隐向量 w<sub>j1f2</sub> 进行交叉。

假设样本的 n 个特征属于 f 个field，那么FFM的二次项有 nf 个隐向量。而在FM模型中，每一维特征的隐向量只有一个。FM可以看作FFM的特例，就是把所有特征都归属到一个field的FFM模型。

如果隐向量的长度为k，那么FFM的二次参数有 nfk 个，远多于FM模型的 nk 个。此外，由于隐向量与field相关，FFM二次项并不能化简，预测复杂度为 O(kn<sup>2</sup>)

- FFM的SGD优化过程。算法输入 tr、va、pa分别是训练样本集、验证样本集和训练参数设置

  - 根据样本特征数量（tr.n）、field的个数（tr.m）和训练参数（pa），生成初始化模型，即随机生成模型的参数；

  - 如果归一化参数pa.norm为真，计算训练和验证样本的归一化系数，样本 i 的归一化系数为
    $$
    R[i]=\frac{1}{||X[i]||}
    $$

  - 对每一轮迭代，随机打乱训练样本的顺序

  - 对每一个训练样本，执行如下操作

    - 计算每一个样本的FFM项
    - 计算每一个样本的训练误差
    - 利用单个样本的损失函数计算梯度，再根据梯度更新模型参数

  - 对每一个验证样本，计算样本的FFM输出，计算验证误差

  - 重复步骤3~5，直到迭代结束或验证误差达到最小



# 深度学习

## DeepFM



## Wide&Deep

### wide&deep动机

- LR（**Memorization**）：线性模型，具有较强的记忆性
  - 前深度学习 主要是使用 LR模型，通过大量的精细特征工程，利用其较强记性挖掘信息，保证预测结果的准确性。但是会导致用户兴趣收敛，无新鲜感，不利于长久的用户留存
  - 缺点：
    - 此种方式非常依赖人工经验挖掘数据中的特征交互模式。
    - 线性模型特征与特征之间在模型中是独立的，对于训练中未出现过的数据或模式，模型无法学习对应的参数，从而使模型对这些数据的预估能力弱。

- DNN（**generalization**）：借助embedding化实现参数空间的共享，即使对于未见过的数据，也具有一定的预估能力。
  - DNN引入embedding，模型通过MLP结构对特征进行复杂、间接和高阶的隐式交叉学习，挖掘隐藏在数据间潜在关联模式，使模型有能力处理未见过的数据或模式。相比传统机器学习模型，具有更好的泛化性。有利于推荐效果中的新颖性这个维度，即对于数据中未出现的模式，模型也能做出相应的合理反应。
  - 缺点：
    - 隐式学习特征交叉相比于人工显式特征交叉，挖掘数据中的已有模式的难度增加，导致模型的记忆性减弱，不利于推荐的准确性。
    - 对于某些特定的场景(数据分布长尾， 共现矩阵稀疏高秩）很难有效学习低纬度的表示， 造成推荐的过渡泛化。
    - DNN结构的效果相比于传统的机器学习模型，没有明显的优势，这与推荐场景中特征的高维稀疏性有关。
- wide&deep
  - wide&deep模型的整体框架设计思路清晰简洁，就是在DNN结构的基础上融合了LR结构，加强了模型处理高维稀疏特征的能力, 使模型兼具泛化性和记忆性，效果得到提升，也使得深度模型在推荐领域开始普及。

### widedeep模型架构

- input：
  - x_wide：
    - 包含**原始特征**和转换的**共现组合特征**（corss-product特征）
    - Linear Model采用的是 FTRL 模型，让Wide部分变得更加的稀疏，即Wide部分的大部分参数都为0，压缩了模型权重及特征向量的维度。Wide部分模型训练完之后留下来的特征都是非常重要的，那么模型的“记忆能力”就可以理解为发现"直接的"，“暴力的”，“显然的”关联规则的能力
  - x_deep：通过embedding的方式将categorical/id特征映射成稠密向量，让DNN学习到这些特征之间的**深层交叉**，以增强扩展能力
- hidden：全连接网络，一般为3层
  - wide侧使用FTRL
    - 为什么使用ftrl
      - Wide部分采用了两个id类特征(当前曝光app和用户安装app)的乘积，两个id类特征向量进行组合，在维度爆炸的同时，会让原本已经非常稀疏的multihot特征向量，变得更加稀疏。wide部分的权重数量其实是海量的。为了不把数量如此之巨的权重都搬到线上进行model serving，采用FTRL过滤掉哪些稀疏特征无疑是非常好的工程经验。
      - FTRL是一个**稀疏性很好**，**精度又不错**的**随机梯度下降方法**。由于是随机梯度下降，当然可以做到来一个样本就训练一次，进而实现模型的在线更新。
      - L1正则化，**FTRL with L1非常注重模型的稀疏性。这也就是问题的答案，W&D采用L1 FTRL是想让Wide部分变得更加稀疏。**压缩模型权重，也压缩了特征向量的维度。
  - deep侧为DNN，
    - DNN模型，输入的特征主要分为两大类，一类是数值特征(可直接输入DNN)，一类是类别特征(需要经过Embedding之后才能输入到DNN中)，Deep部分的数学形式如下： $$ a^{(l+1)} = f(W^{l}a^{(l)} + b^{l}) $$ 
    - 激活函数为Relu
- output：W&D模型是将两部分输出的结果结合起来联合训练，将deep和wide部分的输出重新使用一个逻辑回归模型做最终的预测，输出概率值。联合训练的数学形式如下：需要注意的是，因为Wide侧的数据是高维稀疏的，所以作者使用了 FTRL算法优化，而Deep侧使用的是 Adagrad。 $$ P(Y=1|x)=\delta(w_{wide}^T[x,\phi(x)] + w_{deep}^T a^{(lf)} + b) $$，对wide侧以及deep侧进行相加
  - 论文中wide侧和deep侧的输出维度都为1

![](Img/widedeep模型框架.png)

### 问题

- 为什么DNN加上lr能够起到好的效果

  - 模型的Wide部分增强了模型的记忆能力，弥补了DNN结构泛化性强而记忆性弱的不足。
  - Wide侧输入手动交叉的特征项，模型可以直接从人工经验中获取显式的关联模式，降低了学习难度。也可以理解为模型腾出了原本挖掘这部分模式的精力，去挖掘其它间接的复杂的模式，也可以理解为模型在学习这些输入的已知模式时，有了更多的信息，可以避开一些坑，减小模型掉入坑里的概率，增大模型接近最优解的可能。

- W&D模型中Wide侧和Deep侧的优化器有区别吗，为什么要区别对待，为什么会选择 AdaGrad 和 FTRL优化器。

  - 有区别：选择不同的优化器是因为Wide侧和Deep侧在模型中的作用不同，需要不同的优化策略来达到最佳的训练效果。AdaGrad和FTRL优化器的使用，使得W&D模型能够充分利用各自的优点，实现在训练过程中的稳定性和高效性。
  - Wide侧主要负责记忆，采用的是线性模型，由于线性模型之间特征是相互独立的，其可以通过学习历史数据中的高频模式来筛选出有价值的特征和特征组合。来增强其记忆性，保证搜索结果的准确性。
    - Wide侧的输入包含原始输入和原始输入的特征组合，这些组合特征是高维且稀疏的，为了处理稀疏特征，Wide侧使用的是FTRL优化器。可以让Wide部分变得更加的稀疏，也就是Wide部分的大部分参数都为0，大大压缩了模型权重及特征向量的维度，让模型更高效的去学习有价值的、显而易见的特征及特征组合，进一步增强模型的记忆能力。而且FTRL模型本身特别适合在线学习和大规模稀疏特征，能够实现较为准确的参数更新，同时考虑了正则化项，有助于防止模型过拟合，提高泛化能力。

  - Deep侧则主要用于扩展，引入embedding，模型通过MLP结构对特征进行间接和高阶的隐式交叉学习实现参数共享，并挖掘隐藏在数据间潜在关联模式，使模型有能力处理未见过的数据或模式。相比传统机器学习模型，具有更好的泛化性。有利于推荐效果中的新颖性这个维度，即对于数据中未出现的模式，模型也能做出相应的合理反应。
    - 对于深度学习模型，不同层或神经元可能需要不同的学习速率，因此Deep侧使用AdaGrad优化器。AdaGrad能够自适应地调整学习率，使得训练过程更加稳定，同时加快模型收敛速度。

- wide侧适合输入哪些特征：

  - Wide侧没有发现新的模式，只是学习到这些模式之间的权重，做一些模式的筛选。因此我们需要**根据人工经验、业务背景，将我们认为有价值的、显而易见的特征及特征组合，喂入Wide侧**

- 如何理解Wide部分有利于增强模型的“记忆能力”，Deep部分有利于增强模型的“泛化能力”？

  - Wide部分是一个广义的线性模型，输入的特征主要有两部分组成，一部分是原始的部分特征，另一部分是原始特征的交叉特征(cross-product transformation)，对于交互特征可以定义为： $$ \phi_{k}(x)=\prod_{i=1}^d x_i^{c_{ki}}, c_{ki}\in {0,1} $$ 是一个布尔变量，当第i个特征属于第k个特征组合时，$c_{ki}$的值为1，否则为0，$x_i$是第i个特征的值，大体意思就是两个特征都同时为1这个新的特征才能为1，否则就是0，说白了就是一个特征组合。用原论文的例子举例：

    > AND(user_installed_app=QQ, impression_app=WeChat)，当特征user_installed_app=QQ,和特征impression_app=WeChat取值都为1的时候，组合特征AND(user_installed_app=QQ, impression_app=WeChat)的取值才为1，否则为0。

    对于 Wide部分训练时候使用的优化器是带 $L_1$正则的FTRL算法(Follow-the-regularized-leader)，而L1 FTRL是非常注重模型稀疏性质的，也就是说W&D模型采用L1 FTRL是想让 Wide部分变得更加的稀疏，即 Wide部分的大部分参数都为0，这就大大压缩了模型权重及特征向量的维度。**Wide部分模型训练完之后留下来的特征都是非常重要的，那么模型的“记忆能力”就可以理解为发现"直接的"，“暴力的”，“显然的”关联规则的能力。**例如Google W&D期望 Wide部分发现这样的规则：**用户安装了应用A，此时曝光应用B，用户安装应用B的概率大。**

  - **Deep部分泛化能力**：它把能想到的所有特征扔进这个黑盒去做函数的拟合，显然这样的过程会“模糊”一些直接的因果关系，泛化成一些间接的，可能的相关性。**我们知道DNN模型随着层数的增加，中间的特征就越抽象，也就提高了模型的泛化能力。**对于 Deep部分的DNN模型作者使用了深度学习常用的优化器AdaGrad，这也是为了使得模型可以得到更精确的解。

- **为什么Deep部分不特别考虑稀疏性的问题？**

  Deep部分-**Age、App Installs等数值类特征、Embedding向量等特征**。Deep部分**不存在严重的特征稀疏问题**，自然可以使用精度更好，更适用于深度学习训练的AdaGrad去训练。

### 重点

- **记忆能力、为什么使用 FTRL**
  - Wide侧的输入包含原始输入和原始输入的特征组合，这些组合特征是高维且稀疏的，为了处理稀疏特征，Wide侧使用的是FTRL优化器。可以让Wide部分变得更加的稀疏，也就是 Wide部分的大部分参数都为0，大大压缩了模型权重及特征向量的维度，让模型更高效的去学习有价值的、显而易见的特征及特征组合，进一步增强模型的记忆能力。而且FTRL模型本身特别适合在线学习和大规模稀疏特征，能够实现较为准确的参数更新，同时考虑了正则化项，有助于防止模型过拟合，提高泛化能力。
  - 也可以理解为 Wide侧输入手动交叉的特征项，模型可以直接从人工经验中获取显式的关联模式，降低了学习难度。模型腾出了原本挖掘这部分模式的精力，去挖掘其它间接的复杂的模式，也可以理解为模型在学习这些输入的已知模式时，有了更多的信息，可以避开一些坑，减小模型掉入坑里的概率，增大模型接近最优解的可能。

- **Deep部分泛化能力**、为什么使用AdaGrad、有什么缺点
  - Deep侧主要用于扩展，引入embedding，模型通过MLP结构对特征进行间接和高阶的隐式交叉学习实现参数共享，并挖掘隐藏在数据间潜在关联模式，使模型有能力处理未见过的数据或模式。相比传统机器学习模型，具有更好的泛化性。有利于推荐效果中的新颖性这个维度，即对于数据中未出现的模式，模型也能做出相应的合理反应。
  - Deep部分**不存在严重的特征稀疏问题**，且对于深度学习模型，不同层或神经元可能需要不同的学习速率，因此 Deep侧使用AdaGrad优化器。AdaGrad能够自适应地调整学习率，使得训练过程更加稳定，同时加快模型收敛速度，使得模型可以得到更精确的解。
  - 缺点
    - 隐式学习特征交叉相比于人工显式特征交叉，挖掘数据中的已有模式的难度增加，导致模型的记忆性减弱，不利于推荐的准确性。
    - 对于某些特定的场景(数据分布长尾， 共现矩阵稀疏高秩）很难有效学习低纬度的表示， 造成推荐的过度泛化。

# 样本

## 负样本采样

### 推荐系统中有哪些场景是无法获得真负样本的？如何解决？

个性化推荐。App内部的推荐，我们可以根据埋点，比较容易获知用户滑过、忽略了某些推荐内容，所以比较有信心拿哪些item作为负样本。但是在推送场景下，我们很难知道用户未点击的item是用户真的不喜欢还是压根没看见。所以不能放心地将所有未点击的item都当负样本。

在这种无法获得真负样本的场景下，一般我们通过随机采样来获得负样本。但是，随机采样毕竟引入了噪声，这时，再用CTR预估这种要求"绝对准确性"的算法，就不合适了。所以，在召回或个性化推送场景下，我们一般采用 **pairwise LearningToRank** 建模排序的相对准确性。

### 为什么不能只拿曝光未点击做召回模型的负样本？

我们希望召回训练数据的正样本是user和item匹配度最高的那些样本，也即用户点击样本，负样本是user和item最不匹配的那些样本，但不能拿“曝光未点击”作为召回模型的负样本，因为我们从线上日志获得的训练样本，已经是上一版本的召回、粗排、精排替用户筛选过的，即已经是对用户“匹配度较高”的样本了，即推荐系统以为用户会喜欢他们，但用户的行为又表明的对他的嫌弃。拿这样的样本训练出来的模型做召回，并不能与线上环境的数据分布保持一致。也就是说曝光未点击既不能成为合格的正样本，也不能成为合格的负样本。

所以一般的做法是拿点击样本做正样本，拿随机采样做负样本，因为线上召回时，候选库里大多数的物料是与用户没有关系的，随机抽样能够很好地模拟这一分布。

## 正样本采样

### 热门打压

- 生成正样本 item+ 时，打压高热 item

  目的是为了降低 item 成为 **item+** 的可能性。因此，item越热门，其成为 **item+** 的概率就应该越低。

  一个item成为 **item+** 的概率
  $$
  P_{pos}(w_i)=(\sqrt{\frac{z(w_i)}{a}} + 1)\frac{a}{z(w_i)}
  $$

  $$
  z(w_i)=\frac{点击过w_i的用户数}{同时段所有发生过点击行为的用户总数}
  $$

  a 为一个超参数，一般在 1e<sup>-3</sup>~1e<sup>-5</sup> 之间

  可以看出 z(w<sub>i</sub>) 越高，item成为 item+ 的概率就越低，从而实现了对热门item的打压。

  而对于一些罕见item，按照公式计算出的概率大于1，说明罕见的item只要被点击过，就一定会被当成正样本。

# 其他

## AB实验

- **定义**

  **A/B 测试**为一种随机测试，将两个不同的东西（即A和B）进行假设比较。该测试运用统计学上的**假设检定**和**双母体假设检定**。A/B 测试可以用来测试某一个变量两个不同版本的差异，一般是让A和B只有该变量不同，再测试其他人对于A和B的反映差异，再判断A和B的方式何者较佳。

  在同一时间对于目标受众做科学抽样、分组测试以评估效果。因为**时间**也是属于**变量**的一部分，比如说平时和双十一期间，gmv一定是双十一期间来的高。

- **为什么要做A/B测试**

  **A/B测试** 可以帮助业务进行最终决策，并且有充分的数据来支撑你的论点。

  - **风险控制**：小流量实验可以避免直接上线效果不好以造成损失。其次，实验迭代的过程中，决策都是有科学依据的，可以避免系统性的偏差
  - **因果推断**：我们推断 A/B实验 中的优化和改变最终能影响到线上数据以及用户行为。A/B测试 可以帮助证明或者推翻我们的推断
  - **复利效应**：A/B测试 是可以持续不断进行的实验，即使一次实验提升的效果不大，但是长期下来复利效应的积累会产生很大的变化和回报

- **A/B test 流程**

  - 分析现状，建立假设：分析业务，确定最高优先级的改进点，作出假设，提出优化建议。
  - 设定指标：设置主要指标来衡量版本的优劣；设置辅助指标来评估其他影响。
  - 设计与开发：设计优化版本的原型并完成开发。
  - 确定测试时长：确定测试进行的时长。
  - 确定分流方案：确定每个测试版本的分流比例及其他分流细节。
  - 采集并分析数据：收集实验数据，进行有效性和效果判断。
  - 给出结论：①确定发布新版本；②调整分流比例继续测试；③优化迭代方案重新开发，回到步骤1。

- **分流&分层的策略**

  如果流量人群不进行分流和分层，则会导致某一个实验占的流量很多，变相导致另一个实验的流量锐减，从而得到的实验结果会有统计学上的误差。

  - **分流策略**

    - Random——随机分流：
    - Partition By User——按用户切分：
    - Partition By Category——按分类切分：

  - **分流分层规则**

    - 正交与互斥：

      - 正交：每个独立实验为一层，层与层之间是正交的，流量穿越每层实验时，都会被随机打乱，且随机结果离散
      - 互斥：实验在同一层拆分流量，且同一层内不同组的流量是不互相重叠的

    - 分流模型

      域1和域2拆分流量，此时域1和域2是互斥的

      流量经过域2中的B1层、B2层、B3层，B1层、B2层、B3层的流量都是与域2的流量相等。此时B1层、B2层、B3层的流量是正交的。

      流量流过域2中的B1层时，又把B1层分为了B1-1，B1-2，B1-3，此时B1-1，B1-2，B1-3之间又是互斥的

    - 规则使用场景

      比如B1层、B2层、B3层可能分别为：UI层、搜索结果层、广告结果层，这些层基本上是没有任何业务关联的，即使使用相同的流量（流量正交）也不会对实际业务结果造成影响。但是不同层之间所进行的实验相互关联，就会影响下游实验。因此建议同一类型的实验在同一层内进行，并且要考虑不同实验之间相互的依赖

- **其他技术**

  - **p-value**：概率，主要在 A/B测试 中说明实验提升的显著性，并且往往与假设检验相挂钩。

    - p < 0.05：有统计学差异
    - p < 0.01：有显著统计学差异
    - p < 0.001：有极其显著的统计学差异

    在实践中可以先设置空跑期，进行AA test，来检查流量分布是否均匀

  - **假设检验**：是推论统计中用于检验现有数据是否足以支持特定假设的方法。一旦能估计未知参数，就会希望根据结果对未知的真正参数值做出适当的推论。假设检验的步骤如下：

    - 最初研究假设为真相不明
    - 提出相关的零假设和备择假设
    - 考虑检验中对样本做出的统计假设
    - 选择一个显著性水平 α
    - 选择适合的检验统计量 T
    - 在设定零假设为真下推导检验统计量的分布
    - 根据在零假设成立时的检验统计量T分布，找到概率为显著性水平 (α) 的区域，此区域称为“拒绝域”(记作RR或CR)，即在零假设成立的前提下，落在拒绝域的概率只有α。
    - 针对检验统计量T，根据样本计算其估计值t<sub>obs</sub>
    - 若估计值t<sub>obs</sub>未落在拒绝域，则“不拒绝”零假设（do no reject 𝐻<sub>0</sub>）。若估计值t<sub>obs</sub>落在拒绝域，则拒绝零假设，接受备择假设。

## AB实验中常见的问题

### 用户抽样不科学

先来看一组数据

| 学院 | 女生申请数 | 女生录取数 | 女生录取率 | 男生申请数 | 男生录取数 | 男生录取率 | 申请总数 | 录取总数 | 总录取率 |
| ---- | ---------- | ---------- | ---------- | ---------- | ---------- | ---------- | -------- | -------- | -------- |
| 1    | 100        | 49         | 49%        | 20         | 15         | 75%        | 120      | 64       | 53.3%    |
| 2    | 20         | 1          | 5%         | 100        | 10         | 10%        | 120      | 11       | 9.2%     |
| 总计 | 120        | 50         | 42%        | 120        | 25         | 21%        | 240      | 75       | 31.3%    |

单看男生，无论是1号学院还是2号学院，男生录取率都高于女生，因此总体的录取率是不是也是男生高于女生呢？

统计出来并不是，男生的总体录取率要远低于女生，这种现象就被称为辛普森悖论

- **辛普森悖论**：几组不同的数据中均存在一种趋势，但当这些数据组合在一起后，这种趋势消失或反转。其产生的原因主要是数据中存在多个变量。这些变量通常难以识别，被称为“潜伏变量”。潜伏变量可能是由于采样错误造成的。

在 A/B 测试 中，如果实验组和对照组的样本流量分布不一致，就有可能产生辛普森悖论

### 互斥层选择错误

- 互斥层选择原则：
  - 假设实验之间有相关性，那么实验必须置于同一互斥层；
  - 假设实验之间没有相关性，那么实验可以至于不同互斥层

### 不考虑是否显著

只简单地观测实验数据的涨跌，不去考虑实验结果是否显著

## 评价指标

### Hinge

通常用于 maximum-margin 的分类任务中，如支持向量机
$$
L(y)=max(0, 1-\hat{y}y)
$$
以支持向量机为例，其模型为
$$
\hat{y}=w·x
$$
其求导结果如下
$$
\frac{\partial{L}}{\partial{w_i}}=
\begin{cases}
-yx_i, \hat{y}y > 1\\ 
0,  otherwise
\end{cases}
$$
实际应用中，一方面很多时候我们 y 的值域并不是-1~1，比如我们更希望y更接近于一个概率，其值域最好是0~1。另一方面，很多时候我们希望训练的是两个样本之间的相似关系，而非样本的整体关系，所以很多时候我们会用下面的公式
$$
L(y,y^{'})=max(0, m-y+y^{'})
$$
其中，y是正样本的得分，y<sup>'</sup> 是负样本的得分，m是margin

即我们希望正样本分数越高越好，负样本分数越低越好

### Cross-Entropy

### MSE

### 搜索评价指标——NDCG

NDCG，Normalized Discounted cumulative gain(归一化折损累计增益)。

#### 主要思想：

- 高关联度的结果比一般关联度的结果更影响最终的指标得分
- 有高关联度的结果出现在更靠前的位置的时候，指标会越高

#### 累计增益（CG）

CG，cumulative gain，是DCG的前身，只考虑了相关性的关联程度，没有考虑到位置的因素。它是一个搜索结果相关性分数的总和。指定位置p上的CG为：
$$
CG_p=\sum_{i=1}^prel_i
$$
rel<sub>i</sub> 代表这个位置上的相关度

比如：假设搜索 篮球 结果，最理想的是B1、B2、B3。而出现的结果是 B3、B1、B2的话，CG的值是不会变的

#### 折损累计增益（DCG）

DCG，Discounted的CG，就是在每一个CG的结果上除以一个折损值。

目的：为了让排名越靠前的结果越能影响最后的结果。
$$
DCG_p=\sum_{i=1}^p\frac{rel_i}{log_2(i+1)}=rel_1+\sum_{i=2}^p\frac{rel_i}{log_2(i+1)}
$$
还有一种比较常用的公式，用来增加相关度影响比重的DCG计算方式
$$
DCG_p=\sum_{i=1}^p\frac{2^{rel_i}-1}{log_2(i+1)}
$$
后一种更多用于工业。当相关值为二进制时，二者结果是一致的。

#### 归一化折损累计增益（NDCG）

NDCG，Normalized的DCG，由于搜索结果随着检索词的不同，返回的数量是不同的，而DCG是一个累加的值，没法针对两个不同的搜索结果进行比较，因此需要归一化处理。
$$
nDCG_p=\frac{DCG_p}{IDCG_p}
$$
IDCG为理想情况下最大的DCG值
$$
IDCG_p=\sum_{i=1}^{|REL|}\frac{2^{rel_i}-1}{log_2(i+1)}
$$
其中 |REL| 表示，结果按照相关性从大到小的顺序排序，取前p个结果组成的集合。也就是按照最优的方式对结果进行排序

#### 示例

假设搜索回来的结果，其相关性分数分别是 3、2、3、0、1、2

那么CG = 3+2+3+0+1+2=11

可以看到只是对相关的分数进行了一个关联的打分，并没有召回的所在位置对排序结果评分的影响。而我们看DCG：

| i    | reli | log2(i+1) | reli/log2(i+1) |
| ---- | ---- | --------- | -------------- |
| 1    | 3    | 1         | 3              |
| 2    | 2    | 1.58      | 1.26           |
| 3    | 3    | 2         | 1.5            |
| 4    | 0    | 2.32      | 0              |
| 5    | 1    | 2.58      | 0.38           |
| 6    | 2    | 2.8       | 0.71           |

所以DCG = 3+1.26+1.5+0+0.38+0.71 = 6.86

接下来我们归一化，归一化需要先结算 IDCG，假如我们实际召回了8个物品，除了上面的6个，还有两个结果，假设第7个相关性为3，第8个相关性为0。那么在理想情况下的相关性分数排序应该是：3、3、3、2、2、1、0、0。计算IDCG@6:

| i    | reli | log2(i+1) | reli/log2(i+1) |
| ---- | ---- | --------- | -------------- |
| 1    | 3    | 1         | 3              |
| 2    | 3    | 1.58      | 1.89           |
| 3    | 3    | 2         | 1.5            |
| 4    | 2    | 2.32      | 0.86           |
| 5    | 2    | 2.58      | 0.77           |
| 6    | 1    | 2.8       | 0.35           |

所以IDCG = 3+1.89+1.5+0.86+0.77+0.35 = 8.37

因此最终 NDCG@6 = 6.86/8.37 = 81.96%
