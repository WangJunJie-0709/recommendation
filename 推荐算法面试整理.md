[TOC]

# 机器学习算法

## 逻辑斯蒂回归（Logistic Regression，LR）



## 协同过滤

### 1 目标场景

存在共现矩阵的情况下，进行点击率预估、评分预测等等

### 2 基本思想

物以类聚，人以群分。

### 3 相似度计算方式

- 杰卡德（Jaccard）相似度

  这个是**衡量两个集合的相似度的一种指标**。两个集合A和B的交集元素在A，B的并集中所占的比例，称为两个集合的杰卡德相似系数
  $$
  J(A,B)=\frac{|A\cap{B}|}{|A\cup{B}|}
  $$

- 余弦相似度

  衡量了用户向量之间向量夹角的大小，夹角越小，说明相似度越大，两个用户越相似
  $$
  sim(i,j)=cos(i,j)=\frac{i·j}{||i||·||j||}
  $$
  **局限性：**对于评分数据不规范的时候，存在有的用户喜欢打高分，有的用户喜欢打低分情况的时候，有的用户喜欢乱打分的情况，这时候余弦相似度算出来的结果可能就不是那么准确了。

- 皮尔逊相关系数

  皮尔逊相关系数通过使用用户平均分对个体独立评分进行修正，减少了用户评分偏置的影响
  $$
  sim(i,j)=\frac{\sum_{p\in{P}}(R_{i,p}-\overline{R_i})(R_{jp}-\overline{R_j})}{\sqrt{\sum_{p\in{P}}(R_{i,p}-\overline{R_i})^2}\sqrt{\sum_{p\in{P}}(R_{jp}-\overline{R_j})^2}}
  $$

- 其他

- 余弦相似度VS欧式距离

### 4 基于User的协同过滤 UserCF

- 步骤：

  - 计算用户A与其他用户的相似度

  - 根据相似度用户计算用户A对物品的最终评分
    $$
    R_{u,p}=\frac{\sum_{s\in{S}}(w_{u,s}R_{s,p})}{\sum_{s\in{S}}w_{u,s}}
    $$

  - 根据用户评分对用户进行推荐：定一个阈值，预测评分超过阈值即可推荐给用户

- 缺点：

  - 数据稀疏性：

    一个大型的电子商务推荐系统一般有非常多的物品，用户可能买的其中不到1%的物品，不同用户之间买的物品重叠性较低，导致算法无法找到一个用户的邻居，即偏好相似的用户，即使找到准确性也不会太高。这导致UserCF不适用于那些正反馈获取较困难的应用场景

  - 用户相似度矩阵维护难度大：

    绝大多数产品的用户数都要远大于物品数，因此维护用户相似度矩阵的难度要大得多；用户相似度矩阵的存储空间随着用户数量的增加而增加，不适合用户数据量大的情况的使用。

- 适用场景：常适用于用户少，物品多，时效性较强的场合

### 5 基于Item的协同过滤 ItemCF

- 步骤：
  - 首先计算待选物品和其他物品的相似度
  - 找出与待选物品最相似的n个物品
  - 根据用户对这n个物品的打分去计算对待选物品的打分情况
- 优点：
  - ItemCF算法的预测结果比UserCF算法质量要高一些
  - 由于ItemCF算法可以预先计算好物品的相似度，所以在线的预测性能要比UserCF算法高
- 缺点：
  - 数据稀疏性
  - 物品相似度矩阵维护难度大
- 适用场景：

### 6 UserCF和ItemCF的优缺点对比

- 区别 

  ![image-20220405163844329](F:\面试\推荐算法\图片\UserCF和ItemCF区别.png)

- 共同的缺点

  - 不能彻底解决数据稀疏性问题
  - 泛化能力弱
    - 热门物品具有很强的头部效应，容易跟大量物品产生相似，而尾部物品由于特征向量稀疏，导致很少被推荐
    - 为解决这一问题，矩阵分解技术被提出
  - 无法利用更多的信息：**一般是仅仅基于用户的行为数据**，而不依赖于任何附加信息或者用户的任何附加信息，比如不依赖物品自身特征、用户性别、年龄等

### 7 协同过滤算法的优缺点

- 优点：
  - 算法原理朴素简单，即"物以类聚，人以群分"，已得到工业界验证过的一类重要算法，在大型互联网公司都有很好的落地和应用
  - 易使用Spark分布平台来实现，因此可以通过增加计算节点很容易处理大规模数据集。
  - 可以很好的为用户推荐多样性、新颖性的item，特别是当群体规模越大、用户行为越多，推荐的效果越好
  - 只依赖用户的操作行为，不依赖具体user相关和item相关的信息就可以实现
- 缺点：
  - 冷启动问题：如果用户行为少，这时就很难发挥协同过滤算法的优势和价值，甚至无法为用户做推荐
  - 稀疏性问题：互联网产品用户基数大，item数量多，一般用户只对很少量的item产生操作行为，这时用户操作行为矩阵是非常稀疏的，太稀疏的行为矩阵计算出的item相似度往往不够精准，最终影响推荐结果的精确度。

## 矩阵分解（Matrix Factorization，MF）

矩阵分解也叫做隐语义模型
$$
p(u,i)=p^T_uq_i=\sum_{f=1}^{F}{p_{uf}q_{if}}
$$

- LFM的损失函数：未正则化和正则化

$$
loss=\sum(p(u,i)-p^{LFM}(u,i))^2
$$

$$
loss=\sum(p(u,i)-p^{LFM}(u,i))^2+\alpha|p_u|^2+\alpha|q_i|^2
$$

- LFM算法迭代，对其求偏导
  $$
  \frac{\partial{loss}}{\partial{p_{uf}}} = -2(p(u,i)-p^{LFM}(u,i))q_{if}+2\partial{p_{uf}}
  $$

  $$
  \frac{\partial{loss}}{\partial{q_{if}}} = -2(p(u,i)-p^{LFM}(u,i))p_{uf}+2\partial{q_{if}}
  $$

- 梯度下降
  $$
  p_{uf}=p_{uf} - \beta\frac{\partial{loss}}{\partial{p_{uf}}}
  $$

  $$
  q_{if}=q_{if} - \beta\frac{\partial{loss}}{\partial{q_{if}}}
  $$

- 影响训练效果的因素

  - 负样本的选取
  - 隐特征F，正则化参数，learning rate

- LFM vs CF

  - LFM是属于监督学习的分支，通过训练样本的label设定损失函数，利用最优化方法来使得损失函数最小化，从而得到最优模型；CF是通过公式建模求解相似度矩阵
  - LFM空间复杂度为O(max(M×F，N×F))，CF的空间复杂度为O(M<sup>2</sup>)或O(N<sup>2</sup>)，离线计算LFM较快
  - CF可较好地实时计算，LFM响应不及时，实时计算CF较快

## 因子分解机（Factorization Machine，FM）

- 针对问题

  - 旨在解决稀疏数据下的特征组合问题

  - 在面对稀疏特征向量时，Poly2特征交叉项无法收敛
    $$
    y(x)=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^n\sum_{j=i+1}^nw_{ij}x_ix_j
    $$
    多项式模型是包含特征组合的最直观的模型，当$x_i$ 和 $x_j$ 都非零时，组合特征才有意义。组合特征的参数一共有 $\frac{n(n-1)}{2}$ 个，任意两个参数都是独立的。然而在数据稀疏性普遍存在的实际应用场景中，二次项参数的训练是很困难的。其原因是每个参数的训练都需要大量非零的样本，这部分样本非常少，容易导致参数不准确，严重影响模型性能

  - **Poly2 **计算复杂度过高

- 改进思路：当 k 足够大的时候，对于**任意对称正定的实矩阵W**，均存在实矩阵V，使得 W = V·V<sup>T</sup>

- 数学模型，隐向量长度 k << n
  $$
  y=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n-1}\sum_{j=i+1}^n<v_i,v_j>x_ix_j,<v_i,v_j>=\sum_{f=1}^kv_{i,f}v_{j,f}
  $$

  - 参考$ab + ac +bc = \frac{1}{2}[(a+b+c)^2 - (a^2 + b^2 + c^2)]$    所以得出
    $$
    \begin{align*}
        &\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}<v_i,v_j>x_ix_j \\
        &= \frac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{n}<v_i,v_j>x_ix_j - \frac{1}{2}\sum_{i=1}^{n}<v_i,v_i>x_ix_i & (1)\\
        &= \frac{1}{2} ( \sum_{i=1}^{n}\sum_{j=1}^n\sum_{f=1}^{k}v_{i,f}\,v_{j,f}x_ix_j - \frac{1}{2}\sum_{i=1}^{n}\sum_{f=1}^{k}v_{i,f}\,v_{i,f}x_ix_i )  & (2)\\
        &= \frac{1}{2}\sum_{f=1}^{k}(\sum_{i=1}^{n}v_{i,f}x_i · \sum_{j=1}^{n}v_{j,f}x_j - \ \sum_{i=1}^{n}v_{i,f}^2x_i^2) & (3)\\
        &= \frac{1}{2}\sum_{f=1}^{k}[(\sum_{i=1}^{n}v_{i,f}x_i)^2 -  \sum_{i=1}^{n}v_{i,f}^2x_i^2 ] & (4)
    \end{align*}
    $$

  - 第1个等号：对称矩阵 $w_{ij}$对角线上半部分；

  - 第2个等号：把向量内积 $<v_i,v_i>$ 展开成累加和的形式；

  - 第3个等号：提出公共部分；

  - 第4个等号： $i$ 和 $j$  相当于是一样的，表示成平方过程。

- 损失函数
  $$
  J(w_0,w_1,w_2,...,w_n,w_{12},w_{13},...,w_{n-1,n})=-\frac{1}{m}\sum_{i=1}^my^{(i)}logy^{(i)}_{pre}+(1-y^{(i)})log(1-y^{(i)}_{pre})
  $$

- 梯度下降
  $$
  y=w_0+\sum_{i=1}^nw_ix_i+\frac{1}{2}\sum_{f=1}^k[(\sum_{i=1}^nv_{i,f}x_i)^2-\sum_{i=1}^n(v_{i,f}x_i)^2]
  $$

- 优点

  - 极大降低了训练开销 O($n^2$)->O(kn)
  - **隐向量的引入**，使得FM能更好解决数据稀疏性的问题：
    - 这里可以观察到，**交叉项的权重是两个矩阵的点乘而不直接是一个权重矩阵**，这是因为类型变量经过One-Hot或其他类似形式的编码后，会产生高维稀疏矩阵，导致有的交叉项在训练样本中从未出现过，如直接是一个权重矩阵则权重为0，训练不出相关信息。因而相当于是通过矩阵分解的形式，将原本的权重矩阵表示为两个矩阵相乘。这样，即使交叉项为0还是可以得到相关权重，以此解决高维稀疏矩阵的问题。
  - **FM模型是利用两个特征的Embedding做内积得到二阶特征交叉的权重**，那么我们可以将训练好的FM特征取出离线存好，之后用来做其他扩展

- 与其他模型的对比

  - 相比于SVM的二阶多项式核而言，FM在样本稀疏的情况下是有优势的；而且，FM的训练/预测复杂度是线性的，而二阶多项式核SVM需要计算核矩阵，核矩阵复杂度是 $N^2$ 

  - 相比于MF而言，我们把MF中每一项的rating分改写为 
    $$
    r_{ui}=\beta_u+\gamma_i+x_u^Ty_i
    $$
    从上述公式可以看出，这相当于只有两类特征 u 和 i 的FM模型。对于 FM 而言，我们可以加任意多的特征，比如 user 的历史购买平均值，item 的历史购买平均值等。但是MF只能局限在两类特征。在特征的扩展性上不如 FM

- FM模型做统一的召回模型
  - 统一召回
    - 优点：无论候选 Item 来自于哪里，它们在召回阶段的得分是完全可比的
    - 缺点：将多个白箱变成了一个黑箱子，使得召回路变得不可解释了。
  - 多路召回
    - 优点：有可解释性，更加灵活。
    - 缺点：每一路召回因为采取的策略或者模型不同，所以各自的召回模型得分不可比较。比如利用协同过滤召回找到的候选Item得分，与基于兴趣标签这一路召回找到的候选Ite得分，完全是不可比较的。

## FM引入特征域（Field-ware Factorization Machines，FFM）

相比于FM，FFM模型引入了特征域的概念，其数学形式的二阶部分如下
$$
FM(w,x)=\sum_{j_1=1}^n\sum_{j_2=j_1+1}^n(w_{j_1f_2}w_{j_2f_1})x_{j_1}x_{j_2}
$$
FFM 将相同性质的特征都归于同一个 field。简单来说，同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个field，包括用户性别、职业、品类偏好等。

其与FM的区别在于隐向量由原来的 $w_{j1}$ 变成了 $w_{j1f2}$，这意味着每个特征对应的不是唯一一个隐向量，而是一组隐向量。当 $x_{j1}$ 特征与 $x_{j2}$特征进行交叉时， $x_{j1}$ 会从 $x_{j1}$ 的这一组隐向量中挑出与 $x_{j2}$ 的域对应的隐向量 $w_{j1f2}$ 进行交叉。

假设样本的 n 个特征属于 f 个field，那么FFM的二次项有 nf 个隐向量。而在FM模型中，每一维特征的隐向量只有一个。FM可以看作FFM的特例，就是把所有特征都归属到一个field的FFM模型。

如果隐向量的长度为k，那么FFM的二次参数有 nfk 个，远多于FM模型的 nk 个。此外，由于隐向量与field相关，FFM二次项并不能化简，预测复杂度为 O($kn^2$)

- FFM的SGD优化过程。算法输入 tr、va、pa分别是训练样本集、验证样本集和训练参数设置

  - 根据样本特征数量（tr.n）、field的个数（tr.m）和训练参数（pa），生成初始化模型，即随机生成模型的参数；

  - 如果归一化参数pa.norm为真，计算训练和验证样本的归一化系数，样本 i 的归一化系数为
    $$
    R[i]=\frac{1}{||X[i]||}
    $$

  - 对每一轮迭代，随机打乱训练样本的顺序

  - 对每一个训练样本，执行如下操作

    - 计算每一个样本的FFM项
    - 计算每一个样本的训练误差
    - 利用单个样本的损失函数计算梯度，再根据梯度更新模型参数

  - 对每一个验证样本，计算样本的FFM输出，计算验证误差

  - 重复步骤3~5，直到迭代结束或验证误差达到最小



# 深度学习

## DeepFM



## Wide&Deep

### wide&deep动机

- LR（**Memorization**）：线性模型，具有较强的记忆性
  - 前深度学习 主要是使用 LR模型，通过大量的精细特征工程，利用其较强记性挖掘信息，保证预测结果的准确性。但是会导致用户兴趣收敛，无新鲜感，不利于长久的用户留存
  - 缺点：
    - 此种方式非常依赖人工经验挖掘数据中的特征交互模式。
    - 线性模型特征与特征之间在模型中是独立的，对于训练中未出现过的数据或模式，模型无法学习对应的参数，从而使模型对这些数据的预估能力弱。

- DNN（**generalization**）：借助embedding化实现参数空间的共享，即使对于未见过的数据，也具有一定的预估能力。
  - DNN引入embedding，模型通过MLP结构对特征进行复杂、间接和高阶的隐式交叉学习，挖掘隐藏在数据间潜在关联模式，使模型有能力处理未见过的数据或模式。相比传统机器学习模型，具有更好的泛化性。有利于推荐效果中的新颖性这个维度，即对于数据中未出现的模式，模型也能做出相应的合理反应。
  - 缺点：
    - 隐式学习特征交叉相比于人工显式特征交叉，挖掘数据中的已有模式的难度增加，导致模型的记忆性减弱，不利于推荐的准确性。
    - 对于某些特定的场景(数据分布长尾， 共现矩阵稀疏高秩）很难有效学习低纬度的表示， 造成推荐的过渡泛化。
    - DNN结构的效果相比于传统的机器学习模型，没有明显的优势，这与推荐场景中特征的高维稀疏性有关。
- wide&deep
  - wide&deep模型的整体框架设计思路清晰简洁，就是在DNN结构的基础上融合了LR结构，加强了模型处理高维稀疏特征的能力, 使模型兼具泛化性和记忆性，效果得到提升，也使得深度模型在推荐领域开始普及。

### widedeep模型架构

- input：
  - x_wide：
    - 包含**原始特征**和转换的**共现组合特征**（corss-product特征）
    - Linear Model采用的是 FTRL 模型，让Wide部分变得更加的稀疏，即Wide部分的大部分参数都为0，压缩了模型权重及特征向量的维度。Wide部分模型训练完之后留下来的特征都是非常重要的，那么模型的“记忆能力”就可以理解为发现"直接的"，“暴力的”，“显然的”关联规则的能力
  - x_deep：通过embedding的方式将categorical/id特征映射成稠密向量，让DNN学习到这些特征之间的**深层交叉**，以增强扩展能力
- hidden：全连接网络，一般为3层
  - wide侧使用FTRL
    - 为什么使用FTRL
      - Wide部分采用了两个id类特征(当前曝光app和用户安装app)的乘积，两个id类特征向量进行组合，在维度爆炸的同时，会让原本已经非常稀疏的multihot特征向量，变得更加稀疏。wide部分的权重数量其实是海量的。为了不把数量如此之巨的权重都搬到线上进行model serving，采用FTRL过滤掉哪些稀疏特征无疑是非常好的工程经验。
      - FTRL是一个**稀疏性很好**，**精度又不错**的**随机梯度下降方法**。由于是随机梯度下降，当然可以做到来一个样本就训练一次，进而实现模型的在线更新。
      - L1正则化，**FTRL with L1非常注重模型的稀疏性。这也就是问题的答案，W&D采用L1 FTRL是想让Wide部分变得更加稀疏。**压缩模型权重，也压缩了特征向量的维度。
  - deep侧为DNN，
    - DNN模型，输入的特征主要分为两大类，一类是数值特征(可直接输入DNN)，一类是类别特征(需要经过 Embedding 之后才能输入到DNN中)，Deep部分的数学形式如下： $$ a^{(l+1)} = f(W^{l}a^{(l)} + b^{l}) $$ 
    - 激活函数为Relu
- output：W&D模型是将两部分输出的结果结合起来联合训练，将deep和wide部分的输出重新使用一个逻辑回归模型做最终的预测，输出概率值。联合训练的数学形式如下：需要注意的是，因为Wide侧的数据是高维稀疏的，所以作者使用了 **FTRL算法**优化，而Deep侧使用的是 **Adagrad**。 $$ P(Y=1|x)=\delta(w_{wide}^T[x,\phi(x)] + w_{deep}^T a^{(lf)} + b) $$，对wide侧以及deep侧进行相加
  - 论文中wide侧和deep侧的输出维度都为1

![](Img/widedeep模型框架.png)

### 问题

- 为什么DNN加上 lr 能够起到好的效果

  - 模型的Wide部分增强了模型的记忆能力，弥补了DNN结构泛化性强而记忆性弱的不足。
  - Wide侧输入手动交叉的特征项，模型可以直接从人工经验中获取显式的关联模式，降低了学习难度。也可以理解为模型腾出了原本挖掘这部分模式的精力，去挖掘其它间接的复杂的模式，也可以理解为模型在学习这些输入的已知模式时，有了更多的信息，可以避开一些坑，减小模型掉入坑里的概率，增大模型接近最优解的可能。

- W&D模型中Wide侧和Deep侧的优化器有区别吗，为什么要区别对待，为什么会选择 AdaGrad 和 FTRL优化器。

  - 有区别：选择不同的优化器是因为Wide侧和Deep侧在模型中的作用不同，需要不同的优化策略来达到最佳的训练效果。AdaGrad和FTRL优化器的使用，使得W&D模型能够充分利用各自的优点，实现在训练过程中的稳定性和高效性。
  - Wide侧主要负责记忆，采用的是线性模型，由于线性模型之间特征是相互独立的，其可以通过学习历史数据中的高频模式来筛选出有价值的特征和特征组合。来增强其记忆性，保证搜索结果的准确性。
    - Wide侧的输入包含原始输入和原始输入的特征组合，这些组合特征是高维且稀疏的，为了处理稀疏特征，Wide侧使用的是FTRL优化器。可以让Wide部分变得更加的稀疏，也就是Wide部分的大部分参数都为0，大大压缩了模型权重及特征向量的维度，让模型更高效的去学习有价值的、显而易见的特征及特征组合，进一步增强模型的记忆能力。而且FTRL模型本身特别适合在线学习和大规模稀疏特征，能够实现较为准确的参数更新，同时考虑了正则化项，有助于防止模型过拟合，提高泛化能力。

  - Deep侧则主要用于扩展，引入embedding，模型通过MLP结构对特征进行间接和高阶的隐式交叉学习实现参数共享，并挖掘隐藏在数据间潜在关联模式，使模型有能力处理未见过的数据或模式。相比传统机器学习模型，具有更好的泛化性。有利于推荐效果中的新颖性这个维度，即对于数据中未出现的模式，模型也能做出相应的合理反应。
    - 对于深度学习模型，不同层或神经元可能需要不同的学习速率，因此Deep侧使用AdaGrad优化器。AdaGrad能够自适应地调整学习率，使得训练过程更加稳定，同时加快模型收敛速度。

- wide侧适合输入哪些特征：

  - Wide侧没有发现新的模式，只是学习到这些模式之间的权重，做一些模式的筛选。因此我们需要**根据人工经验、业务背景，将我们认为有价值的、显而易见的特征及特征组合，喂入Wide侧**

- 如何理解Wide部分有利于增强模型的“记忆能力”，Deep部分有利于增强模型的“泛化能力”？

  - Wide部分是一个广义的线性模型，输入的特征主要有两部分组成，一部分是原始的部分特征，另一部分是原始特征的交叉特征(cross-product transformation)，对于交互特征可以定义为： $$ \phi_{k}(x)=\prod_{i=1}^d x_i^{c_{ki}}, c_{ki}\in {0,1} $$ 是一个布尔变量，当第i个特征属于第k个特征组合时，$c_{ki}$的值为1，否则为0，$x_i$是第i个特征的值，大体意思就是两个特征都同时为1这个新的特征才能为1，否则就是0，说白了就是一个特征组合。用原论文的例子举例：

    > AND(user_installed_app=QQ, impression_app=WeChat)，当特征user_installed_app=QQ,和特征impression_app=WeChat取值都为1的时候，组合特征AND(user_installed_app=QQ, impression_app=WeChat)的取值才为1，否则为0。

    对于 Wide部分训练时候使用的优化器是带 $L_1$正则的FTRL算法(Follow-the-regularized-leader)，而L1 FTRL是非常注重模型稀疏性质的，也就是说W&D模型采用L1 FTRL是想让 Wide部分变得更加的稀疏，即 Wide部分的大部分参数都为0，这就大大压缩了模型权重及特征向量的维度。**Wide部分模型训练完之后留下来的特征都是非常重要的，那么模型的“记忆能力”就可以理解为发现"直接的"，“暴力的”，“显然的”关联规则的能力。**例如Google W&D期望 Wide部分发现这样的规则：**用户安装了应用A，此时曝光应用B，用户安装应用B的概率大。**

  - **Deep部分泛化能力**：它把能想到的所有特征扔进这个黑盒去做函数的拟合，显然这样的过程会“模糊”一些直接的因果关系，泛化成一些间接的，可能的相关性。**我们知道DNN模型随着层数的增加，中间的特征就越抽象，也就提高了模型的泛化能力。**对于 Deep部分的DNN模型作者使用了深度学习常用的优化器AdaGrad，这也是为了使得模型可以得到更精确的解。

- **为什么Deep部分不特别考虑稀疏性的问题？**

  Deep部分-**Age、App Installs等数值类特征、Embedding向量等特征**。Deep部分**不存在严重的特征稀疏问题**，自然可以使用精度更好，更适用于深度学习训练的AdaGrad去训练。

### 重点

- **记忆能力、为什么使用 FTRL**
  - Wide侧的输入包含原始输入和原始输入的特征组合，这些组合特征是高维且稀疏的，为了处理稀疏特征，Wide侧使用的是FTRL优化器。可以让Wide部分变得更加的稀疏，也就是 Wide部分的大部分参数都为0，大大压缩了模型权重及特征向量的维度，让模型更高效的去学习有价值的、显而易见的特征及特征组合，进一步增强模型的记忆能力。而且FTRL模型本身特别适合在线学习和大规模稀疏特征，能够实现较为准确的参数更新，同时考虑了正则化项，有助于防止模型过拟合，提高泛化能力。
  - 也可以理解为 Wide侧输入手动交叉的特征项，模型可以直接从人工经验中获取显式的关联模式，降低了学习难度。模型腾出了原本挖掘这部分模式的精力，去挖掘其它间接的复杂的模式，也可以理解为模型在学习这些输入的已知模式时，有了更多的信息，可以避开一些坑，减小模型掉入坑里的概率，增大模型接近最优解的可能。

- **Deep部分泛化能力**、为什么使用AdaGrad、有什么缺点
  - Deep侧主要用于扩展，引入embedding，模型通过MLP结构对特征进行间接和高阶的隐式交叉学习实现参数共享，并挖掘隐藏在数据间潜在关联模式，使模型有能力处理未见过的数据或模式。相比传统机器学习模型，具有更好的泛化性。有利于推荐效果中的新颖性这个维度，即对于数据中未出现的模式，模型也能做出相应的合理反应。
  - Deep部分**不存在严重的特征稀疏问题**，且对于深度学习模型，不同层或神经元可能需要不同的学习速率，因此 Deep侧使用AdaGrad优化器。AdaGrad能够自适应地调整学习率，使得训练过程更加稳定，同时加快模型收敛速度，使得模型可以得到更精确的解。
  - 缺点
    - 隐式学习特征交叉相比于人工显式特征交叉，挖掘数据中的已有模式的难度增加，导致模型的记忆性减弱，不利于推荐的准确性。
    - 对于某些特定的场景(数据分布长尾， 共现矩阵稀疏高秩）很难有效学习低纬度的表示， 造成推荐的过度泛化。

## DIN(Deep Interest Network)

### 简介

- **内容**：DIN（[Deep Interest Network for Click-Through Rate Prediction](https://arxiv.org/abs/1706.06978#)）是2018年阿里提出来的模型，是阿里妈妈精准定向检索及基础算法团队在2017年6月提出的。其针对电子商务领域（e-commerce industry）的CTR预估，重点在于充分利用/挖掘用户历史行为数据中的信息。通过引入attention机制，针对不同的广告构造不同的用户抽象表示（考虑不同的候选（**广告**）和用户历史行为的相关性），从而实现了在数据维度一定的情况下，更精准地捕捉用户当前的兴趣。

- **核心思想**：

  - 用户的兴趣是多元化的（**diversity**）
  - 并且对于特定的广告，用户不同的兴趣会产生不同的影响（**local activation**）

- **背景**：

  - Embedding&MLP 模型表示**用户的兴趣多样性有限制**，将用户行为序列编码成一个固定长的向量来表示用户兴趣，就是大量稀疏特征先经过 embedding层， 转成低维稠密的，然后进行 concat保留所有信息、或使用常用 pooling的方式压缩 embedding表示，但是会造成一定的信息丢失。而且这两种方式embedding向量的权重都是相同的。

  - Embedding&MLP 模型没有考虑用户与广告之间的关系，也就**无法表达用户广泛的兴趣**， 比如对于同一个用户, 如果候选广告 （Candidate Ad） 发生了变化, 用户的兴趣却依然是同一个向量来表达，根本没有考虑之前用户历史行为商品具体是什么, 究竟用户历史行为中的哪个会对当前的点击预测带来积极的作用。 这限制了模型的表达能力, 毕竟用户的兴趣是多样的。

  - 不必将某个用户所有的兴趣（用户的历史购买记录）全部压缩到向量中，因为只有用户部分的兴趣会影响当前行为（对候选广告点击或不点击），王喆老师举了个例子

    ```text
    假设广告中的商品是键盘，如果用户历史点击的商品中有化妆品，包包，衣服，洗面奶等商品，那么大概率上该用户可能是对键盘不感兴趣的，而如果用户历史行为中的商品有鼠标，电脑，iPad，手机等， 那么大概率该用户对键盘是感兴趣的， 而如果用户历史商品中有鼠标，化妆品，T-shirt和洗面奶， 鼠标这个商品embedding对预测“键盘”广告的点击率的重要程度应该大于后面的那三个。
    ```

- **动机**：

  - 在业务的角度，我们应该怎样自适应的去捕捉用户的兴趣变化，较为准确的实施广告推荐；而放到模型的角度， 我们应该**考虑到用户的历史行为商品与当前商品广告的一个关联性**，如果用户历史商品中很多与当前商品关联，那么说明该商品可能符合用户的品味，就把该广告推荐给他。而一谈到关联性的话， 我们就容易想到“注意力”的思想了， 所以为了更好的从用户的历史行为中学习到与当前商品广告的关联性，学习到用户的兴趣变化， 作者把注意力引入到了模型，设计了一个"local activation unit"结构，利用候选商品和历史问题商品之间的相关性计算出权重，这个就代表了对于当前商品广告的预测，用户历史行为的各个商品的重要程度大小， 而加入了注意力权重的深度学习网络

- **创新**：

  - **前提**：这个模型的使用场景是**非常注重用户的历史行为特征（历史购买过的商品或者类别信息）**

  - **针对Diversity：** 针对用户广泛的兴趣，DIN用 **an interest distribution** 去表示，即用 Pooling（weighted sum）对Diversity建模（对用户多种多样的兴趣建模）。
  - 针对**Local Activation**
    - 所以 DIN 稍加改进，利用 attention机制实现 Local Activation，从用户历史行为中动态学习用户兴趣的embedding向量，针对不同的广告构造不同的用户抽象表示，从而实现了在数据维度一定的情况下，更精准地捕捉用户当前的兴趣。
    - 对用户历史行为进行了不同的加权处理，针对不同的广告，不同的 behavior id 赋予不同的权重，这个权重是由当前behavior id和候选广告共同决定的，这就是Attention机制。即针对当前候选Ad，去局部的激活（*Local Activate*）相关的历史兴趣信息。
    - 与当前候选广告相关性越高的历史行为，会获得越高的 **attention score**，从而会主导这一次预测。
  - CTR中**特征稀疏而且维度高**，通常利用 L1、L2、Dropout 等手段防止过拟合。由于传统L2正则计算的是全部参数，CTR预估场景的模型参数往往数以亿计。DIN 提出了一种正则化方法，在每次小批量迭代中，给与不同频次的特征不同的正则权重；
  - 由于传统的**激活函数**，如Relu在输入小于0时输出为0，将导致许多网络节点的迭代速度变慢。PRelu虽然加快了迭代速度，但是其分割点默认为0，实际上分割点应该由数据决定。因此，DIN提出了一种数据动态自适应激活函数Dice。
  - **针对大规模稀疏数据的模型训练：**当DNN深度比较深（参数非常多），输入又非常稀疏的时候，很容易过拟合。DIN提出**Adaptive regularizaion**来防止过拟合，效果显著。

### 模型结构及原理

- 特征表示

  - 工业上的CTR预测数据集一般都是`multi-group categorial form`的形式，就是类别型特征最为常见，这种数据集一般长这样：

    <div align=center>
    <img src="https://img-blog.csdnimg.cn/20210118190044920.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" style="zoom: 67%;" />
    </div>

  - 框出来的那个特征，这个包含着丰富的用户兴趣信息对于特征编码，作者这里举了个例子：`[weekday=Friday, gender=Female, visited_cate_ids={Bag,Book}, ad_cate_id=Book]`， 这种情况我们知道一般是通过one-hot的形式对其编码， 转成系数的二值特征的形式。但是这里我们会发现一个`visted_cate_ids`， 也就是用户的历史商品列表， 对于某个用户来讲，这个值是个多值型的特征， 而且还要知道这个特征的长度不一样长，也就是用户购买的历史商品个数不一样多，这个显然。这个特征的话，我们一般是用到multi-hot编码，也就是可能不止1个1了，有哪个商品，对应位置就是1， 所以经过编码后的数据长下面这个样子： 

<div align=center>
<img src="https://img-blog.csdnimg.cn/20210118185933510.png" style="zoom:67%;" />
</div>


- 基线模型

  - 这里的 base模型，就是上面提到过的 Embedding&MLP 的形式， 分为三大模块：Embedding layer，Pooling & Concat layer和MLP， 结构如下

    <div align=center>
    <img src="https://img-blog.csdnimg.cn/20210118191224464.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" style="zoom:80%;" />
    </div>

  - 前面的大部分深度模型结构也是遵循着这个范式套路， 简介一下各个模块。

    - Embedding layer：这个层的作用是把高维稀疏的输入转成低维稠密向量， 每个离散特征下面都会对应着一个embedding词典， 维度是$D\times K$， 这里的$D$表示的是隐向量的维度， 而$K$表示的是当前离散特征的唯一取值个数,  这里为了好理解，

      - 这里举个例子说明，就比如上面的 weekday 特征：假设某个用户的weekday特征就是周五，化成one-hot编码的时候，就是[0,0,0,0,1,0,0]表示，这里如果再假设隐向量维度是D， 那么这个特征对应的embedding词典是一个$D\times7$的一个矩阵(每一列代表一个embedding，7列正好7个embedding向量，对应周一到周日)，那么该用户这个one-hot向量经过embedding层之后会得到一个$D\times1$的向量，也就是周五对应的那个embedding，怎么算的，其实就是$embedding矩阵* [0,0,0,0,1,0,0]^T$ 。其实也就是直接把 embedding矩阵中 one-hot向量为1的那个位置的embedding向量拿出来。 这样就得到了稀疏特征的稠密向量了。其他离散特征也是同理，只不过上面那个multi-hot编码的那个，会得到一个embedding向量的列表，因为他开始的那个multi-hot向量不止有一个是1，这样乘以embedding矩阵，就会得到一个列表了。通过这个层，上面的输入特征都可以拿到相应的稠密embedding向量了。

    - **pooling layer and Concat layer**： pooling层的作用是将用户的历史行为embedding这个最终变成一个定长的向量，因为每个用户历史购买的商品数是不一样的， 也就是每个用户multi-hot中1的个数不一致，这样经过embedding层，得到的用户历史行为embedding的个数不一样多，也就是上面的embedding列表$t_i$不一样长， 那么这样的话，每个用户的历史行为特征拼起来就不一样长了。 而后面如果加全连接网络的话，我们知道，他需要定长的特征输入。 所以往往用一个pooling layer先把用户历史行为embedding变成固定长度(统一长度)，所以有了这个公式：
      $$
      e_i=pooling(e_{i1}, e_{i2}, ...e_{ik})
      $$

      - 这里的$e_{ij}$是用户历史行为的那些 embedding。$e_i$就变成了定长的向量， 这里的$i$表示第$i$个历史特征组(是历史行为，比如历史的商品id，历史的商品类别id等)， 这里的$k$表示对应历史特种组里面用户购买过的商品数量，也就是历史embedding的数量，看上面图里面的user behaviors系列，就是那个过程了。 Concat layer层的作用就是拼接了，就是把这所有的特征embedding向量，如果再有连续特征的话也算上，从特征维度拼接整合，作为MLP的输入。

    - **MLP**：这个就是普通的全连接，用了学习特征之间的各种交互。

    - **Loss**: 由于这里是点击率预测任务， 二分类的问题，所以这里的损失函数用的负的log对数似然：
      $$
      L=-\frac{1}{N} \sum_{(\boldsymbol{x}, y) \in \mathcal{S}}(y \log p(\boldsymbol{x})+(1-y) \log (1-p(\boldsymbol{x})))
      $$

  - 这就是base 模型的全貌， 这里应该能看出这种模型的问题， 通过上面的图也能看出来， 用户的历史行为特征和当前的候选广告特征在全都拼起来给神经网络之前，是一点交互的过程都没有， 而拼起来之后给神经网络，虽然是有了交互了，但是原来的一些信息，比如，每个历史商品的信息会丢失了一部分，因为这个与当前候选广告商品交互的是池化后的历史特征embedding， 这个embedding是综合了所有的历史商品信息， 这个通过我们前面的分析，对于预测当前广告点击率，并不是所有历史商品都有用，综合所有的商品信息反而会增加一些噪声性的信息，可以联想上面举得那个键盘鼠标的例子，如果加上了各种洗面奶，衣服啥的反而会起到反作用。其次就是这样综合起来，已经没法再看出到底用户历史行为中的哪个商品与当前商品比较相关，也就是丢失了历史行为中各个商品对当前预测的重要性程度。最后一点就是如果所有用户浏览过的历史行为商品，最后都通过embedding和pooling转换成了固定长度的embedding，这样会限制模型学习用户的多样化兴趣。

  - 那么改进这个问题的思路有哪些呢？  第一个就是加大embedding的维度，增加之前各个商品的表达能力，这样即使综合起来，embedding的表达能力也会加强， 能够蕴涵用户的兴趣信息，但是这个在大规模的真实推荐场景计算量超级大，不可取。 另外一个思路就是**在当前候选广告和用户的历史行为之间引入注意力的机制**，这样在预测当前广告是否点击的时候，让模型更关注于与当前广告相关的那些用户历史产品，也就是说**与当前商品更加相关的历史行为更能促进用户的点击行为**。 作者这里又举了之前的一个例子：

    - 想象一下，当一个年轻母亲访问电子商务网站时，她发现展示的新手袋很可爱，就点击它。让我们来分析一下点击行为的驱动力。
    - 展示的广告通过软搜索这位年轻母亲的历史行为，发现她最近曾浏览过类似的商品，如大手提袋和皮包，从而击中了她的相关兴趣

  - 第二个思路就是DIN的改进之处了。DIN通过给定一个候选广告，然后去注意与该广告相关的局部兴趣的表示来模拟此过程。 DIN不会通过使用同一向量来表达所有用户的不同兴趣，而是通过考虑历史行为的相关性来自适应地计算用户兴趣的表示向量（对于给的广告）。 该表示向量随不同广告而变化。下面看一下DIN模型。

### DIN模型架构

上面分析完了base模型的不足和改进思路之后，DIN模型的结构就呼之欲出了。首先，它依然是采用了base模型的结构，只不过是在这个的基础上加了一个注意力机制来学习用户兴趣与当前候选广告间的关联程度， 用论文里面的话是，引入了一个新的`local activation unit`， 这个东西用在了用户历史行为特征上面， **能够根据用户历史行为特征和当前广告的相关性给用户历史行为特征embedding进行加权**。我们先看一下它的结构，然后看一下这个加权公式。

<img src="https://img-blog.csdnimg.cn/20210118220015871.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" style="zoom: 80%;" />


这里改进的地方已经框出来了，这里会发现相比于base model， 这里加了一个local activation unit， 这里面是一个前馈神经网络，输入是用户历史行为商品和当前的候选商品， 输出是它俩之间的相关性， 这个相关性相当于每个历史商品的权重，把这个权重与原来的历史行为embedding相乘求和就得到了用户的兴趣表示$\boldsymbol{v}_{U}(A)$, 这个东西的计算公式如下：
$$
\boldsymbol{v}_{U}(A)=f\left(\boldsymbol{v}_{A}, \boldsymbol{e}_{1}, \boldsymbol{e}_{2}, \ldots, \boldsymbol{e}_{H}\right)=\sum_{j=1}^{H} a\left(\boldsymbol{e}_{j}, \boldsymbol{v}_{A}\right) \boldsymbol{e}_{j}=\sum_{j=1}^{H} \boldsymbol{w}_{j} \boldsymbol{e}_{j}
$$
这里的$\{\boldsymbol{v}_{A}, \boldsymbol{e}_{1}, \boldsymbol{e}_{2}, \ldots, \boldsymbol{e}_{H}\}$是用户$U$的历史行为特征embedding， $v_{A}$表示的是候选广告$A$的embedding向量， $a(e_j, v_A)=w_j$表示的权重或者历史行为商品与当前广告$A$的相关性程度。$a(\cdot)$表示的上面那个前馈神经网络，也就是那个所谓的注意力机制， 当然，看图里的话，输入除了历史行为向量和候选广告向量外，还加了一个它俩的外积操作，作者说这里是有利于模型相关性建模的显性知识。

这里有一点需要特别注意，就是**这里的权重加和不是1**， 准确的说这里不是权重， 而是直接算的相关性的那种分数作为了权重，也就是平时的那种scores(softmax之前的那个值)，这个是为了保留用户的兴趣强度。

#### local activation unit

DIN的关键点在于 AU 的设计，DIN会计算候选广告与用户最近N个历史行为商品的相关性权重weight，将其作为加权系数来对这N个行为商品的embeddings做sum pooling，用户兴趣正是由这个加权求和后的embedding来体现

<img src="C:/Users/PC/Desktop/推荐系统(1)/推荐系统/img/din_local_activation_unit.png" alt="img" style="zoom:40%;" />

- 与传统attention区别：
  - 权重加和不是1
  - 直接算的相关性的那种分数作为了权重
- 实现细节
  - local_activation_unit:  
    - att_input = torch.cat([queries, keys, queries - keys, queries * keys], axis=-1), queries * keys为向量外积
    - att_output = dnn(att_input)  - > B x len， **用Dice方法替代经典的PReLU激活函数**
    - 对分数scale, 和Transformer同样操作，用于控制元素间的数据量级，防止softemax后输出接近1 导致梯度消失
  - AttentionPoolingLayer:
    - 输入：query 为候选target， keys为历史行为序列
    - 先对keys进行mask，记录填充位置， 得到key_masks
    - 把att_output中mask位置分数置为0
    - 做sum pooling
  - mini-batch aware regularization
    - 如果我们使用 **L2正则化** 来防止过拟合，那么我们需要对 $W$ 进行惩罚，即在损失函数中加入一个正则项： $L= L_0 + \lambda \| w\|^2$ 那么我们需要对W的每一个元素进行更新。
      - 一是计算开销过大。因为 $X$ 是一个高维稀疏的矩阵，所以W也是一个高维稀疏的矩阵。如果我们对W的每一个元素都进行更新，那么我们需要遍历整个W矩阵，这会消耗大量的时间和空间。
      - 二是信息丢失。因为 $X$ 是一个稀疏的矩阵，所以有很多特征在某些样本中并没有出现。如果我们对这些特征对应的嵌入向量也进行惩罚，那么我们就会降低这些特征的权重，从而丢失了这些特征所包含的信息。
    - **mini-batch aware regularization: 一种Adaptive的正则化方法**是一种用于大规模稀疏场景下的正则化方法，它可以减少计算开销和过拟合的风险。它的主要思想是只对每个mini-batch中参数不为0的部分进行梯度更新，而不是对整个参数矩阵进行更新。这样可以避免对那些没有出现在mini-batch中的特征进行惩罚，从而保留更多的信息。此外，它还在一定程度上解决了数据长尾分布的过拟合问题。对长尾部分样本施加较大的惩罚而对短尾部分施加较小的惩罚来防止模型对于长尾部分的过拟合。

### DIN实现细节

```python
class Dice(nn.Module):
    """
    自定义的dice激活函数，原论文有公式介绍，有点复杂我也没看懂，别的地方用的不多，不介绍了。
    """
    def __init__(self):
        super(Dice, self).__init__()
        self.alpha = nn.Parameter(torch.zeros((1,)))
        self.epsilon = 1e-9
    
    def forward(self, x):

        norm_x = (x - x.mean(dim=0)) / torch.sqrt(x.var(dim=0) + self.epsilon)
        p = torch.sigmoid(norm_x)
        x = self.alpha * x.mul(1-p) + x.mul(p)
    
        return x


class ActivationUnit(nn.Module):
    """
    激活函数单元
    功能是计算用户购买行为与推荐目标之间的注意力系数，比如说用户虽然用户买了这个东西，但是这个东西实际上和推荐目标之间没啥关系，也不重要，所以要乘以一个小权重
    """
    def __init__(self, embedding_dim, dropout=0.2, fc_dims = [32, 16]):
        super(ActivationUnit, self).__init__()
        # 1.初始化fc层
        fc_layers = []
        # 2.输入特征维度
        input_dim = embedding_dim*4     
        # 3.fc层内容：全连接层（4*embedding,32）—>激活函数->dropout->全连接层（32,16）->.....->全连接层（16,1）
        for fc_dim in fc_dims:
            fc_layers.append(nn.Linear(input_dim, fc_dim))
            fc_layers.append(Dice())
            fc_layers.append(nn.Dropout(p = dropout))
            input_dim = fc_dim
        
        fc_layers.append(nn.Linear(input_dim, 1))
        # 4.将上面定义的fc层，整合到sequential中
        self.fc = nn.Sequential(*fc_layers)
    
    def forward(self, query, user_behavior):
        """
            :param query:targe目标的embedding ->（输入维度） batch*1*embed 
            :param user_behavior:行为特征矩阵 ->（输入维度） batch*seq_len*embed
            :return out:预测目标与历史行为之间的注意力系数
        """
        # 1.获取用户历史行为序列长度
        seq_len = user_behavior.shape[1]
        # 2.序列长度*embedding
        queries = torch.cat([query] * seq_len, dim=1)
        # 3.前面的把四个embedding合并成一个（4*embedding）的向量，
        #  第一个向量是目标商品的向量，第二个向量是用户行为的向量，
        #  至于第三个和第四个则是他们的相减和相乘（这里猜测是为了添加一点非线性数据用于全连接层，充分训练）
        attn_input = torch.cat([queries, user_behavior, queries - user_behavior, 
                                queries * user_behavior], dim = -1)
        out = self.fc(attn_input)
        return out

```

### 思考

DIN模型在工业上的应用还是比较广泛的， 大家可以自由去通过查资料看一下具体实践当中这个模型是怎么用的？ 有什么问题？比如行为序列的制作是否合理， 如果时间间隔比较长的话应不应该分一下段？ 再比如注意力机制那里能不能改成别的计算注意力的方式会好点？(我们也知道注意力机制的方式可不仅DNN这一种)， 再比如注意力权重那里该不该加softmax？  这些其实都是可以值的思考探索的一些问题，根据实际的业务场景，大家也可以总结一些更加有意思的工业上应用该模型的技巧和tricks，欢迎一块讨论和分享。

### 总结

**DIN (Deep Interest Network)** 是一种深度学习模型，主要应用于推荐系统中，通过捕捉用户的兴趣并进行个性化推荐。DIN 的核心思想是引入注意力机制，根据用户的历史行为和当前的推荐目标，动态调整每个历史行为的权重，从而实现更精准的推荐。

- **模型结构**

  - **Embedding层**：将用户和物品的离散特征转换为连续的向量表示。

  - **兴趣提取层**（local activation unit）：使用注意力机制对用户的历史行为进行加权，提取与当前推荐目标相关的兴趣。
    - att_input = torch.cat([queries, keys, queries - keys, queries * keys], axis=-1), queries * keys为向量外积
    - att_output = dnn(att_input)  - > B x len， **用Dice方法替代经典的PReLU激活函数**, 准确的说这里不是权重， 而是直接算的相关性的那种分数作为了权重，也就是平时的那种scores(softmax之前的那个值)，这个是为了保留用户的兴趣强度。因为sofmax会导致两极分化
    - 对分数scale, 和Transformer同样操作，用于控制元素间的数据量级，防止softemax后输出接近1 导致梯度消失
    - **mini-batch aware regularization: 一种Adaptive的正则化方法**是一种用于大规模稀疏场景下的正则化方法，它可以减少计算开销和过拟合的风险。它的主要思想是只对每个mini-batch中参数不为0的部分进行梯度更新，而不是对整个参数矩阵进行更新。这样可以避免对那些没有出现在mini-batch中的特征进行惩罚，从而保留更多的信息。此外，它还在一定程度上解决了数据长尾分布的过拟合问题。对长尾部分样本施加较大的惩罚而对短尾部分施加较小的惩罚来防止模型对于长尾部分的过拟合。

  - **全连接层**：对提取的兴趣向量进行进一步的非线性变换，生成最终的用户兴趣表示。

  - **输出层**：计算用户对推荐目标的点击率（CTR）或其他目标。

- **核心思想**：DIN 模型的核心在于引入了注意力机制，用于捕捉用户历史行为与当前推荐目标之间的相关性。具体来说，模型通过计算每个历史行为与当前推荐目标之间的相似度来动态调整每个历史行为的权重，从而使得与当前推荐目标更相关的历史行为在兴趣提取中占据更大的比重。

- **优势**

  - **个性化**：通过注意力机制，DIN 能够动态地调整用户历史行为的权重，实现更个性化的推荐。

  - **解释性强**：注意力机制提供了每个历史行为的权重，可以解释模型的推荐结果。

  - **灵活性高**：可以灵活地处理用户的各种历史行为数据，适用于多种推荐场景。
  - **前提**：这个模型的使用场景是**非常注重用户的历史行为特征（历史购买过的商品或者类别信息）**
  - **针对Diversity：** 针对用户广泛的兴趣，DIN用*an interest distribution*去表示，即用 Pooling（weighted sum）对Diversity建模（对用户多种多样的兴趣建模）。
  - 针对**Local Activation**
    - 所以 DIN 稍加改进，利用attention机制实现 Local Activation，从用户历史行为中动态学习用户兴趣的embedding向量，针对不同的广告构造不同的用户抽象表示，从而实现了在数据维度一定的情况下，更精准地捕捉用户当前的兴趣。
    - 对用户历史行为进行了不同的加权处理，针对不同的广告，不同的 behavior id 赋予不同的权重，这个权重是由当前behavior id和候选广告共同决定的，这就是Attention机制。即针对当前候选Ad，去局部的激活（*Local Activate*）相关的历史兴趣信息。
    - 与当前候选Ad相关性越高的历史行为，会获得越高的*attention score*，从而会主导这一次预测。
  - CTR中**特征稀疏而且维度高**，通常利用L1、L2、Dropout等手段防止过拟合。由于传统L2正则计算的是全部参数，CTR预估场景的模型参数往往数以亿计。DIN提出了一种正则化方法，在每次小批量迭代中，给与不同频次的特征不同的正则权重；
  - 由于传统的**激活函数**，如Relu在输入小于0时输出为0，将导致许多网络节点的迭代速度变慢。PRelu虽然加快了迭代速度，但是其分割点默认为0，实际上分割点应该由数据决定。因此，DIN提出了一种数据动态自适应激活函数Dice。
  - **针对大规模稀疏数据的模型训练：**当DNN深度比较深（参数非常多），输入又非常稀疏的时候，很容易过拟合。DIN提出**Adaptive regularizaion**来防止过拟合，效果显著。

- **实际业务场景应用**：在电商平台上，DIN 模型可以用于商品推荐、内容推荐、广告推荐等多个场景。例如：

  - **商品推荐**：

    - **问题**：用户在浏览商品时，如何根据其历史浏览、点击、购买行为进行精准推荐。

    - **应用**：使用 DIN 模型，根据用户的历史行为和当前正在浏览的商品，动态调整每个历史行为的权重，推荐用户可能感兴趣的商品。

  - **内容推荐**：

    - **问题**：用户在浏览新闻、视频等内容时，如何根据其历史浏览行为进行个性化推荐。

    - **应用**：使用 DIN 模型，根据用户的历史内容浏览行为和当前推荐目标，提取用户兴趣，为用户推荐可能感兴趣的内容。

  - **广告推荐**：

    - **问题**：在广告投放中，如何根据用户的历史点击行为提高广告点击率。
      - **应用**：使用 DIN 模型，根据用户的历史广告点击行为和当前广告目标，动态调整每个历史行为的权重，提高广告点击率预测的准确性。

- **常见问题及解决方案**

  - **行为序列制作是否合理**：

    - **问题**：如何选择和处理用户的行为数据以便最大化模型的效果。

    - **解决方案**：确保选择与目标任务相关的用户行为，并进行数据清洗和预处理，控制行为序列的长度。

  - **如何处理时间间隔较长的行为序列**：

    - **解决方案**：对时间间隔较长的行为序列进行分段(日、周、月、季度)，并引入时间衰减机制。

  - **是否可以尝试其他的注意力机制以提升模型表现**：
    - **解决方案**：可以尝试多头注意力机制、自注意力机制或层次化注意力机制。

  - **注意力权重是否应该加Softmax**：
    - **解决方案**：加Softmax可以使权重归一化，有助于模型稳定性和解释性；在某些场景下，可以考虑其他归一化方法或不进行归一化。原文未加softmax

## 多目标优化（MOE、MMOE、CGC、PLE）

### [MOE(Mixture-Of-Experts)](https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/06_distributed_training/moe_cn.html)

- 动机：模型规模的扩展会导致训练成本显著增加，计算资源的限制成为了大规模密集模型训练的瓶颈

- 内容

  <img src="C:/Users/PC/Desktop/推荐系统(1)/推荐系统/img/moe模型架构.png" alt="image-20240223152155495" style="zoom:50%;" />

  - 与密集模型不同，MoE 将模型的某一层扩展为多个具有相同结构的专家网络( `expert` )，并由门( `gate` )网络决定激活哪些 `expert` 用于计算，从而实现超大规模稀疏模型的训练。 以上图为例，示例模型包含 3 个模型层；如(a)到(b)，将中间层扩展为具有 `n` 个 `expert` 的 MoE 结构，并引入 `Gating network` 和 `Top_k` 机制，MoE 细节上图，计算过程如下述公式。
    $$
    MoE(x)=\sum_{i=1}^{n}(G_i(x)E_i(x)) \\
    G(x) = TopK(softmax(w_g(x)+b))
    $$

  - 使用 MoE 结构，可以在计算成本呈线性增加的同时实现超大规模模型训练，为恒定的计算资源预算带来巨大增益。


### MMOE

- 内容：MMoE由 Google在 2018年 KDD 上发表的文章 [Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts](https://dl.acm.org/doi/pdf/10.1145/3219819.3220007)，MMOE的结构优化为每个任务都单独使用一个门控网络。这样的改进可以针对不同任务得到不同的 Experts 权重，从而实现对 Experts 的选择性利用，不同任务对应的门控网络可以学习到不同的Experts 组合模式，因此模型更容易捕捉到子任务间的相关性和差异性。

  <img src="C:/Users/PC/Desktop/推荐系统(1)/推荐系统/img/三种多任务学习模型架构.png" alt="image-20240226105913786" style="zoom:80%;" />

- 和MOE的差别

  - moe是输入经过同一个门控网络加权多个expert的输出，而mmoe是每个tower有自己专门的门控加权网络，多个expert是共享，mmoe无明显增加参数，却对网络的学习起到了重要的影响作用
  - 门控网络相当于学习了一个简单的attention，mmoe的冲突建模能力，就是建立在多个门控网络对于多个任务可学习的调控能力。多个专家加上多个门控网络，不同任务对应的门控网络可以学习到不同的 Experts 组合模式，模型更容易捕捉到子任务间的相关性和差异性，能够使得我们多个任务融合的更加平滑 

- esmm和mmoe对比：

  - esmm要求任务之间是存在递进关系的，而mmoe则不需要，从loss函数就可以体现，pCTCVR 任务的核心是： **我们站在曝光的前提下，不知道点击与否，不知道转化与否，这个时候去预估点击并且转化的概率**。CTR 任务和 CVR任务 都是进行分类模型的 0/1概率预估, 用到的**特征相似, 场景也相似, 任务相关性非常高**。并且，该模型使用的业务场景也要求了在曝光后，**item先被点击才会有转化，没有被点击就压根谈不上转化了，这是一种严格的递进关系**。同时**CTR与CVR两者的概率相乘有着明显且理论正确的业务意义**。

- **任务相关性衡量** 

  - **Spearman相关系数仅评估单调关系，Pearson相关系数仅评估线性关系**。例如： 如果关系是一个变量在另一个变量增加时增加，但数量不一致，则**Pearson相关系数**为正但小于+1。 在这种情况下，Spearman系数仍然等于+1。

    我们这里说的 **两个任务的相关性，可以通过 两个任务的label 之间的 皮尔逊相关系数 来表示** 。假设模型中包含两个回归任务，而数据通过采样生成，并且规定输入相同，输出label不同，求得他们的皮尔逊相关系数，相关系数越大，表示任务之间越相关，相关系数越大，表示任务之间越相关。

- **训练技巧**

  - 是否存在多个gate的过度偏差，例如：（0.999, 0.001）情况
    - 网络的实现有问题，需要去排查下各个专家网络以及门控网络的初始化值有没有问题。
    - 排查下两个任务的标签情况，是不是两任务的标签呈现比较多的极端情况，
    - 任务相关性衡量办法看一下两个任务的相关性。 
  - 两个任务的目标差异特别巨大时，如预估视频点击率与观看时长，怎样处理：
    - 这个任务我们应该直觉上就觉得标签的差异太过于大了，时长的label最好能够进行一定的处理。例如log处理。
    - 经过**log处理**后目标会削弱量级，数据也会变得更符合正态分布，同时**loss也更小和稳定** 。loss的稳定对于多任务模型学习和训练来说是至关重要的，它影响着**多个任务根据loss更新的梯度，最好我们能够把多个目标的loss加权重调到同一量级**，对这种差异比较大的问题总是能够起到缓解作用的

### PLE

- PLE模型结构的整体框架和MMoE类似，在底层通过expert进行信息抽取，通过gate对expert组合得到task的输入。

- **CGC**(Customized Gate Control) 定制门控

  - PLE将共享的部分和每个任务特定的部分**显式的分开**，强化任务自身独立特性。把MMOE中提出的Expert分成两种，任务特定task-specific和任务共享task-shared。保证expert“各有所得”，更好的降低了弱相关性任务之间参数共享带来的问题。
  - 网络结构如图所示，同样的特征输入分别送往三类不同的专家模型（任务A专家、任务B专家、任务共享专家），再通过门控机制加权聚合之后输入各自的Tower网络。门控网络，把原始数据和expert网络输出共同作为输入，通过单层全连接网络+softmax激活函数，得到分配给expert的加权权重，与attention机制类型。

  <img src="C:/Users/PC/Desktop/推荐系统(1)/推荐系统/img/PLE_CGC层架构.png" alt="image-20240226173656377" style="zoom:50%;" />

  - 底层网络：包含一些 expert 模块, 每个expert 模块由若干子网络(sub-networks)构成，这些子网络称作 experts，每个模块包含多少个 expert 是可调节的超参。其中 shared experts 负责学习 shared patterns，task-specific experts负责学习task-specific patterns。
  - 上层网络：一些 task-specific 塔 ，网络的宽度和深度都是可调节的超参。每个塔同时从 shared experts 和各自的task-specific experts 中学习知识。
  - 门控网络：Shared experts 和 task-specific experts 的信息通过门控网络进行融合。门控网络的结构为单层的前向网络，激活函数为softmax 函数。

- **PLE** (progressive layered extraction) 分层萃取

  - PLE就是上述CGC网络的多层纵向叠加，以获得更加丰富的表征能力。在分层的机制下，Gate设计成两种类型，使得不同类型Expert信息融合交互。task-share gate融合所有Expert信息，task-specific gate只融合specific expert和share expert。模型结构如图：

    ![img](C:/Users/PC/Desktop/推荐系统(1)/推荐系统/img/ple层模型架构.png)

  - PLE的每层输出都是有指向性的，**即上一层task A的输出只作为下一层expertA的输入，上一层task B的输出只作为下一层expertB的输入，上一层expert shared的输出只作为下一层expert shared的输入**。这样体现了不同任务之间的差异性。这使得gate同时融合task-shares expert和task-specific expert的信息，论文实验中证明这种不同类型expert信息的交叉，可以带来更好的效果。

  - 其中任务k的独享专家模块融合了上一层网络中任务k的独享专家模块和共享专家模块，而共享专家模块则融合了上一层所有的专家模块。

- **样本空间不一致**：PLE将所有任务样本空间的并集作为全部训练样本空间，在分别针对每个任务算loss时，只考虑该任务的样本的空 间，一般需对这种数据集会附带一个样本空间标签。lossx如下

  <img src="C:/Users/PC/Desktop/推荐系统(1)/推荐系统/img/ple损失函数.png" alt="img" style="zoom:50%;" />

- [**不同任务之间权重的优化**](https://camo.githubusercontent.com/a6cf89b3388dbdf96d345ab05bba98bbf5c2febdf9929795e1093c86f15b355c/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d32666264323335393962643263643632323232363037653736636239373565635f31343430772e6a7067)

  - 不同任务各自独立的权重设定：PLE提出了一种加权的规则，它的思想是随着迭代次数的增加，任务的权重应当不断衰减。它为每个任务设定一个初始权重 $w_{k,0}$再按该公式进行更新：

    ![img](C:/Users/PC/Desktop/推荐系统(1)/推荐系统/img/ple权重优化公式.png)

- **和mmoe区别**

  - **特点：**在MMOE的基础上进一步建模了任务间的个性。如果说MMOE的所有expert都是shared，当任务间差异较大，光凭借gate的权重差异可能无法很好刻画。而PLE通过让不同任务维护各自的experts，体现了任务间的差异性；不同任务共同维护experts shared，体现了任务间的共性。

- [PLE](https://github.com/datawhalechina/fun-rec/blob/master/docs/ch02/ch2.2/ch2.2.5/PLE.md)

  [PLE论文精读笔记（含代码实现）](https://blog.csdn.net/weixin_41888257/article/details/123493534)



[多任务学习之mmoe理论详解与实践](https://juejin.cn/post/7186683552640008251)

[使用PyTorch实现混合专家(MoE)模型](https://cloud.tencent.com/developer/article/2378153)

[MoE: 稀疏门控制的专家混合层](https://zhuanlan.zhihu.com/p/335024684)

[MOE](https://huggingface.co/blog/zh/moe)

### 关键问题：label delay标签延迟，如何解决

- 业界label 延迟的数据分布

  - 公司：

    - 天级转化率

      <img src="C:/Users/PC/Desktop/推荐系统(1)/推荐系统/img/mmoe我司天级转化率.png" alt="img" style="zoom:90%;" />

    - 小时级转化率：可以看到0.25小时内，我们的转化事件在95%

      <img src="C:/Users/PC/Desktop/推荐系统(1)/推荐系统/img/mmoe我司小时级转化率.png" alt="image-20240118150134657" style="zoom:70%;" />

  - 淘系：

    - 论文约55%的转化事件发生在0.25小时内

    - 按品类：不同品类天级转化不同

      <img src="C:/Users/PC/Desktop/推荐系统(1)/推荐系统/img/mmoe淘宝某品类天级转化.png" alt="image-20240118110456944" style="zoom:20%;" />

  - Criteo公司早期：

    - 35%的转化事件发生在0.25小时内
    - 有50%的商品会在点击后24h内得到转化
    - 有13%的商品会在点击后2周之后才得到转化。

- 方法演进

  - 基本方法：
    - 选择合适的时间窗口：窗口外的全部为负样本
      - 实现简单，但转化率被低估
    - 天级别正确样本+增量更新小窗口样本
      - 每天需要重新训练模型
  - 延迟建模反馈
    - 同时学习最终转化模型、转化随时间的分布函数 如 DFM
    - ES-DFM
  - **<u>样本回补：可能存在错误，后续补充</u>**
    - 正样本回补：将前窗口内未转化且已经转化的样本，加入训练集
      - 会导致cvr预估存在偏差，过高或过低
      - 实现简单
    - 正负样本回补：同时补回转化的正样本和假负样本
      - 效果比较好

- 多目标建模：

  - 模型演进
    - share-bottom
    - MMOE
      - 注意查看每个expert的gate权重，是否偏差过重
      - log函数有着优秀的性质，经过log处理后目标会削弱量级，数据也会变得更符合正态分布，同时loss也更小和稳定 。loss的稳定对于多任务模型学习和训练来说是至关重要的，它影响着多个任务根据loss更新的梯度，最好我们能够把多个目标的loss加权重调到同一量级，对这种差异比较大的问题总是能够起到缓解作用的额
    - PLE
    - ESMM

  - 优化策略
    - loss函数构建

- enhance dcn

### 参考

【0】：[阿里多任务多目标CTR预估技术](https://developer.aliyun.com/article/793252)、

【1】：[cvr延迟建模方法概述](https://zhuanlan.zhihu.com/p/653946302)

【2】：[CVR预估 --- 延迟转化处理及思考](https://zhuanlan.zhihu.com/p/348335062)

【3】：[淘系KDD 2021 | 一种使用真负样本的在线延迟反馈建模](https://zhuanlan.zhihu.com/p/412871074)

【4】：[搜索推荐广告排序艺术-Delayed Feedback问题](https://zhuanlan.zhihu.com/p/373509195)

【5】：[CVR预测方法新突破，基于无偏延迟的反馈标签校正，提升推荐系统效果](https://zhuanlan.zhihu.com/p/665169103)

【6】：[负样本修正：CVR预估时间延迟问题](https://zhuanlan.zhihu.com/p/353379888)

【7】：[WWW 2022 | 搜索广告CVR延迟反馈建模DEFUSE](https://zhuanlan.zhihu.com/p/506476146)

### 待分析

- 转化率为60%，那未转化的东西到底是什么、转化的又是哪些
- [ctr cvr联合建模问题合集](https://blog.csdn.net/weixin_31866177/article/details/133812899)
- [MMOE实现](https://github.com/SummerRaining/multi_task-learning)
- [paddle实现](https://github.com/PaddlePaddle/PaddleRec/blob/master/models/multitask/mmoe/net.py)
- [多目标学习——Shared Bottom/MMOE/PLE/ESMM](https://zhuanlan.zhihu.com/p/643708894)
- [主流模型实现，带数据](https://github.com/huangjunheng/recommendation_model/blob/master/mmoe_model/mmoe.py#L36)、[多任务pytorch模型实现](https://github.com/easezyc/Multitask-Recommendation-Library/blob/main/models/mmoe.py)
- [华为云ESSM实现带问题分析](https://bbs.huaweicloud.com/blogs/362298)
- [多任务学习优化-loss优化](https://zhuanlan.zhihu.com/p/269492239)
  - 简单对loss加和：$loss=\sum_iL_i$
    - 这种loss计算方式的不合理之处是显而易见的，不同任务loss的量级很有可能不一样，loss直接相加的方式有可能会导致多任务的学习被某个任务所主导或学偏。当模型倾向于去拟合某个任务时，其他任务的效果往往可能受到负面影响，效果会相对变差（这是不是有一种零和博弈的感觉，当然也有跷跷板的感觉）。
    - 固定权重：$loss=\sum_iw_iL_i$
    - 允许我们手动调整每个任务的重要性程度；但是固定的w会一直伴随整个训练周期。
    - 问题:不同任务学习的难易程度也是不同的；且不同任务可能处于不同的学习阶段，比如任务A接近收敛，任务B仍然没训练好等。这种固定的权重在某个阶段可能会限制了任务的学习。

  - 动态调整权重：$loss=\sum_iw_i(t)L_i$
    - 根据不同任务学习的阶段，学习的难易程度，学习的效果来进行调整
    - **Gradient Normalization——梯度标准化**
    - **Dynamic Weight Averaging ——动态加权平均**

- [ 多场景多任务学习在美团到店餐饮推荐的实践](https://tech.meituan.com/2023/03/23/recommendation-multi-scenario-task.html)
- [AI学习手册包含各种论文的翻译版本](https://www.huaxiaozhuan.com/)



[推荐系统-特征实践总结](https://zhuanlan.zhihu.com/p/570634766)

[推荐系统（五）—— 特征交叉](https://zhuanlan.zhihu.com/p/457853657)

[特征增强&个性化在CTR预估中的经典方法和效果对比](https://zhuanlan.zhihu.com/p/672878757)

[快手：搜索词主导的用户兴趣网络在搜索排序中的应用](https://zhuanlan.zhihu.com/p/661889514)

[一文详解搜广推 CTR 建模](https://zhuanlan.zhihu.com/p/631188465)

[如何改进双塔模型，更好的提升算法效果？](https://zhuanlan.zhihu.com/p/629042132)

[神经网络训练Trick](https://www.jianshu.com/p/ff5d63b43b19)



[统计特征等频分桶](https://zhuanlan.zhihu.com/p/673817221)

[维特征的哈希技巧](https://zhuanlan.zhihu.com/p/161058660)

[推荐系统时代前沿（20）：特征层面，甚至动态长度的搜索](https://zhuanlan.zhihu.com/p/463139547)



oMOE指的是one gate moe

[华为云王喆推荐系统实战](https://bbs.huaweicloud.com/community/usersnew/id_1581562504371027)

```sql
-- 多级json解析
json_extract_scalar(param_ext, '$.intention.cat_l1')    cat_l1_dsl_online,




```

[deepcross](https://zhuanlan.zhihu.com/p/524314161)

[一文搞懂bias](https://zhuanlan.zhihu.com/p/434443674)、

[基于MindSpore框架wide&deep模型的实战CTR体验](

## Transformer

### 详解

### 优缺点

## 召回

### 召回层

召回层解决的是从海量候选item中召回千级别的item问题

- 统计类，热度，LBS
- 协同过滤类，UserCF、ItemCF
- U2T2I，如基于user tag召回
- I2I类，如Embedding（Word2Vec，FastText），GraphEmbedding（Node2Vec、DeepWalk、EGES）
- U2I类，如DSSM、YouTube DNN、Sentence Berts

## LTR（Learning To Rank）三大结构

### 模型定义

learning to rank流程三大模式（pointwise、pairwise、listwise），主要是特征工程和CTR模型预估

排序模型按照样本生成方法和损失函数loss的不同，可以划分为Pointwise，Pairwise，Listwise三种方法

- 粗排层：本质上跟精排类似，只是特征和模型复杂度上会精简，此外也有将精排模型通过蒸馏得到简化版模型来做粗排
  - 常见的特征挖掘（user、item、context以及相互交叉）
- 精排层：精排解决的是从千级别item到几十这个级别的问题
  - **CTR预估**：lr，gbdt，fm及其变种（fm是一个工程团队不太强又对算法精度有一定要求时比较好的选择），widedeep，deepfm，NCF各种交叉，DIN，BERT，MTL（多任务学习）
  - **多目标**：MOE，MMOE，MTL（多任务学习）
  - **打分公式融合**：随机搜索，CEM，在线贝叶斯优化，带模型CEM，强化学习
- **重排层**：重排层解决的是展示列表总体最优，模型有**MMR**，DPP，RNN系列
- 展示层：
  - 推荐理由：统计规则、行为规则、抽取式（一般从评论和内容中抽取）、生成式；排序可以用汤普森采样（简单有效），融合到精排模型等等
  - 首图优选：CNN抽特征，汤普森采样
- 探索与利用：随机策略（简单有效），汤普森采样，bandit，强化学习（Q-Learning、DQN）等
- 产品层：交互式推荐、分tab、多种类型物料融合

### 排序学习场景

- 推荐系统：基于历史行为的猜你喜欢
- 搜索排序：基于某Query进行的结果排序，期望用户选中的在排序结果中是靠前的=>有意识的被动推荐
- 排序结果都很重要，猜用户想要点击或者booking 的item就在结果列表前面
- 排序学习是个性化结果，用于搜索列表、推荐列表、广告等场景

### LTR

- 采用机器学习的方法，在给定一组文档集合，对任意查询请求给出反应文档相关性的文档排序。
- LTR已经被广泛应用到文本挖掘的很多领域，比如IR中排序返回的文档，推荐系统中的候选产品、搜索召回系统的商品排序。
- 能够融合多种信息，语义、tf、idf、统计数据（点击、加购、曝光，比率，占比，回购周期）
- 有3种不同的优化方式：
  - **pointwise**：将问题转化为多分类或回归问题。
    - 如果归结为多分类问题：对于某个 Query，对文档与此 Query 的相关程度打标签，标签分为有限的类别，这样就将问题转为多分类问题；
    - 如果归结为回归问题：对于某个 Query，则对文档与此 Query 的相关程度计算相关度 Score，这样就将问题归结为回归问题。
    - 局限性：它只对给定 Query 单个文档的相关度进行建模，仅仅考虑了单个文档的绝对相关度，Pointwise 只学习到了文档和 Query 的全局相关性，对排序先后顺序有一定的影响。在某一些场景下，排在最前面的几个文档对排序结果的影响非常重要，如搜索引擎的第一页的内容非常重要，而 Pointwise 没有考虑这方面的影响，不对排序的先后顺序优劣做惩罚
  - **pairwise**：Pairwise 考虑的则是两个文档之间的相对相关度，比较不同文档的先后顺序。
    - 它将整个排序问题转为二元分类问题，即构建的是一个二分类器，对一个文档对 <Doc1, Doc2> 做二分类，一类是 Doc1 排序前于 Doc2，另一类则相反，通过两两比较，模型可以学习到不同文档之间的先后顺序。
    - 局限：
      - 只考虑了两篇文档的相对顺序，使用的是两文档之间相关度的损失函数没有考虑他们出现在搜索结果列表中的位置，如可能出现 Pairwise Loss 越来越低，但 NDCG 分数也越来越低的现象。排在前面的文档更为重要，如果出现在前面的文档判断错误，惩罚函数要明显高于排在后面判断错误。因此需要引入位置因素，每个文档对根据其在结果列表中的位置具有不同的权重，越排在前面权重越大，如果排错顺序其受到的惩罚也越大。
      - 对于不同的查询相关文档集的数量差异很大，转换为文档对后，有的查询可能只有十几个文档对，而有的查询可能会有数百个对应的文档对，这对学习系统的效果评价带来了偏置。假设查询1对应500个文档对，查询2对应10个文档对，假设机器学习系统对应查询1能够判断正确480个文档对，对应查询2能够判断正确2个。对于总的文档对该系统准确率是（480+2）/（500+10）=95%，但从查询的角度，两个查询对应的准确率分别为：96%和20%，平均为58%，与总的文档对判断准确率相差巨大，这将使得模型偏向于相关文档集大的查询
  - **listwise**：它将每个查询对应的所有搜索结果列表作为一个训练样例，不再将排序问题转化为一个分类问题或者回归问题，而是直接针对评价指标对文档的排序结果进行优化，如常用的 MAP、NDCG 等。
    -  Listwise方法往往更加直接，它专注于自己的目标和任务，直接对文档排序结果进行优化，因此往往效果也是最好的



### Pointwise排序学习（单点法）

- 将训练样本转换为多分类问题（样本特征-类别标记）或者回归问题（样本特征-连续值）
- 只考虑单个样本的好坏，没有考虑样本之间的顺序

pointwise将其转化为多类分类或者回归问题

pointwise类方法，其L2R框架具有以下特征

- 输入空间中样本是单个doc（和对应query）构成的特征向量
- 输出空间中样本是单个doc（和对应query）的相关度
- 假设空间中样本是打分函数
- 损失函数评估单个doc的预测得分和真实得分之间差异

**算法简介：**根据使用的ML方法不同，pointwise类可以进一步分成三类（基于回归的算法、基于分类的算法、基于有序回归的算法）

- 基于回归的算法：此时输出空间包含的是实值相关度得分，采用ML中传统的回归方法即可
- 基于分类的算法：此时，输出空间包含的是无序类别，对于二分类，SVM、LR等均可；对于多酚类，提升树等均可
- 基于有序回归的算法：此时输出空间包含的是有序类别，通常是找到一个打分函数，然后用一系列阈值对得分进行分割，得到有序类别。采用PRanking、基于margin的方法都可以

**pointwise细则：**

- 输入：单个document

- 标签label：document所属类型或者分支。一个k维度的one-hot表示，我们可以用交叉熵loss作为目标损失函数
  $$
  L=-(y_ilog(p_i)-(1-y_ilog(1-p_i)))
  $$

**pointwise排序学习**

- 总结
  - 将文档转化为特征向量，每个文档都是独立的
  - 对于某一个query，它将每个doc分别判断与这个query的相关程度
  - 将docs排序问题转化为了分类（比如相关、不相关）或回归问题（相关程度越大，回归函数的值越大）
  - 从训练数据中学习到的分类或者回归函数对doc打分，打分结果即是搜索结果，CTR可以采用Pointwise方式进行学习，对每一个候选item给出一个评分，基于评分进行排序
  - 仅仅考虑了query和doc之间的关系，而没有考虑排序列表中docs之间的关系
  - 主要算法：转换为回归问题，使用LR，GBDT，Prank, McRank
- 缺陷
  - ranking 追求的是排序结果，并不要求精确打分，只要有相对打分即可。
  - pointwise 类方法并没有考虑同一个 query 对应的 docs 间的内部依赖性。一方面，导致输入空间内的样本不是 IID 的，违反了 ML 的基本假设，另一方面，没有充分利用这种样本间的结构性。其次，当不同 query 对应不同数量的 docs 时，整体 loss 将会被对应 docs 数量大的 query 组所支配，前面说过应该每组 query 都是等价的。
  - 损失函数也没有 model 到预测排序中的位置信息。因此，损失函数可能无意的过多强调那些不重要的 docs，即那些排序在后面对用户体验影响小的 doc。
- 改进
  - Pointwise 类算法也可以再改进，比如在 loss 中引入基于 query 的正则化因子的 RankCosine 方法。

### Pairewise排序学习（配对法）

Pairwise 类方法，其 L2R 框架具有以下特征：

- 输入空间中样本是（同一 query 对应的）两个 doc（和对应 query）构成的两个特征向量；
- 输出空间中样本是 pairwise preference；
- 假设空间中样本是二变量函数；
- 损失函数评估 doc pair 的预测 preference 和真实 preference 之间差异。

**算法简介：**pairwise 类方法基本就是使用二分类算法即可。

经典的算法有 基于 NN 的 SortNet，基于 NN 的 RankNet，基于 fidelity loss 的 FRank，基于 AdaBoost 的 RankBoost，基于 SVM 的 RankingSVM，基于提升树的 GBRank。

- 比较流行的LTR学习方法，将排序问题转换为二元分类问题
- 接收到用户查询后，返回相关文档列表，确定文档之间的先后顺序关系（多个pair的排序问题），只考虑了两个文档的相对顺序，没有考虑文档在搜索列表中的位置

**pairwise细则：**

基于pairwise的方法，在计算目标损失函数的时候，每一次需要基于一个pair的document的预测结果进行损失函数的计算。比如给定一个pair对的document，优化器需要优化的是两个document的排序关系，与groud truth的排序顺序保持一致。目标是最小化与groud truth不一致的排序对。在实际应用中，pairwise方法比pointwise效果更好，因为预测相对的排序相比预测一个类别或者一个分值，更符合排序的性质。其中模型输入和对应的标签label形式如下：

- 输入: 一个pair对document (A,B)
- 输出标签: 相对顺序label (1, 0.5, 0)

**Pairewise排序学习（配对法）总结：**

1. 比较流行的LTR学习方法，将排序问题转换为二元分类问题
2. 接收到用户査询后，返回相关文档列表，确定文档之间的先后顺序关系（多个pair的排序问题）
3. 对于同一查询的相关文档集中，对任何两个不同label的文档，都可以得到一个训练实例（di,dj）（*d**i*,*d**j*），如果di>dj*d**i*>*d**j*则赋值+1，反之-1
4. 没有考虑文档出现在搜索列表中的位置，排在搜索结果前面的文档更为重要，如果靠前的文档出现判断错误，代价会很高

**缺点：**
**虽然 pairwise 类相较 pointwise 类 model 到一些 doc pair 间的相对顺序信息，但还是存在不少问题，回顾概述中提到的评估指标应该基于 query 和 position，**

- 如果人工标注给定的是第一种和第三种，即已包含多有序类别，那么转化成 pairwise preference 时必定会损失掉一些更细粒度的相关度标注信息。
- doc pair 的数量将是 doc 数量的二次，从而 pointwise 类方法就存在的 query 间 doc 数量的不平衡性将在 pairwise 类方法中进一步放大。
- pairwise 类方法相对 pointwise 类方法对噪声标注更敏感，即一个错误标注会引起多个 doc pair 标注错误。
- pairwise 类方法仅考虑了 doc pair 的相对位置，损失函数还是没有 model 到预测排序中的位置信息。
- pairwise 类方法也没有考虑同一个 query 对应的 doc pair 间的内部依赖性，即输入空间内的样本并不是 IID 的，违反了 ML 的基本假设，并且也没有充分利用这种样本间的结构性。

**改进**
pairwise 类方法也有一些尝试，去一定程度解决上述缺陷，比如：

- Multiple hyperplane ranker，主要针对前述第一个缺陷
- magnitude-preserving ranking，主要针对前述第一个缺陷
- IRSVM，主要针对前述第二个缺陷
- 采用 Sigmoid 进行改进的 pairwise 方法，主要针对前述第三个缺陷
- P-norm push，主要针对前述第四个缺陷
- Ordered weighted average ranking，主要针对前述第四个缺陷
- LambdaRank，主要针对前述第四个缺陷
- Sparse ranker，主要针对前述第四个缺陷

### Listwise排序方法（列表法）

Listwise 类方法，其 L2R 框架具有以下特征：

- 输入空间中样本是（同一 query 对应的）所有 doc（与对应的 query）构成的多个特征向量（列表）；
- 输出空间中样本是这些 doc（和对应 query）的相关度排序列表或者排列；
- 假设空间中样本是多变量函数，对于 docs 得到其排列，实践中，通常是一个打分函数，根据打分函数对所有 docs 的打分进行排序得到 docs 相关度的排列；
- 损失函数分成两类，一类是直接和评价指标相关的，还有一类不是直接相关的。具体后面介绍。

**算法简介：**

- 它是将每一个Query对应的所有搜索结果列表作为一个训练样例
- 根据训练样例训练得到最优评分函数F，对应新的查询，评分F对每个文档打分，然后根据得分由高到低排序，即为最终的排序结果

**Listwise排序学习（列表法）总结：**

1. 它是将每个Query对应的所有搜索结果列表作为一个训练样例
2. 根据训练样例训练得到最优评分函数F，对应新的查询，评分F对每个文档打分，然后根据得分由高到低排序，即为最终的排序结果
3. 直接考虑整体序列，针对Ranking评价指标（比如MAP, NDCG）进行优化
4. 主要算法：ListNet, AdaRank，SoftRank，LambdaRank, LambdaMART等LambdaMART是对RankNet和LambdaRank的改进，在 Yahoo Learning to Rank Challenge比赛中的冠军模型

listwise 类相较 pointwise、pairwise 对 ranking 的 model 更自然，解决了 ranking 应该基于 query 和 position 问题。

**listwise 类存在的主要缺陷是**：一些 ranking 算法需要基于排列来计算 loss，从而使得训练复杂度较高，如 ListNet和 BoltzRank。此外，位置信息并没有在 loss 中得到充分利用，可以考虑在 ListNet 和 ListMLE 的 loss 中引入位置折扣因子。

## 重排层

### MMR

全称最大边缘相关模型，同时将相关性和多样性进行衡量。因此可以方便的调节相关性和多样性的权重来满足偏向"需要相似的内容"或者偏向"需要不同方面的内容"的要求。公式如下
$$
MMR(Q,C,R)=argmax_{D_i\in{R|S}}[\lambda{sim_i(Q,d_i)-(1-\lambda{max_{D_j\in{S}}(sim_2(d_i,d_j))})}]
$$

- $D_i$ ：集合C中的一篇文档
- $Q$ ：query
- $R$ ：C中的相关文档集合
- $S$ ：当前结果集合
- $\lambda$ ：可调超参，$\lambda$ 越大，准确率越高；反之，准确率越小

**改进MMR**

- 内循环中的max改为mean：实际使用中，每次往最终列表S中添加物品时是考虑添加的物品与已在S中物品的平均距离，这样可能会在全局性上保证更多样性化一些。
- 自定义Sim2：物品间的相似度有很多衡量方法，可以不使用模型建模，而是从业务角度出发实现一套物品间相似度的规则。例如，在58的跨域推荐分享中提到，58信息流里面处理的是异构item，很难通过一种固定的、简单的距离 ( 算法 ) 来衡量相似度，所以采用了自定义距离的策略。

**$\lambda$ 值**

通过调节λ值，控制相关性的大小以及相关性和多样性的权衡。理想的状态是，随着λ值的增大，多样性的提升，人均的浏览条数基本是在稳定地增加的，并且点击率会在λ为某值的时候达到最大值，随着之后多样性的增加，点击率会逐渐下降。

## 展示层

### 汤普森采样

# 冷启动

## 如何解决深度推荐系统中的Embedding冷启动问题

### 问题出现原因

以 Word2vec为例，训练它的最终目的是要得到与onehot输入对应的向量，用这个Embedding向量来表示一个用户，或者一个物品，或者一个特定的特征。

为了生成这样一个Embedding向量，我们就必须完成整个神经网络的训练，必须在Embedding matrix 训练完毕、收敛之后，才能够提取对应的Embedding。

**但如果在模型训练完毕之后，又来了一个新的user或者item。怎么办？**

### 补充Side Information

大多数Embedding方法是建立在用户的行为序列数据基础上的，用户历史行为越多，训练出的Embedding越准确。但是，用户的历史行为并不是很容易产生的，尤其是购买、完成观看这类高质量的正向行为。因此，如果仅基于历史行为生成Embedding，必然会造成其覆盖率低下。

为了为更多的item和user生成Embedding，我们必须加入一些其他类型的特征，典型的用户侧特征是人口属性特征，典型的物品侧特征是一些内容型特征，一般统称**side information**

当一个Item没有历史行为信息的时候，还可以通过其他特征生成其Embedding，这就大大提高了Embedding的覆盖率。

解决冷启动问题也没必要总是执着于从Embedding的角度解决，因为Embedding也是作为一类特征输入到主推荐模型，或者主CTR预估模型之中的。既然这样，我们也完全可以直接把物品或者用户特征输入到主模型之中，只要这个主模型能够进行online inference，照样可以解决冷启动问题

### 补充机制

在Airbnb那篇经典的Embedding文章中，所采用的冷启动机制就很实用。（论文地址：[https://www.kdd.org/kdd2018/accepted-papers/view/real-time-personalization-using-embeddings-for-search-ranking-at-airbnb](https://link.zhihu.com/?target=https%3A//www.kdd.org/kdd2018/accepted-papers/view/real-time-personalization-using-embeddings-for-search-ranking-at-airbnb)）

首先为大多数已有短租屋生成Embedding，那么在新的短租屋上架之后，会按照新的短租屋和已有短租屋的属性（房屋类型，价格，房间数等等）和地理位置距离，找到三个相似的有Embedding的短租屋，然后取其Embedding的平均。

类似于利用聚类快速定位新物品所在的cluster，找到相似物品。

再比如根据用户/物品的特征训练一颗决策树，再把冷启动的用户/物品根据有限的信息分配到决策树的某个分支中去，再根据分支对应的默认列表进行推荐。

### 推荐系统框架的改进

冷启动的问题其实有一半是系统实时性的问题。

模拟一个新闻APP新用户的交互过程，最开始用户的第一次登陆，这个新用户确实是白板一个，我们不得不使用我们刚才介绍的几种方法去做一些聊胜于无的推荐。但是一旦这个用户点击过了第一条新闻，剩下的事情就是速度的比拼了。你的系统能不能实时捕捉到这最新的珍贵信号，决定了你能不能快速的让这个用户渡过冷启动的阶段

### 跳出固有思维

在探索与利用的诸多方法之中，epsilon greedy就是把一部分流量用于瞎猜，让冷启动的物品得到更多的展示，并快速收集数据。

做到快速学习，主动探索，快速收集冷启动物品或者用户的数据，并且快速反馈到模型和特征中去。

# 样本

## 负样本采样

### 推荐系统中有哪些场景是无法获得真负样本的？如何解决？

个性化推荐。App内部的推荐，我们可以根据埋点，比较容易获知用户滑过、忽略了某些推荐内容，所以比较有信心拿哪些item作为负样本。但是在推送场景下，我们很难知道用户未点击的item是用户真的不喜欢还是压根没看见。所以不能放心地将所有未点击的item都当负样本。

在这种无法获得真负样本的场景下，一般我们通过随机采样来获得负样本。但是，随机采样毕竟引入了噪声，这时，再用CTR预估这种要求"绝对准确性"的算法，就不合适了。所以，在召回或个性化推送场景下，我们一般采用 **pairwise LearningToRank** 建模排序的相对准确性。

### 为什么不能只拿曝光未点击做召回模型的负样本？

我们希望召回训练数据的正样本是user和item匹配度最高的那些样本，也即用户点击样本，负样本是user和item最不匹配的那些样本，但不能拿“曝光未点击”作为召回模型的负样本，因为我们从线上日志获得的训练样本，已经是上一版本的召回、粗排、精排替用户筛选过的，即已经是对用户“匹配度较高”的样本了，即推荐系统以为用户会喜欢他们，但用户的行为又表明的对他的嫌弃。拿这样的样本训练出来的模型做召回，并不能与线上环境的数据分布保持一致。也就是说曝光未点击既不能成为合格的正样本，也不能成为合格的负样本。

所以一般的做法是拿点击样本做正样本，拿随机采样做负样本，因为线上召回时，候选库里大多数的物料是与用户没有关系的，随机抽样能够很好地模拟这一分布。

### Batch内负采样

Batch内负采样，即仅将正样本（有曝光有点击）作为训练样本输入模型。在训练过程中，对于一个batch的第 i 行样本，其他行的正样本作为第 i 行样本的负样本。一般而言，neg越大越好，neg最大等于batch_size。

缺点：batch内的物品都是热门物品，导致采样后的负样本中页大都为热门物品，造成对热门物品的过度打压。

## 正样本采样

### 热门打压

- 生成正样本 item+ 时，打压高热 item

  目的是为了降低 item 成为 **item+** 的可能性。因此，item越热门，其成为 **item+** 的概率就应该越低。

  一个item成为 **item+** 的概率
  $$
  P_{pos}(w_i)=(\sqrt{\frac{z(w_i)}{a}} + 1)\frac{a}{z(w_i)}
  $$

  $$
  z(w_i)=\frac{点击过w_i的用户数}{同时段所有发生过点击行为的用户总数}
  $$

  a 为一个超参数，一般在 1e<sup>-3</sup>~1e<sup>-5</sup> 之间

  可以看出 z(w<sub>i</sub>) 越高，item成为 item+ 的概率就越低，从而实现了对热门item的打压。

  而对于一些罕见item，按照公式计算出的概率大于1，说明罕见的item只要被点击过，就一定会被当成正样本。

# 其他

## 如何判断模型是否过拟合

## AB实验

- **定义**

  **A/B 测试**为一种随机测试，将两个不同的东西（即A和B）进行假设比较。该测试运用统计学上的**假设检定**和**双母体假设检定**。A/B 测试可以用来测试某一个变量两个不同版本的差异，一般是让A和B只有该变量不同，再测试其他人对于A和B的反映差异，再判断A和B的方式何者较佳。

  在同一时间对于目标受众做科学抽样、分组测试以评估效果。因为**时间**也是属于**变量**的一部分，比如说平时和双十一期间，gmv一定是双十一期间来的高。

- **为什么要做A/B测试**

  **A/B测试** 可以帮助业务进行最终决策，并且有充分的数据来支撑你的论点。

  - **风险控制**：小流量实验可以避免直接上线效果不好以造成损失。其次，实验迭代的过程中，决策都是有科学依据的，可以避免系统性的偏差
  - **因果推断**：我们推断 A/B实验 中的优化和改变最终能影响到线上数据以及用户行为。A/B测试 可以帮助证明或者推翻我们的推断
  - **复利效应**：A/B测试 是可以持续不断进行的实验，即使一次实验提升的效果不大，但是长期下来复利效应的积累会产生很大的变化和回报

- **A/B test 流程**

  - 分析现状，建立假设：分析业务，确定最高优先级的改进点，作出假设，提出优化建议。
  - 设定指标：设置主要指标来衡量版本的优劣；设置辅助指标来评估其他影响。
  - 设计与开发：设计优化版本的原型并完成开发。
  - 确定测试时长：确定测试进行的时长。
  - 确定分流方案：确定每个测试版本的分流比例及其他分流细节。
  - 采集并分析数据：收集实验数据，进行有效性和效果判断。
  - 给出结论：①确定发布新版本；②调整分流比例继续测试；③优化迭代方案重新开发，回到步骤1。

- **分流&分层的策略**

  如果流量人群不进行分流和分层，则会导致某一个实验占的流量很多，变相导致另一个实验的流量锐减，从而得到的实验结果会有统计学上的误差。

  - **分流策略**

    - Random——随机分流：
    - Partition By User——按用户切分：
    - Partition By Category——按分类切分：

  - **分流分层规则**

    - 正交与互斥：

      - 正交：每个独立实验为一层，层与层之间是正交的，流量穿越每层实验时，都会被随机打乱，且随机结果离散
      - 互斥：实验在同一层拆分流量，且同一层内不同组的流量是不互相重叠的

    - 分流模型

      域1和域2拆分流量，此时域1和域2是互斥的

      流量经过域2中的B1层、B2层、B3层，B1层、B2层、B3层的流量都是与域2的流量相等。此时B1层、B2层、B3层的流量是正交的。

      流量流过域2中的B1层时，又把B1层分为了B1-1，B1-2，B1-3，此时B1-1，B1-2，B1-3之间又是互斥的

    - 规则使用场景

      比如B1层、B2层、B3层可能分别为：UI层、搜索结果层、广告结果层，这些层基本上是没有任何业务关联的，即使使用相同的流量（流量正交）也不会对实际业务结果造成影响。但是不同层之间所进行的实验相互关联，就会影响下游实验。因此建议同一类型的实验在同一层内进行，并且要考虑不同实验之间相互的依赖

- **其他技术**

  - **p-value**：概率，主要在 A/B测试 中说明实验提升的显著性，并且往往与假设检验相挂钩。

    - p < 0.05：有统计学差异
    - p < 0.01：有显著统计学差异
    - p < 0.001：有极其显著的统计学差异

    在实践中可以先设置空跑期，进行AA test，来检查流量分布是否均匀

  - **假设检验**：是推论统计中用于检验现有数据是否足以支持特定假设的方法。一旦能估计未知参数，就会希望根据结果对未知的真正参数值做出适当的推论。假设检验的步骤如下：

    - 最初研究假设为真相不明
    - 提出相关的零假设和备择假设
    - 考虑检验中对样本做出的统计假设
    - 选择一个显著性水平 α
    - 选择适合的检验统计量 T
    - 在设定零假设为真下推导检验统计量的分布
    - 根据在零假设成立时的检验统计量T分布，找到概率为显著性水平 (α) 的区域，此区域称为“拒绝域”(记作RR或CR)，即在零假设成立的前提下，落在拒绝域的概率只有α。
    - 针对检验统计量T，根据样本计算其估计值t<sub>obs</sub>
    - 若估计值t<sub>obs</sub>未落在拒绝域，则“不拒绝”零假设（do no reject 𝐻<sub>0</sub>）。若估计值t<sub>obs</sub>落在拒绝域，则拒绝零假设，接受备择假设。

## AB实验中常见的问题

### 用户抽样不科学

先来看一组数据

| 学院 | 女生申请数 | 女生录取数 | 女生录取率 | 男生申请数 | 男生录取数 | 男生录取率 | 申请总数 | 录取总数 | 总录取率 |
| ---- | ---------- | ---------- | ---------- | ---------- | ---------- | ---------- | -------- | -------- | -------- |
| 1    | 100        | 49         | 49%        | 20         | 15         | 75%        | 120      | 64       | 53.3%    |
| 2    | 20         | 1          | 5%         | 100        | 10         | 10%        | 120      | 11       | 9.2%     |
| 总计 | 120        | 50         | 42%        | 120        | 25         | 21%        | 240      | 75       | 31.3%    |

单看男生，无论是1号学院还是2号学院，男生录取率都高于女生，因此总体的录取率是不是也是男生高于女生呢？

统计出来并不是，男生的总体录取率要远低于女生，这种现象就被称为辛普森悖论

- **辛普森悖论**：几组不同的数据中均存在一种趋势，但当这些数据组合在一起后，这种趋势消失或反转。其产生的原因主要是数据中存在多个变量。这些变量通常难以识别，被称为“潜伏变量”。潜伏变量可能是由于采样错误造成的。

在 A/B 测试 中，如果实验组和对照组的样本流量分布不一致，就有可能产生辛普森悖论

### 互斥层选择错误

- 互斥层选择原则：
  - 假设实验之间有相关性，那么实验必须置于同一互斥层；
  - 假设实验之间没有相关性，那么实验可以至于不同互斥层

### 不考虑是否显著

只简单地观测实验数据的涨跌，不去考虑实验结果是否显著

## 评价指标

### Hinge

通常用于 maximum-margin 的分类任务中，如支持向量机
$$
L(y)=max(0, 1-\hat{y}y)
$$
以支持向量机为例，其模型为
$$
\hat{y}=w·x
$$
其求导结果如下
$$
\frac{\partial{L}}{\partial{w_i}}=
\begin{cases}
-yx_i, \hat{y}y > 1\\ 
0,  otherwise
\end{cases}
$$
实际应用中，一方面很多时候我们 y 的值域并不是-1~1，比如我们更希望y更接近于一个概率，其值域最好是0~1。另一方面，很多时候我们希望训练的是两个样本之间的相似关系，而非样本的整体关系，所以很多时候我们会用下面的公式
$$
L(y,y^{'})=max(0, m-y+y^{'})
$$
其中，y是正样本的得分，y<sup>'</sup> 是负样本的得分，m是margin

即我们希望正样本分数越高越好，负样本分数越低越好

### Cross-Entropy

### MSE

### 搜索评价指标——NDCG

NDCG，Normalized Discounted cumulative gain(归一化折损累计增益)。

#### 主要思想：

- 高关联度的结果比一般关联度的结果更影响最终的指标得分
- 有高关联度的结果出现在更靠前的位置的时候，指标会越高

#### 累计增益（CG）

CG，cumulative gain，是DCG的前身，只考虑了相关性的关联程度，没有考虑到位置的因素。它是一个搜索结果相关性分数的总和。指定位置p上的CG为：
$$
CG_p=\sum_{i=1}^prel_i
$$
rel<sub>i</sub> 代表这个位置上的相关度

比如：假设搜索 篮球 结果，最理想的是B1、B2、B3。而出现的结果是 B3、B1、B2的话，CG的值是不会变的

#### 折损累计增益（DCG）

DCG，Discounted的CG，就是在每一个CG的结果上除以一个折损值。

目的：为了让排名越靠前的结果越能影响最后的结果。
$$
DCG_p=\sum_{i=1}^p\frac{rel_i}{log_2(i+1)}=rel_1+\sum_{i=2}^p\frac{rel_i}{log_2(i+1)}
$$
还有一种比较常用的公式，用来增加相关度影响比重的DCG计算方式
$$
DCG_p=\sum_{i=1}^p\frac{2^{rel_i}-1}{log_2(i+1)}
$$
后一种更多用于工业。当相关值为二进制时，二者结果是一致的。

#### 归一化折损累计增益（NDCG）

NDCG，Normalized的DCG，由于搜索结果随着检索词的不同，返回的数量是不同的，而DCG是一个累加的值，没法针对两个不同的搜索结果进行比较，因此需要归一化处理。
$$
nDCG_p=\frac{DCG_p}{IDCG_p}
$$
IDCG为理想情况下最大的DCG值
$$
IDCG_p=\sum_{i=1}^{|REL|}\frac{2^{rel_i}-1}{log_2(i+1)}
$$
其中 |REL| 表示，结果按照相关性从大到小的顺序排序，取前p个结果组成的集合。也就是按照最优的方式对结果进行排序

#### 示例

假设搜索回来的结果，其相关性分数分别是 3、2、3、0、1、2

那么CG = 3+2+3+0+1+2=11

可以看到只是对相关的分数进行了一个关联的打分，并没有召回的所在位置对排序结果评分的影响。而我们看DCG：

| i    | reli | log2(i+1) | reli/log2(i+1) |
| ---- | ---- | --------- | -------------- |
| 1    | 3    | 1         | 3              |
| 2    | 2    | 1.58      | 1.26           |
| 3    | 3    | 2         | 1.5            |
| 4    | 0    | 2.32      | 0              |
| 5    | 1    | 2.58      | 0.38           |
| 6    | 2    | 2.8       | 0.71           |

所以DCG = 3+1.26+1.5+0+0.38+0.71 = 6.86

接下来我们归一化，归一化需要先结算 IDCG，假如我们实际召回了8个物品，除了上面的6个，还有两个结果，假设第7个相关性为3，第8个相关性为0。那么在理想情况下的相关性分数排序应该是：3、3、3、2、2、1、0、0。计算IDCG@6:

| i    | reli | log2(i+1) | reli/log2(i+1) |
| ---- | ---- | --------- | -------------- |
| 1    | 3    | 1         | 3              |
| 2    | 3    | 1.58      | 1.89           |
| 3    | 3    | 2         | 1.5            |
| 4    | 2    | 2.32      | 0.86           |
| 5    | 2    | 2.58      | 0.77           |
| 6    | 1    | 2.8       | 0.35           |

所以IDCG = 3+1.89+1.5+0.86+0.77+0.35 = 8.37

因此最终 NDCG@6 = 6.86/8.37 = 81.96%

## 智力题

### 使用一个天平找8个球中其中一个重量不一致的球

- 第一次：将八个球两两分组，12为A组，34为B组，56为C组，78为D组；将A组放在左盘，B组放在右盘，如果不平衡，可以判断不一致的在AB两组，即1234，否则在5678
- 第二次：假设在AB两组。将1球放在左盘，2球放在右盘，如果不平衡，不一致的在12两个球中，否则在34两个球中
- 第三次：假设不一致的球在12两个球中，将1放在左盘，3放在右盘，如果不平衡，则不一致的为1球，否则为2球

### 八个小球找最重

最少要两次。

先从8个球中拿出六个球，天平两端各三个，若平衡，则较重的那个球在剩余的两个里，把剩余的两个球放在天平上，较重的那端就是较重的球；

若不平衡，则将6个球中较重一端的其中两个放在天平上，若平衡，则剩余的那个就是较重的球；若不平衡，较重的那端，就是较重的球。

### 北京一般有雾霾的概率是1/4，有三个同事都说今天有雾霾，但他们说真话的概率为3/4，问今天真的有雾霾的概率是多少。

$$
P=3*P(A)*P(O)=3*\frac{3}{4}*\frac{1}{4}
$$

### 36匹马，6个赛道，没有计时器，如何用最少的次数比出前三名

- 第一轮比赛：将36匹马分成6组，每组6匹马，进行6场比赛。这6场比赛后，每组都会有一个第一名、第二名和第三名。
  - 记录下每组的前三名，这样我们有18匹马进入了下一轮筛选。

- 第二轮比赛：从每组的第一名中挑选出6匹马，进行一场复赛。这场比赛的前三名就是所有36匹马中的前三名的候选者。
  - 假设这场比赛的结果是A1 > B1 > C1 > D1 > E1 > F1（A1是第一名，B1是第二名，C1是第三名，依此类推）。

- **第三轮比赛**：根据复赛的结果，确定哪些马有资格进入最后一轮比赛以决定最终的前三名。

  - A1已经确定是所有马中的第一名。

  - B1和C1可能是第二名和第三名的候选者。

  - A1所在组的第二名（A2）和第三名（A3）也可能是第二名和第三名的候选者。

  - B1所在组的第二名（B2）也可能是第三名的候选者。

- **第四轮比赛**：让B1、C1、A2、A3和B2进行一场比赛，这场比赛的前两名将是所有马中的第二名和第三名。

总结

- **初赛**：6场比赛。
- **复赛**：1场比赛。
- **确定最终前三名**：1场比赛。

### 有N个人(N<365)，生日都不相同的概率。

- 第一个人的生日可以是任何一天，所以概率为 $365/365=1$
- 第二个人的生日不能与第一个人的生日相同，因此有364中选择，概率为 $364/365$
- 第三个人的生日不能与前两个人的生日相同，因此有363中选择，概率为 $363/365$

将这些概率相乘，就得到了N个人生日都不相同的概率P
$$
P=\frac{365}{365}*\frac{364}{365}*\frac{363}{365}*...*\frac{366-N}{365}
$$

$$
P=\frac{365!}{(365-N)!*365^N}
$$

当N=23时，两个人生日不相同的概率超过50%

### 比较e^2与2^e的大小

思路：

- 将 $e$ 看作变量 $x$ ，即比较$x^2$ 和 $2^x$ 的大小
- 令 f(x)=x^2-2^x$  
- 将其对数化后可得，$g(x)=ln(f(x))=\frac{2lnx}{xln2}=\frac{2}{ln2}\frac{lnx}{x}$
- 因此，假设 $f(x)=\frac{lnx}{x}$
- 对其求导可得 $f'(x)=\frac{1-lnx}{x^2}$，令其为0，可得x = e
- 故 $f(e)>f(2)$ ，因此 $e^2>2^e$

## 常见的排序算法

### O(n^2)

- 冒泡排序

  ```python
  import random
  class Solution:
      def sortArray(self, nums: List[int]) -> List[int]:
          # 冒泡排序
          n = len(nums)
          for i in range(n - 1, -1, -1):
              for j in range(i):
                  if nums[j] > nums[j+1]:
                      nums[j], nums[j+1] = nums[j+1], nums[j]
          return nums
  ```

- 选择排序

  ```python
  import random
  class Solution:
      def sortArray(self, nums: List[int]) -> List[int]:
      	for i in range(len(nums)):
              idx = i
              for j in range(i + 1, len(nums)):
                  if nums[j] < nums[idx]:
                      idx = j
              nums[i], nums[idx] = nums[idx], nums[i]
          return nums
  ```

- 插入排序

  ```python
  import random
  class Solution:
      def sortArray(self, nums: List[int]) -> List[int]:
      	for i in range(1, len(nums)):
          #     cur = nums[i]
          #     j = i - 1
          #     while j >= 0 and nums[j] >= cur:
          #         nums[j + 1] = nums[j]
          #         j -= 1
          #     nums[j+1] = cur
          # return nums
  ```

### O(nlogn)

- 快速排序

  ```python
  class Solution:
      def sortArray(self, nums: List[int]) -> List[int]:
  		n = len(nums)
          if n < 2:
              return nums
          idx = random.randint(0, n - 1)
          nums[idx], nums[-1] = nums[-1], nums[idx]
          cur = nums[-1]
          l, r = 0, n - 1
          i = 0
          while i < r:
              if nums[i] < cur:
                  nums[i], nums[l] = nums[l], nums[i]
                  i += 1
                  l += 1
              elif nums[i] == cur:
                  i += 1
              elif nums[i] > cur:
                  nums[i], nums[r-1] = nums[r-1], nums[i]
                  r -= 1
          nums[i], nums[-1] = nums[-1], nums[i]
          return self.sortArray(nums[:l]) + nums[l:r+1] + self.sortArray(nums[r+1:])
  ```

- 堆排序

- 归并排序

  ```python
  class Solution:
      def sortArray(self, nums: List[int]) -> List[int]:
      	if len(nums) < 2:
              return nums
          n = len(nums)
          mid = n // 2
          left = self.sortArray(nums[:mid])
          right = self.sortArray(nums[mid:])
          L, R = 0, 0
          res = []
          while L < len(left) and R < len(right):
              if left[L] <= right[R]:
                  res.append(left[L])
                  L += 1
              else:
                  res.append(right[R])
                  R += 1
          res += left[L:] 
          res += right[R:]
          return res
  ```

  

# 面试流程

## 1. 自我介绍





## 2. 项目介绍



## 3. 可能会问的问题
